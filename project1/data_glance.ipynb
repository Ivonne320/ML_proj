{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "# import SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure: 1. normalize coding for missing values: check each feature, assign NaN to values > 95% percentile. --> 2. check each row, drop the rows where over 50% of the features are NaN. Also remove the corresponding y  --> 3. Check each columns, drop the feature where over 50% of the rows are NaN or std == 0. Record the index for test set. --> 4. Handling NaN values: check for categorical feature (record the index), assign NaN to mean for non-categorical and majority label for categorial. --> 5. One-hot encoding for categorical data. --> 6. Standardize (skip categorical 0-1 columns)  --> 7. Regard a datapoint having more than 30% of the features with Z-score>2.5 as outliers, remove from x and corresponding y. --> 8. Data Augmentation --> 9. PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"./data/dataset_to_release\", sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6563, 321)\n",
      "(6563,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(656, 321)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sub, y_sub = split_cross_validation(x_train, y_train, 10)\n",
    "np.shape(x_sub[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6101, 199)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6101, 521)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thresholds for nans\n",
    "row_nan = 0.55\n",
    "feature_nan = 0.8\n",
    "# threshold for categorical features\n",
    "threshold_cat = 10\n",
    "# threshold for outliers\n",
    "z_threshold=2\n",
    "feature_threshold=0.15\n",
    "\n",
    "x_train_processed = x_train.copy()\n",
    "y_train_processed = y_train.copy()\n",
    "\n",
    "# transform y to 0-1 encoding\n",
    "y_train_processed = process_y(y_train_processed)\n",
    "\n",
    "# Uniform missing value encoding\n",
    "x_train_processed = normalize_nan(x_train_processed)\n",
    "# Remove rows with too many nans\n",
    "x_train_processed, y_train_processed = drop_rows(x_train_processed, y_train_processed, row_nan) # 0.55 remains 6101 rows\n",
    "# x_train_processed.shape\n",
    "# Remove features with too many nans\n",
    "x_train_processed, nan_indices = drop_features(x_train_processed, feature_nan) # 0.5 remains 174 features\n",
    "print(x_train_processed.shape)\n",
    "\n",
    "# get categorical feature indices\n",
    "cat_indices = check_categorical(x_train_processed, threshold_cat)\n",
    "# handling remaining nans\n",
    "x_train_processed = fillna(x_train_processed, cat_indices)\n",
    "# One hot encoding for categorical features\n",
    "x_train_processed = one_hot_encoding(x_train_processed, cat_indices)\n",
    "x_train_processed = standardize(x_train_processed)\n",
    "x_train_processed, y_train_processed = z_outlier_removal(x_train_processed, y_train_processed, z_threshold, feature_threshold)\n",
    "x_train_processed.shape\n",
    "# x_train_processed = add_bias(x_train_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train_processed==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6093, 446)\n",
      "(6093,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(x_train_processed.shape)\n",
    "print(y_train_processed.shape)\n",
    "print(np.sum(x_train_processed.std(axis=0) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_processed_orig = x_train.copy()\n",
    "# x_train_processed_orig = fillna_with_mean(x_train_processed_orig, threshold=threshold_nan)\n",
    "# x_train_processed_orig = standardize(x_train_processed_orig)\n",
    "# x_train_processed_orig = polynomial_expansion_single(x_train_processed_orig, degree=2)\n",
    "# x_train_processed_orig = standardize(x_train_processed_orig)\n",
    "# x_train_processed_orig = add_bias(x_train_processed_orig)\n",
    "# # add a column of ones\n",
    "# y_train_processed_orig = y_train.copy()\n",
    "# y_train_processed_orig = process_y(y_train_processed_orig)\n",
    "# print(np.isnan(x_train_processed_orig).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train_processed_orig.shape)\n",
    "# print(y_train_processed_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.26568829e-02+3.28389692e-36j  4.02483804e-02+2.51005234e-36j\n",
      "  3.03924838e-02+1.89539863e-36j  2.49265648e-02+1.55452174e-36j\n",
      "  2.18695115e-02+1.36387149e-36j  1.94795027e-02+1.21482084e-36j\n",
      "  1.73995382e-02+1.08510582e-36j  1.65357118e-02+1.03123410e-36j\n",
      "  1.56929782e-02+9.78677806e-37j  1.44867255e-02+9.03450997e-37j\n",
      "  1.37198643e-02+8.55626416e-37j  1.33676614e-02+8.33661616e-37j\n",
      "  1.28341179e-02+8.00387676e-37j  1.22195935e-02+7.62063440e-37j\n",
      "  1.16619885e-02+7.27288931e-37j  1.14594041e-02+7.14654948e-37j\n",
      "  1.12799034e-02+7.03460551e-37j  1.04455630e-02+6.51427698e-37j\n",
      "  9.91533879e-03+6.18360767e-37j  9.08010631e-03+5.66272280e-37j\n",
      "  8.87686340e-03+5.53597227e-37j  8.66614304e-03+5.40455850e-37j\n",
      "  8.41713465e-03+5.24926676e-37j  7.99141873e-03+4.98377304e-37j\n",
      "  7.94743009e-03+4.95633994e-37j  7.71911948e-03+4.81395618e-37j\n",
      "  7.54541672e-03+4.70562809e-37j  7.36794659e-03+4.59495051e-37j\n",
      "  7.27105948e-03+4.53452778e-37j  6.96238106e-03+4.34202339e-37j\n",
      "  6.83296695e-03+4.26131550e-37j  6.77225055e-03+4.22345029e-37j\n",
      "  6.53634648e-03+4.07633093e-37j  6.38731769e-03+3.98339053e-37j\n",
      "  6.35812365e-03+3.96518394e-37j  6.24644783e-03+3.89553837e-37j\n",
      "  5.94202644e-03+3.70568884e-37j  5.84049015e-03+3.64236669e-37j\n",
      "  5.65292920e-03+3.52539607e-37j  5.60895439e-03+3.49797159e-37j\n",
      "  5.51346603e-03+3.43842117e-37j  5.36197990e-03+3.34394827e-37j\n",
      "  5.33709752e-03+3.32843061e-37j  5.16445951e-03+3.22076654e-37j\n",
      "  5.12361091e-03+3.19529170e-37j  5.05116589e-03+3.15011204e-37j\n",
      "  5.01468396e-03+3.12736043e-37j  4.92411793e-03+3.07087978e-37j\n",
      "  4.86280284e-03+3.03264120e-37j  4.79652777e-03+2.99130938e-37j\n",
      "  4.74550304e-03+2.95948828e-37j  4.66814221e-03+2.91124293e-37j\n",
      "  4.64741271e-03+2.89831517e-37j  4.63692629e-03+2.89177542e-37j\n",
      "  4.57380248e-03+2.85240885e-37j  4.53699223e-03+2.82945248e-37j\n",
      "  4.45331179e-03+2.77726596e-37j  4.39517650e-03+2.74101044e-37j\n",
      "  4.38737463e-03+2.73614487e-37j  4.35826359e-03+2.71799005e-37j\n",
      "  4.28194021e-03+2.67039169e-37j  4.19070470e-03+2.61349352e-37j\n",
      "  4.14497350e-03+2.58497369e-37j  4.09387672e-03+2.55310766e-37j\n",
      "  4.07916618e-03+2.54393358e-37j  4.05350831e-03+2.52793229e-37j\n",
      "  3.99868709e-03+2.49374355e-37j  3.96493529e-03+2.47269456e-37j\n",
      "  3.93559942e-03+2.45439952e-37j  3.86752875e-03+2.41194789e-37j\n",
      "  3.85867431e-03+2.40642589e-37j  3.83783251e-03+2.39342811e-37j\n",
      "  3.73418521e-03+2.32878944e-37j  3.71098370e-03+2.31432004e-37j\n",
      "  3.69781449e-03+2.30610719e-37j  3.65529549e-03+2.27959061e-37j\n",
      "  3.60410083e-03+2.24766354e-37j  3.59617541e-03+2.24272093e-37j\n",
      "  3.54792689e-03+2.21263120e-37j  3.51589645e-03+2.19265571e-37j\n",
      "  3.50120143e-03+2.18349130e-37j  3.41738304e-03+2.13121875e-37j\n",
      "  3.38179858e-03+2.10902684e-37j  3.36447326e-03+2.09822206e-37j\n",
      "  3.34455759e-03+2.08580185e-37j  3.32467804e-03+2.07340416e-37j\n",
      "  3.29174175e-03+2.05286375e-37j  3.24519229e-03+2.02383361e-37j\n",
      "  3.22147191e-03+2.00904062e-37j  3.16763397e-03+1.97546509e-37j\n",
      "  3.16064542e-03+1.97110675e-37j  3.13579990e-03+1.95561208e-37j\n",
      "  3.11713989e-03+1.94397494e-37j  3.08361932e-03+1.92307015e-37j\n",
      "  3.02507127e-03+1.88655721e-37j  2.97404486e-03+1.85473507e-37j\n",
      "  2.96789397e-03+1.85089913e-37j  2.93358822e-03+1.82950467e-37j\n",
      "  2.92399895e-03+1.82352441e-37j  2.89736457e-03+1.80691413e-37j\n",
      "  2.87049858e-03+1.79015941e-37j  2.83192284e-03+1.76610201e-37j\n",
      "  2.80751486e-03+1.75088020e-37j  2.79520958e-03+1.74320613e-37j\n",
      "  2.78054332e-03+1.73405966e-37j  2.76597273e-03+1.72497284e-37j\n",
      "  2.73657085e-03+1.70663664e-37j  2.72934847e-03+1.70213247e-37j\n",
      "  2.71614974e-03+1.69390121e-37j  2.67848322e-03+1.67041084e-37j\n",
      "  2.65874719e-03+1.65810265e-37j  2.63900377e-03+1.64578985e-37j\n",
      "  2.61499596e-03+1.63081760e-37j  2.59923159e-03+1.62098630e-37j\n",
      "  2.58082812e-03+1.60950915e-37j  2.56246023e-03+1.59805419e-37j\n",
      "  2.53686010e-03+1.58208891e-37j  2.52681100e-03+1.57582189e-37j\n",
      "  2.51428881e-03+1.56801254e-37j  2.49388705e-03+1.55528918e-37j\n",
      "  2.48433390e-03+1.54933144e-37j  2.45865246e-03+1.53331546e-37j\n",
      "  2.43756484e-03+1.52016436e-37j  2.42852947e-03+1.51452954e-37j\n",
      "  2.40413761e-03+1.49931778e-37j  2.40063536e-03+1.49713363e-37j\n",
      "  2.38094629e-03+1.48485473e-37j  2.36606006e-03+1.47557108e-37j\n",
      "  2.36335500e-03+1.47388409e-37j  2.35287833e-03+1.46735041e-37j\n",
      "  2.33795840e-03+1.45804574e-37j  2.32600712e-03+1.45059244e-37j\n",
      "  2.31703367e-03+1.44499623e-37j  2.31057890e-03+1.44097077e-37j\n",
      "  2.29446495e-03+1.43092146e-37j  2.27167535e-03+1.41670894e-37j\n",
      "  2.25894811e-03+1.40877172e-37j  2.25224981e-03+1.40459438e-37j\n",
      "  2.23733726e-03+1.39529431e-37j  2.22881558e-03+1.38997985e-37j\n",
      "  2.21827485e-03+1.38340622e-37j  2.20482008e-03+1.37501528e-37j\n",
      "  2.20000592e-03+1.37201298e-37j  2.18866873e-03+1.36494264e-37j\n",
      "  2.16937944e-03+1.35291306e-37j  2.15148151e-03+1.34175119e-37j\n",
      "  2.14190209e-03+1.33577707e-37j  2.13640719e-03+1.33235023e-37j\n",
      "  2.11609682e-03+1.31968386e-37j  2.11131834e-03+1.31670380e-37j\n",
      "  2.10961319e-03+1.31564040e-37j  2.08840337e-03+1.30241310e-37j\n",
      "  2.07075108e-03+1.29140441e-37j  2.06411321e-03+1.28726477e-37j\n",
      "  2.05378153e-03+1.28082151e-37j  2.04473457e-03+1.27517946e-37j\n",
      "  2.00927093e-03+1.25306289e-37j  1.99225416e-03+1.24245055e-37j\n",
      "  1.99012686e-03+1.24112388e-37j  1.97593020e-03+1.23227026e-37j\n",
      "  1.95678991e-03+1.22033360e-37j  1.94674996e-03+1.21407228e-37j\n",
      "  1.93620824e-03+1.20749803e-37j  1.92982955e-03+1.20352003e-37j\n",
      "  1.90877285e-03+1.19038821e-37j  1.90605514e-03+1.18869334e-37j\n",
      "  1.90249712e-03+1.18647441e-37j  1.88998712e-03+1.17867267e-37j\n",
      "  1.86443846e-03+1.16273949e-37j  1.86020161e-03+1.16009722e-37j\n",
      "  1.84866553e-03+1.15290285e-37j  1.82879829e-03+1.14051283e-37j\n",
      "  1.82748743e-03+1.13969533e-37j  1.80290692e-03+1.12436592e-37j\n",
      "  1.77959413e-03+1.10982712e-37j  1.76128790e-03+1.09841062e-37j\n",
      "  1.75000858e-03+1.09137637e-37j  1.74463011e-03+1.08802214e-37j\n",
      "  1.73825132e-03+1.08404407e-37j  1.71652066e-03+1.07049194e-37j\n",
      "  1.70074389e-03+1.06065291e-37j  1.68983372e-03+1.05384889e-37j\n",
      "  1.66159044e-03+1.03623523e-37j  1.63694962e-03+1.02086821e-37j\n",
      "  1.61915091e-03+1.00976822e-37j  1.59724632e-03+9.96107627e-38j\n",
      "  1.56856400e-03+9.78220168e-38j  1.54985229e-03+9.66550787e-38j\n",
      "  1.54769150e-03+9.65203231e-38j  1.52208113e-03+9.49231561e-38j\n",
      "  1.50529459e-03+9.38762797e-38j  1.49003123e-03+9.29243946e-38j\n",
      "  1.46134559e-03+9.11354417e-38j  1.44729832e-03+9.02593969e-38j\n",
      "  1.43574055e-03+8.95386071e-38j  1.40868633e-03+8.78513966e-38j\n",
      "  1.39028071e-03+8.67035476e-38j  1.36710889e-03+8.52584584e-38j\n",
      "  1.35586014e-03+8.45569409e-38j  1.32875172e-03+8.28663500e-38j\n",
      "  1.31907756e-03+8.22630301e-38j  1.29292127e-03+8.06318172e-38j\n",
      "  1.25817198e-03+7.84647110e-38j  1.24665772e-03+7.77466350e-38j\n",
      "  1.21750212e-03+7.59283729e-38j  1.21223620e-03+7.55999690e-38j\n",
      "  1.21077108e-03+7.55085986e-38j  1.17702579e-03+7.34041052e-38j\n",
      "  1.15748772e-03+7.21856315e-38j  1.11758915e-03+6.96973951e-38j\n",
      "  1.10981334e-03+6.92124639e-38j  1.08464913e-03+6.76431219e-38j\n",
      "  1.05495310e-03+6.57911566e-38j  1.03720298e-03+6.46841868e-38j\n",
      "  1.03012951e-03+6.42430567e-38j  1.01003514e-03+6.29898907e-38j\n",
      "  1.00022309e-03+6.23779711e-38j  9.77868179e-04+6.09838282e-38j\n",
      "  9.76649678e-04+6.09078375e-38j  9.51266921e-04+5.93248657e-38j\n",
      "  9.41164890e-04+5.86948621e-38j  9.23462504e-04+5.75908695e-38j\n",
      "  8.69960822e-04+5.42542875e-38j  8.50234925e-04+5.30241005e-38j\n",
      "  8.41777020e-04+5.24966312e-38j  8.17987234e-04+5.10130036e-38j\n",
      "  7.94901945e-04+4.95733113e-38j  7.55635060e-04+4.71244690e-38j\n",
      "  7.38827459e-04+4.60762788e-38j  7.08486557e-04+4.41840969e-38j\n",
      "  7.00030043e-04+4.36567144e-38j  6.71504380e-04+4.18777383e-38j\n",
      "  6.66181349e-04+4.15457725e-38j  6.46358297e-04+4.03095265e-38j\n",
      "  5.94884511e-04+3.70994124e-38j  5.81300080e-04+3.62522321e-38j\n",
      "  5.63269778e-04+3.51277893e-38j  5.37266741e-04+3.35061344e-38j\n",
      "  5.00106238e-04+3.11886546e-38j  4.73394218e-04+2.95227846e-38j\n",
      "  4.25039460e-04+2.65071857e-38j  4.11051678e-04+2.56348508e-38j\n",
      "  3.95489464e-04+2.46643280e-38j  3.81904596e-04+2.38171205e-38j\n",
      "  3.50322468e-04+2.18475308e-38j  3.43095678e-04+2.13968389e-38j\n",
      "  3.30301285e-04+2.05989286e-38j  2.97571711e-04+1.85577796e-38j\n",
      "  2.78142352e-04+1.73460859e-38j  2.42324901e-04+1.51123643e-38j\n",
      "  2.30654131e-04+1.43845277e-38j  2.08241058e-04+1.29867575e-38j\n",
      "  1.72689463e-04+1.07696158e-38j  1.64652783e-04+1.02684158e-38j\n",
      "  1.63432564e-04+1.01923180e-38j  1.55099784e-04+9.67265196e-39j\n",
      "  1.43839417e-04+8.97040978e-39j  1.29980729e-04+8.10612579e-39j\n",
      "  1.24977542e-04+7.79410672e-39j  1.19993563e-04+7.48328554e-39j\n",
      "  1.04268722e-04+6.50262069e-39j  9.20738714e-05+5.74210029e-39j\n",
      "  6.88259604e-05+4.29226621e-39j  6.40872264e-05+3.99673952e-39j\n",
      "  6.00905303e-05+3.74748934e-39j  5.42906204e-05+3.38578342e-39j\n",
      "  3.22821745e-05+2.01324742e-39j  3.04690511e-05+1.90017368e-39j\n",
      "  2.86336664e-05+1.78571164e-39j  2.77965137e-05+1.73350340e-39j\n",
      "  2.56625172e-05+1.60041872e-39j  2.51032904e-05+1.56554307e-39j\n",
      "  2.09855536e-05+1.30874429e-39j  1.80153608e-05+1.12351101e-39j\n",
      "  1.37583395e-05+8.58025886e-40j  1.35464775e-05+8.44813311e-40j\n",
      "  1.31173842e-05+8.18053316e-40j  7.64370020e-06+4.76692165e-40j\n",
      "  6.95773755e-06+4.33912751e-40j  6.71024428e-06+4.18478066e-40j\n",
      "  3.02182122e-06+1.88453035e-40j  2.34745544e-06+1.46396848e-40j\n",
      "  1.45608682e-06+9.08074833e-41j  1.28381221e-06+8.00637397e-41j\n",
      "  6.80180312e-07+4.24188046e-41j  5.27574165e-09+3.29016660e-43j\n",
      "  1.27091132e-17+7.92591874e-52j  1.18311778e-17+7.37840262e-52j\n",
      "  7.22165351e-18+4.50371621e-52j  6.99612504e-18+4.36306750e-52j\n",
      "  6.04613862e-18+1.47796621e-19j  6.04613862e-18-1.47796621e-19j\n",
      "  5.65688652e-18+3.52786401e-52j  5.50187695e-18+3.43119375e-52j\n",
      "  4.91921935e-18+3.50521355e-20j  4.91921935e-18-3.50521355e-20j\n",
      "  4.67566004e-18+2.32132662e-19j  4.67566004e-18-2.32132662e-19j\n",
      "  4.57817083e-18+2.85513313e-52j  4.11395353e-18+2.56562838e-52j\n",
      "  3.89522731e-18+8.31554394e-20j  3.89522731e-18-8.31554394e-20j\n",
      "  3.58085172e-18+1.34734244e-19j  3.58085172e-18-1.34734244e-19j\n",
      "  3.55399199e-18+2.21641364e-52j  3.16549827e-18+1.97413319e-52j\n",
      "  3.11386908e-18+1.94193513e-52j  2.98443949e-18+1.86121759e-52j\n",
      "  2.95020513e-18+1.83986765e-52j  2.47527522e-18+1.46191556e-19j\n",
      "  2.47527522e-18-1.46191556e-19j  2.42621748e-18+4.89493242e-19j\n",
      "  2.42621748e-18-4.89493242e-19j  2.15818051e-18+1.34592895e-52j\n",
      "  1.77735833e-18+1.10843278e-52j  1.74209832e-18+3.82836238e-19j\n",
      "  1.74209832e-18-3.82836238e-19j  1.71827061e-18+1.07158329e-52j\n",
      "  1.48028578e-18+4.67447943e-19j  1.48028578e-18-4.67447943e-19j\n",
      "  1.15750848e-18+4.24684340e-19j  1.15750848e-18-4.24684340e-19j\n",
      "  1.02002697e-18+9.92775991e-20j  1.02002697e-18-9.92775991e-20j\n",
      "  7.02211828e-19+3.57310839e-19j  7.02211828e-19-3.57310839e-19j\n",
      "  6.98093400e-19+7.95859194e-19j  6.98093400e-19-7.95859194e-19j\n",
      "  5.44449445e-19+2.42733002e-19j  5.44449445e-19-2.42733002e-19j\n",
      "  5.23301442e-19+3.26352017e-53j  4.22991507e-19+7.66074636e-19j\n",
      "  4.22991507e-19-7.66074636e-19j  3.79894679e-19+6.23946665e-20j\n",
      "  3.79894679e-19-6.23946665e-20j  2.70833101e-19+1.68902513e-53j\n",
      "  1.66170934e-19+1.42888400e-19j  1.66170934e-19-1.42888400e-19j\n",
      "  1.43596247e-19+3.68714561e-19j  1.43596247e-19-3.68714561e-19j\n",
      "  1.24322888e-19+2.11246225e-20j  1.24322888e-19-2.11246225e-20j\n",
      "  7.44093753e-20+4.64047062e-54j  4.68412891e-20+5.22806019e-20j\n",
      "  4.68412891e-20-5.22806019e-20j  4.31260779e-20+2.68951724e-54j\n",
      "  4.29057252e-20+1.39283798e-19j  4.29057252e-20-1.39283798e-19j\n",
      "  2.79078012e-20+1.79904525e-20j  2.79078012e-20-1.79904525e-20j\n",
      "  1.39806449e-20+2.98843548e-19j  1.39806449e-20-2.98843548e-19j\n",
      "  4.50809259e-22+7.44858847e-21j  4.50809259e-22-7.44858847e-21j\n",
      "  9.06992671e-25+5.65637438e-59j  6.44110809e-33+4.01693641e-67j\n",
      "  5.91941789e-34+3.69158923e-68j  3.84933269e-34+1.08947410e-34j\n",
      "  3.84933269e-34-1.08947410e-34j  3.18894377e-34+1.52251849e-33j\n",
      "  3.18894377e-34-1.52251849e-33j  1.66860930e-34+1.04061248e-68j\n",
      "  5.81994865e-36+7.09980420e-36j  5.81994865e-36-7.09980420e-36j\n",
      "  2.10632225e-48+1.31358804e-82j -1.01087345e-34+1.27857488e-34j\n",
      " -1.01087345e-34-1.27857488e-34j -3.27418745e-34+3.26881941e-34j\n",
      " -3.27418745e-34-3.26881941e-34j -4.07491114e-34-2.54127996e-68j\n",
      " -5.67993748e-34-3.54223952e-68j -1.60853522e-33-1.00314784e-67j\n",
      " -2.71223581e-21-1.69146032e-55j -1.90581334e-20-1.18854254e-54j\n",
      " -2.52165416e-20+7.47395753e-19j -2.52165416e-20-7.47395753e-19j\n",
      " -3.52230411e-20-2.19665179e-54j -6.91954694e-20+8.58602533e-20j\n",
      " -6.91954694e-20-8.58602533e-20j -7.37779619e-20+4.52896637e-20j\n",
      " -7.37779619e-20-4.52896637e-20j -8.68317563e-20+1.16296623e-20j\n",
      " -8.68317563e-20-1.16296623e-20j -1.27000322e-19+3.45569460e-19j\n",
      " -1.27000322e-19-3.45569460e-19j -1.36039793e-19+2.12170180e-19j\n",
      " -1.36039793e-19-2.12170180e-19j -1.43916068e-19+1.41452626e-19j\n",
      " -1.43916068e-19-1.41452626e-19j -2.14489342e-19-1.33764258e-53j\n",
      " -2.45286155e-19+1.12932854e-19j -2.45286155e-19-1.12932854e-19j\n",
      " -2.74856899e-19+4.17258582e-19j -2.74856899e-19-4.17258582e-19j\n",
      " -3.65621955e-19-2.28016689e-53j -4.01571096e-19+6.10833532e-19j\n",
      " -4.01571096e-19-6.10833532e-19j -5.26135457e-19+6.32029778e-21j\n",
      " -5.26135457e-19-6.32029778e-21j -6.48699339e-19+3.20945852e-19j\n",
      " -6.48699339e-19-3.20945852e-19j -7.72539750e-19+7.88956238e-19j\n",
      " -7.72539750e-19-7.88956238e-19j -7.73075390e-19+3.72739623e-19j\n",
      " -7.73075390e-19-3.72739623e-19j -9.14553228e-19+5.72910260e-20j\n",
      " -9.14553228e-19-5.72910260e-20j -9.79072448e-19+1.48298386e-19j\n",
      " -9.79072448e-19-1.48298386e-19j -1.47592587e-18+1.00652172e-19j\n",
      " -1.47592587e-18-1.00652172e-19j -1.64613305e-18-1.02659537e-52j\n",
      " -1.83706162e-18+4.04129906e-19j -1.83706162e-18-4.04129906e-19j\n",
      " -1.95882514e-18-1.22160286e-52j -2.25957244e-18+3.76891384e-19j\n",
      " -2.25957244e-18-3.76891384e-19j -2.45776213e-18+1.68794982e-20j\n",
      " -2.45776213e-18-1.68794982e-20j -2.61261606e-18-1.62933340e-52j\n",
      " -2.79623462e-18-1.74384539e-52j -2.84032054e-18+2.02235186e-19j\n",
      " -2.84032054e-18-2.02235186e-19j -3.31188345e-18+2.22245303e-19j\n",
      " -3.31188345e-18-2.22245303e-19j -3.64792370e-18-2.27499327e-52j\n",
      " -3.78918046e-18-2.36308671e-52j -4.06282525e-18+2.74897136e-19j\n",
      " -4.06282525e-18-2.74897136e-19j -4.27791318e-18-2.66788027e-52j\n",
      " -4.45732124e-18-2.77976642e-52j -4.94638316e-18-3.08476528e-52j\n",
      " -5.19734519e-18+8.22001392e-20j -5.19734519e-18-8.22001392e-20j\n",
      " -5.59797947e-18-3.49112718e-52j -6.15523044e-18-3.83865151e-52j\n",
      " -6.50308759e-18-4.05558934e-52j -6.76121621e-18-4.21656882e-52j\n",
      " -6.93556323e-18-4.32529870e-52j -7.17599684e-18-4.47524286e-52j\n",
      " -7.65293870e-18-4.77268316e-52j -7.79761646e-18-4.86291008e-52j\n",
      " -8.53967375e-18-5.32568712e-52j -9.23173932e-18-5.75728730e-52j\n",
      " -1.16243700e-17-7.24942889e-52j -1.41815824e-17-8.84421032e-52j]\n"
     ]
    }
   ],
   "source": [
    "## PCA feature selection \n",
    "pre_train_data = x_train_processed.copy()\n",
    "\n",
    "x_pca, eig_vec, eig_val,weight = pca(pre_train_data, 200)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6093, 200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivonne/.local/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:1340: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.asarray(x, float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb14c9a3760>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cummulation = np.cumsum(weight)\n",
    "cummulation\n",
    "plt.plot(cummulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6093, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/499: loss=0.06394634915180893\n",
      "GD iter. 10/499: loss=0.03961391798968512\n",
      "GD iter. 20/499: loss=0.038320730961004426\n",
      "GD iter. 30/499: loss=0.037499733991507335\n",
      "GD iter. 40/499: loss=0.036915451129429094\n",
      "GD iter. 50/499: loss=0.03647201929627528\n",
      "GD iter. 60/499: loss=0.036120910228329375\n",
      "GD iter. 70/499: loss=0.03583407179388655\n",
      "GD iter. 80/499: loss=0.03559397625899747\n",
      "GD iter. 90/499: loss=0.03538908101728824\n",
      "GD iter. 100/499: loss=0.03521146274871529\n",
      "GD iter. 110/499: loss=0.03505548636346044\n",
      "GD iter. 120/499: loss=0.03491701924052287\n",
      "GD iter. 130/499: loss=0.034792949896194726\n",
      "GD iter. 140/499: loss=0.03468088312000202\n",
      "GD iter. 150/499: loss=0.034578940554541256\n",
      "GD iter. 160/499: loss=0.03448562612025759\n",
      "GD iter. 170/499: loss=0.03439973249642951\n",
      "GD iter. 180/499: loss=0.034320274375879485\n",
      "GD iter. 190/499: loss=0.03424643969606625\n",
      "GD iter. 200/499: loss=0.03417755327930504\n",
      "GD iter. 210/499: loss=0.034113049259400195\n",
      "GD iter. 220/499: loss=0.03405244987111798\n",
      "GD iter. 230/499: loss=0.03399534893769622\n",
      "GD iter. 240/499: loss=0.03394139888466709\n",
      "GD iter. 250/499: loss=0.03389030043729542\n",
      "GD iter. 260/499: loss=0.033841794384120674\n",
      "GD iter. 270/499: loss=0.03379565494684234\n",
      "GD iter. 280/499: loss=0.03375168440962071\n",
      "GD iter. 290/499: loss=0.03370970874303977\n",
      "GD iter. 300/499: loss=0.033669574018755345\n",
      "GD iter. 310/499: loss=0.03363114345639256\n",
      "GD iter. 320/499: loss=0.03359429497875719\n",
      "GD iter. 330/499: loss=0.03355891917780761\n",
      "GD iter. 340/499: loss=0.03352491761416737\n",
      "GD iter. 350/499: loss=0.03349220138873986\n",
      "GD iter. 360/499: loss=0.03346068993730741\n",
      "GD iter. 370/499: loss=0.03343031000867088\n",
      "GD iter. 380/499: loss=0.033400994794516276\n",
      "GD iter. 390/499: loss=0.03337268318524336\n",
      "GD iter. 400/499: loss=0.03334531913080464\n",
      "GD iter. 410/499: loss=0.03331885108945032\n",
      "GD iter. 420/499: loss=0.03329323155036103\n",
      "GD iter. 430/499: loss=0.033268416618635555\n",
      "GD iter. 440/499: loss=0.03324436565310993\n",
      "GD iter. 450/499: loss=0.03322104094911343\n",
      "GD iter. 460/499: loss=0.03319840745959387\n",
      "GD iter. 470/499: loss=0.033176432549127784\n",
      "GD iter. 480/499: loss=0.033155085776219534\n",
      "GD iter. 490/499: loss=0.03313433870002326\n",
      "The Accuracy is: 0.6236\n",
      "The F1 score is: 0.2767\n",
      "The precision is: 0.1624\n",
      "The recall is: 0.9362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27672955974842767"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## linear regression using all the features except for those having NaN values over 50% ##\n",
    "x_t, y_t, x_v, y_v = split_data(add_bias(x_train_processed), y_train_processed, 0.9)\n",
    "# x_t, y_t = data_augmentation(x_t, y_t)\n",
    "initial_w = np.random.randn(x_t.shape[1]) * 0.01\n",
    "w, loss = mean_square_error_gd(y_t, x_t, initial_w, max_iters=500, gamma=0.01)\n",
    "y_pred = x_v @ w\n",
    "y_pred_mean = np.mean(y_pred)\n",
    "y_pred = (y_pred > y_pred_mean).astype(int)\n",
    "predict_acc_pure(y_pred, y_v)\n",
    "predict_f1_pure(y_pred, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6093, 446)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/499: loss=0.7077207253086517\n",
      "GD iter. 1/499: loss=0.5504003964501993\n",
      "GD iter. 2/499: loss=0.5328991040001598\n",
      "GD iter. 3/499: loss=0.523618274201921\n",
      "GD iter. 4/499: loss=0.5169128907141344\n",
      "GD iter. 5/499: loss=0.5114694869024743\n",
      "GD iter. 6/499: loss=0.5068135380469915\n",
      "GD iter. 7/499: loss=0.5027148388779595\n",
      "GD iter. 8/499: loss=0.49903750717093687\n",
      "GD iter. 9/499: loss=0.49569148737380253\n",
      "GD iter. 10/499: loss=0.4926130762662449\n",
      "GD iter. 11/499: loss=0.4897554310139592\n",
      "GD iter. 12/499: loss=0.48708319660399824\n",
      "GD iter. 13/499: loss=0.4845691488492277\n",
      "GD iter. 14/499: loss=0.4821919660195744\n",
      "GD iter. 15/499: loss=0.47993469317199294\n",
      "GD iter. 16/499: loss=0.47778365692880004\n",
      "GD iter. 17/499: loss=0.4757276841343601\n",
      "GD iter. 18/499: loss=0.47375753070307736\n",
      "GD iter. 19/499: loss=0.4718654585931703\n",
      "GD iter. 20/499: loss=0.4700449187563622\n",
      "GD iter. 21/499: loss=0.4682903108985622\n",
      "GD iter. 22/499: loss=0.4665967995626002\n",
      "GD iter. 23/499: loss=0.46496017195032163\n",
      "GD iter. 24/499: loss=0.46337672698397186\n",
      "GD iter. 25/499: loss=0.46184318796616936\n",
      "GD iter. 26/499: loss=0.4603566332239545\n",
      "GD iter. 27/499: loss=0.45891444057352565\n",
      "GD iter. 28/499: loss=0.45751424249176936\n",
      "GD iter. 29/499: loss=0.4561538896466642\n",
      "GD iter. 30/499: loss=0.45483142100248314\n",
      "GD iter. 31/499: loss=0.4535450391340997\n",
      "GD iter. 32/499: loss=0.45229308969754073\n",
      "GD iter. 33/499: loss=0.45107404423951786\n",
      "GD iter. 34/499: loss=0.44988648570733086\n",
      "GD iter. 35/499: loss=0.4487290961569137\n",
      "GD iter. 36/499: loss=0.4476006462615546\n",
      "GD iter. 37/499: loss=0.4464999863048053\n",
      "GD iter. 38/499: loss=0.4454260384040555\n",
      "GD iter. 39/499: loss=0.44437778976049574\n",
      "GD iter. 40/499: loss=0.44335428676992356\n",
      "GD iter. 41/499: loss=0.44235462985948176\n",
      "GD iter. 42/499: loss=0.4413779689397862\n",
      "GD iter. 43/499: loss=0.4404234993813692\n",
      "GD iter. 44/499: loss=0.4394904584400337\n",
      "GD iter. 45/499: loss=0.43857812206835256\n",
      "GD iter. 46/499: loss=0.437685802060826\n",
      "GD iter. 47/499: loss=0.4368128434885909\n",
      "GD iter. 48/499: loss=0.43595862238645094\n",
      "GD iter. 49/499: loss=0.4351225436606622\n",
      "GD iter. 50/499: loss=0.4343040391905988\n",
      "GD iter. 51/499: loss=0.4335025661013163\n",
      "GD iter. 52/499: loss=0.4327176051872981\n",
      "GD iter. 53/499: loss=0.43194865947038424\n",
      "GD iter. 54/499: loss=0.4311952528771961\n",
      "GD iter. 55/499: loss=0.43045692902330085\n",
      "GD iter. 56/499: loss=0.429733250093013\n",
      "GD iter. 57/499: loss=0.4290237958051324\n",
      "GD iter. 58/499: loss=0.42832816245611294\n",
      "GD iter. 59/499: loss=0.42764596203318905\n",
      "GD iter. 60/499: loss=0.42697682139086246\n",
      "GD iter. 61/499: loss=0.4263203814849191\n",
      "GD iter. 62/499: loss=0.4256762966588044\n",
      "GD iter. 63/499: loss=0.42504423397775276\n",
      "GD iter. 64/499: loss=0.4244238726065688\n",
      "GD iter. 65/499: loss=0.42381490322739096\n",
      "GD iter. 66/499: loss=0.4232170274941488\n",
      "GD iter. 67/499: loss=0.42262995752075583\n",
      "GD iter. 68/499: loss=0.42205341540037766\n",
      "GD iter. 69/499: loss=0.4214871327533712\n",
      "GD iter. 70/499: loss=0.42093085030172017\n",
      "GD iter. 71/499: loss=0.4203843174679963\n",
      "GD iter. 72/499: loss=0.41984729199705506\n",
      "GD iter. 73/499: loss=0.4193195395988347\n",
      "GD iter. 74/499: loss=0.41880083361077436\n",
      "GD iter. 75/499: loss=0.41829095467849137\n",
      "GD iter. 76/499: loss=0.41778969045347614\n",
      "GD iter. 77/499: loss=0.417296835306665\n",
      "GD iter. 78/499: loss=0.4168121900568462\n",
      "GD iter. 79/499: loss=0.4163355617129364\n",
      "GD iter. 80/499: loss=0.4158667632292434\n",
      "GD iter. 81/499: loss=0.41540561327289854\n",
      "GD iter. 82/499: loss=0.41495193600270436\n",
      "GD iter. 83/499: loss=0.4145055608587029\n",
      "GD iter. 84/499: loss=0.4140663223618159\n",
      "GD iter. 85/499: loss=0.41363405992296376\n",
      "GD iter. 86/499: loss=0.4132086176611046\n",
      "GD iter. 87/499: loss=0.41278984422968124\n",
      "GD iter. 88/499: loss=0.412377592650995\n",
      "GD iter. 89/499: loss=0.41197172015806205\n",
      "GD iter. 90/499: loss=0.4115720880435359\n",
      "GD iter. 91/499: loss=0.4111785615153088\n",
      "GD iter. 92/499: loss=0.4107910095584309\n",
      "GD iter. 93/499: loss=0.41040930480300797\n",
      "GD iter. 94/499: loss=0.4100333233977629\n",
      "GD iter. 95/499: loss=0.4096629448889641\n",
      "GD iter. 96/499: loss=0.40929805210444437\n",
      "GD iter. 97/499: loss=0.4089385310424495\n",
      "GD iter. 98/499: loss=0.4085842707650736\n",
      "GD iter. 99/499: loss=0.4082351632960512\n",
      "GD iter. 100/499: loss=0.4078911035226914\n",
      "GD iter. 101/499: loss=0.4075519891017522\n",
      "GD iter. 102/499: loss=0.407217720369062\n",
      "GD iter. 103/499: loss=0.40688820025271283\n",
      "GD iter. 104/499: loss=0.40656333418965196\n",
      "GD iter. 105/499: loss=0.4062430300455145\n",
      "GD iter. 106/499: loss=0.40592719803754684\n",
      "GD iter. 107/499: loss=0.4056157506604767\n",
      "GD iter. 108/499: loss=0.4053086026151978\n",
      "GD iter. 109/499: loss=0.40500567074013877\n",
      "GD iter. 110/499: loss=0.404706873945201\n",
      "GD iter. 111/499: loss=0.4044121331481444\n",
      "GD iter. 112/499: loss=0.4041213712133215\n",
      "GD iter. 113/499: loss=0.40383451289265043\n",
      "GD iter. 114/499: loss=0.4035514847687345\n",
      "GD iter. 115/499: loss=0.40327221520003304\n",
      "GD iter. 116/499: loss=0.4029966342679995\n",
      "GD iter. 117/499: loss=0.40272467372610066\n",
      "GD iter. 118/499: loss=0.4024562669506399\n",
      "GD iter. 119/499: loss=0.40219134889330965\n",
      "GD iter. 120/499: loss=0.4019298560353995\n",
      "GD iter. 121/499: loss=0.4016717263435957\n",
      "GD iter. 122/499: loss=0.4014168992273037\n",
      "GD iter. 123/499: loss=0.4011653154974347\n",
      "GD iter. 124/499: loss=0.40091691732659634\n",
      "GD iter. 125/499: loss=0.40067164821063184\n",
      "GD iter. 126/499: loss=0.40042945293145427\n",
      "GD iter. 127/499: loss=0.4001902775211255\n",
      "GD iter. 128/499: loss=0.39995406922712945\n",
      "GD iter. 129/499: loss=0.3997207764787961\n",
      "GD iter. 130/499: loss=0.39949034885482915\n",
      "GD iter. 131/499: loss=0.3992627370518972\n",
      "GD iter. 132/499: loss=0.3990378928542456\n",
      "GD iter. 133/499: loss=0.39881576910429317\n",
      "GD iter. 134/499: loss=0.3985963196741739\n",
      "GD iter. 135/499: loss=0.39837949943819023\n",
      "GD iter. 136/499: loss=0.39816526424614335\n",
      "GD iter. 137/499: loss=0.3979535708975071\n",
      "GD iter. 138/499: loss=0.3977443771164163\n",
      "GD iter. 139/499: loss=0.39753764152743826\n",
      "GD iter. 140/499: loss=0.3973333236320994\n",
      "GD iter. 141/499: loss=0.39713138378613955\n",
      "GD iter. 142/499: loss=0.39693178317746775\n",
      "GD iter. 143/499: loss=0.396734483804795\n",
      "GD iter. 144/499: loss=0.3965394484569186\n",
      "GD iter. 145/499: loss=0.39634664069263564\n",
      "GD iter. 146/499: loss=0.39615602482126444\n",
      "GD iter. 147/499: loss=0.3959675658837503\n",
      "GD iter. 148/499: loss=0.3957812296343377\n",
      "GD iter. 149/499: loss=0.3955969825227868\n",
      "GD iter. 150/499: loss=0.395414791677118\n",
      "GD iter. 151/499: loss=0.3952346248868641\n",
      "GD iter. 152/499: loss=0.39505645058681393\n",
      "GD iter. 153/499: loss=0.3948802378412306\n",
      "GD iter. 154/499: loss=0.394705956328528\n",
      "GD iter. 155/499: loss=0.39453357632638975\n",
      "GD iter. 156/499: loss=0.394363068697317\n",
      "GD iter. 157/499: loss=0.3941944048745895\n",
      "GD iter. 158/499: loss=0.3940275568486263\n",
      "GD iter. 159/499: loss=0.3938624971537337\n",
      "GD iter. 160/499: loss=0.3936991988552271\n",
      "GD iter. 161/499: loss=0.3935376355369142\n",
      "GD iter. 162/499: loss=0.3933777812889286\n",
      "GD iter. 163/499: loss=0.39321961069590156\n",
      "GD iter. 164/499: loss=0.3930630988254614\n",
      "GD iter. 165/499: loss=0.39290822121705027\n",
      "GD iter. 166/499: loss=0.39275495387104725\n",
      "GD iter. 167/499: loss=0.39260327323818933\n",
      "GD iter. 168/499: loss=0.39245315620927923\n",
      "GD iter. 169/499: loss=0.39230458010517255\n",
      "GD iter. 170/499: loss=0.3921575226670341\n",
      "GD iter. 171/499: loss=0.3920119620468559\n",
      "GD iter. 172/499: loss=0.3918678767982288\n",
      "GD iter. 173/499: loss=0.39172524586735896\n",
      "GD iter. 174/499: loss=0.3915840485843218\n",
      "GD iter. 175/499: loss=0.39144426465454746\n",
      "GD iter. 176/499: loss=0.391305874150529\n",
      "GD iter. 177/499: loss=0.3911688575037469\n",
      "GD iter. 178/499: loss=0.3910331954968049\n",
      "GD iter. 179/499: loss=0.3908988692557678\n",
      "GD iter. 180/499: loss=0.39076586024269844\n",
      "GD iter. 181/499: loss=0.39063415024838494\n",
      "GD iter. 182/499: loss=0.39050372138525524\n",
      "GD iter. 183/499: loss=0.3903745560804709\n",
      "GD iter. 184/499: loss=0.3902466370691971\n",
      "GD iter. 185/499: loss=0.3901199473880411\n",
      "GD iter. 186/499: loss=0.38999447036865736\n",
      "GD iter. 187/499: loss=0.3898701896315121\n",
      "GD iter. 188/499: loss=0.38974708907980227\n",
      "GD iter. 189/499: loss=0.3896251528935278\n",
      "GD iter. 190/499: loss=0.38950436552370826\n",
      "GD iter. 191/499: loss=0.38938471168674416\n",
      "GD iter. 192/499: loss=0.3892661763589138\n",
      "GD iter. 193/499: loss=0.38914874477100797\n",
      "GD iter. 194/499: loss=0.3890324024030926\n",
      "GD iter. 195/499: loss=0.3889171349793994\n",
      "GD iter. 196/499: loss=0.3888029284633401\n",
      "GD iter. 197/499: loss=0.38868976905264047\n",
      "GD iter. 198/499: loss=0.3885776431745906\n",
      "GD iter. 199/499: loss=0.3884665374814091\n",
      "GD iter. 200/499: loss=0.3883564388457171\n",
      "GD iter. 201/499: loss=0.3882473343561197\n",
      "GD iter. 202/499: loss=0.3881392113128918\n",
      "GD iter. 203/499: loss=0.3880320572237652\n",
      "GD iter. 204/499: loss=0.3879258597998141\n",
      "GD iter. 205/499: loss=0.38782060695143705\n",
      "GD iter. 206/499: loss=0.38771628678443254\n",
      "GD iter. 207/499: loss=0.38761288759616475\n",
      "GD iter. 208/499: loss=0.38751039787181796\n",
      "GD iter. 209/499: loss=0.38740880628073776\n",
      "GD iter. 210/499: loss=0.38730810167285534\n",
      "GD iter. 211/499: loss=0.38720827307519384\n",
      "GD iter. 212/499: loss=0.38710930968845364\n",
      "GD iter. 213/499: loss=0.3870112008836758\n",
      "GD iter. 214/499: loss=0.38691393619898035\n",
      "GD iter. 215/499: loss=0.38681750533637765\n",
      "GD iter. 216/499: loss=0.3867218981586523\n",
      "GD iter. 217/499: loss=0.38662710468631584\n",
      "GD iter. 218/499: loss=0.38653311509462734\n",
      "GD iter. 219/499: loss=0.3864399197106803\n",
      "GD iter. 220/499: loss=0.3863475090105543\n",
      "GD iter. 221/499: loss=0.38625587361652897\n",
      "GD iter. 222/499: loss=0.3861650042943587\n",
      "GD iter. 223/499: loss=0.38607489195060857\n",
      "GD iter. 224/499: loss=0.38598552763004657\n",
      "GD iter. 225/499: loss=0.38589690251309366\n",
      "GD iter. 226/499: loss=0.38580900791332906\n",
      "GD iter. 227/499: loss=0.38572183527504833\n",
      "GD iter. 228/499: loss=0.38563537617087573\n",
      "GD iter. 229/499: loss=0.38554962229942624\n",
      "GD iter. 230/499: loss=0.38546456548301833\n",
      "GD iter. 231/499: loss=0.3853801976654357\n",
      "GD iter. 232/499: loss=0.3852965109097359\n",
      "GD iter. 233/499: loss=0.3852134973961057\n",
      "GD iter. 234/499: loss=0.38513114941976195\n",
      "GD iter. 235/499: loss=0.3850494593888959\n",
      "GD iter. 236/499: loss=0.38496841982266194\n",
      "GD iter. 237/499: loss=0.38488802334920647\n",
      "GD iter. 238/499: loss=0.38480826270373986\n",
      "GD iter. 239/499: loss=0.38472913072664683\n",
      "GD iter. 240/499: loss=0.3846506203616372\n",
      "GD iter. 241/499: loss=0.3845727246539339\n",
      "GD iter. 242/499: loss=0.3844954367484987\n",
      "GD iter. 243/499: loss=0.38441874988829455\n",
      "GD iter. 244/499: loss=0.3843426574125827\n",
      "GD iter. 245/499: loss=0.38426715275525536\n",
      "GD iter. 246/499: loss=0.3841922294432018\n",
      "GD iter. 247/499: loss=0.3841178810947079\n",
      "GD iter. 248/499: loss=0.3840441014178872\n",
      "GD iter. 249/499: loss=0.38397088420914494\n",
      "GD iter. 250/499: loss=0.3838982233516714\n",
      "GD iter. 251/499: loss=0.3838261128139668\n",
      "GD iter. 252/499: loss=0.3837545466483943\n",
      "GD iter. 253/499: loss=0.3836835189897633\n",
      "GD iter. 254/499: loss=0.38361302405393927\n",
      "GD iter. 255/499: loss=0.3835430561364826\n",
      "GD iter. 256/499: loss=0.3834736096113125\n",
      "GD iter. 257/499: loss=0.3834046789293995\n",
      "GD iter. 258/499: loss=0.3833362586174811\n",
      "GD iter. 259/499: loss=0.3832683432768047\n",
      "GD iter. 260/499: loss=0.38320092758189317\n",
      "GD iter. 261/499: loss=0.38313400627933614\n",
      "GD iter. 262/499: loss=0.38306757418660325\n",
      "GD iter. 263/499: loss=0.38300162619088135\n",
      "GD iter. 264/499: loss=0.38293615724793356\n",
      "GD iter. 265/499: loss=0.3828711623809801\n",
      "GD iter. 266/499: loss=0.3828066366796018\n",
      "GD iter. 267/499: loss=0.3827425752986621\n",
      "GD iter. 268/499: loss=0.3826789734572528\n",
      "GD iter. 269/499: loss=0.382615826437657\n",
      "GD iter. 270/499: loss=0.3825531295843329\n",
      "GD iter. 271/499: loss=0.3824908783029174\n",
      "GD iter. 272/499: loss=0.3824290680592471\n",
      "GD iter. 273/499: loss=0.3823676943783985\n",
      "GD iter. 274/499: loss=0.3823067528437463\n",
      "GD iter. 275/499: loss=0.382246239096039\n",
      "GD iter. 276/499: loss=0.3821861488324913\n",
      "GD iter. 277/499: loss=0.3821264778058943\n",
      "GD iter. 278/499: loss=0.38206722182374153\n",
      "GD iter. 279/499: loss=0.38200837674737115\n",
      "GD iter. 280/499: loss=0.3819499384911243\n",
      "GD iter. 281/499: loss=0.3818919030215185\n",
      "GD iter. 282/499: loss=0.3818342663564365\n",
      "GD iter. 283/499: loss=0.38177702456432966\n",
      "GD iter. 284/499: loss=0.38172017376343625\n",
      "GD iter. 285/499: loss=0.3816637101210138\n",
      "GD iter. 286/499: loss=0.3816076298525848\n",
      "GD iter. 287/499: loss=0.3815519292211967\n",
      "GD iter. 288/499: loss=0.3814966045366955\n",
      "GD iter. 289/499: loss=0.3814416521550115\n",
      "GD iter. 290/499: loss=0.3813870684774585\n",
      "GD iter. 291/499: loss=0.3813328499500452\n",
      "GD iter. 292/499: loss=0.3812789930627989\n",
      "GD iter. 293/499: loss=0.3812254943491021\n",
      "GD iter. 294/499: loss=0.3811723503850389\n",
      "GD iter. 295/499: loss=0.38111955778875545\n",
      "GD iter. 296/499: loss=0.3810671132198294\n",
      "GD iter. 297/499: loss=0.3810150133786522\n",
      "GD iter. 298/499: loss=0.3809632550058209\n",
      "GD iter. 299/499: loss=0.3809118348815417\n",
      "GD iter. 300/499: loss=0.3808607498250429\n",
      "GD iter. 301/499: loss=0.38080999669399934\n",
      "GD iter. 302/499: loss=0.38075957238396535\n",
      "GD iter. 303/499: loss=0.38070947382781845\n",
      "GD iter. 304/499: loss=0.3806596979952127\n",
      "GD iter. 305/499: loss=0.3806102418920411\n",
      "GD iter. 306/499: loss=0.3805611025599074\n",
      "GD iter. 307/499: loss=0.3805122770756068\n",
      "GD iter. 308/499: loss=0.3804637625506159\n",
      "GD iter. 309/499: loss=0.3804155561305909\n",
      "GD iter. 310/499: loss=0.38036765499487496\n",
      "GD iter. 311/499: loss=0.3803200563560128\n",
      "GD iter. 312/499: loss=0.3802727574592751\n",
      "GD iter. 313/499: loss=0.3802257555821893\n",
      "GD iter. 314/499: loss=0.3801790480340797\n",
      "GD iter. 315/499: loss=0.38013263215561444\n",
      "GD iter. 316/499: loss=0.3800865053183598\n",
      "GD iter. 317/499: loss=0.3800406649243434\n",
      "GD iter. 318/499: loss=0.3799951084056229\n",
      "GD iter. 319/499: loss=0.3799498332238632\n",
      "GD iter. 320/499: loss=0.3799048368699199\n",
      "GD iter. 321/499: loss=0.37986011686343\n",
      "GD iter. 322/499: loss=0.37981567075240924\n",
      "GD iter. 323/499: loss=0.3797714961128562\n",
      "GD iter. 324/499: loss=0.37972759054836275\n",
      "GD iter. 325/499: loss=0.3796839516897308\n",
      "GD iter. 326/499: loss=0.3796405771945955\n",
      "GD iter. 327/499: loss=0.37959746474705497\n",
      "GD iter. 328/499: loss=0.379554612057305\n",
      "GD iter. 329/499: loss=0.3795120168612803\n",
      "GD iter. 330/499: loss=0.3794696769203024\n",
      "GD iter. 331/499: loss=0.37942759002073156\n",
      "GD iter. 332/499: loss=0.3793857539736251\n",
      "GD iter. 333/499: loss=0.37934416661440207\n",
      "GD iter. 334/499: loss=0.3793028258025113\n",
      "GD iter. 335/499: loss=0.3792617294211071\n",
      "GD iter. 336/499: loss=0.3792208753767279\n",
      "GD iter. 337/499: loss=0.379180261598982\n",
      "GD iter. 338/499: loss=0.37913988604023663\n",
      "GD iter. 339/499: loss=0.37909974667531326\n",
      "GD iter. 340/499: loss=0.37905984150118655\n",
      "GD iter. 341/499: loss=0.3790201685366892\n",
      "GD iter. 342/499: loss=0.37898072582222064\n",
      "GD iter. 343/499: loss=0.3789415114194605\n",
      "GD iter. 344/499: loss=0.3789025234110865\n",
      "GD iter. 345/499: loss=0.37886375990049725\n",
      "GD iter. 346/499: loss=0.37882521901153854\n",
      "GD iter. 347/499: loss=0.3787868988882344\n",
      "GD iter. 348/499: loss=0.3787487976945224\n",
      "GD iter. 349/499: loss=0.3787109136139928\n",
      "GD iter. 350/499: loss=0.37867324484963166\n",
      "GD iter. 351/499: loss=0.3786357896235683\n",
      "GD iter. 352/499: loss=0.3785985461768263\n",
      "GD iter. 353/499: loss=0.3785615127690782\n",
      "GD iter. 354/499: loss=0.37852468767840436\n",
      "GD iter. 355/499: loss=0.37848806920105543\n",
      "GD iter. 356/499: loss=0.378451655651218\n",
      "GD iter. 357/499: loss=0.3784154453607844\n",
      "GD iter. 358/499: loss=0.3783794366791253\n",
      "GD iter. 359/499: loss=0.3783436279728666\n",
      "GD iter. 360/499: loss=0.3783080176256689\n",
      "GD iter. 361/499: loss=0.37827260403801083\n",
      "GD iter. 362/499: loss=0.37823738562697534\n",
      "GD iter. 363/499: loss=0.3782023608260391\n",
      "GD iter. 364/499: loss=0.37816752808486553\n",
      "GD iter. 365/499: loss=0.3781328858691005\n",
      "GD iter. 366/499: loss=0.3780984326601707\n",
      "GD iter. 367/499: loss=0.3780641669550865\n",
      "GD iter. 368/499: loss=0.3780300872662457\n",
      "GD iter. 369/499: loss=0.3779961921212418\n",
      "GD iter. 370/499: loss=0.3779624800626741\n",
      "GD iter. 371/499: loss=0.37792894964796103\n",
      "GD iter. 372/499: loss=0.37789559944915657\n",
      "GD iter. 373/499: loss=0.37786242805276854\n",
      "GD iter. 374/499: loss=0.3778294340595799\n",
      "GD iter. 375/499: loss=0.37779661608447307\n",
      "GD iter. 376/499: loss=0.37776397275625634\n",
      "GD iter. 377/499: loss=0.3777315027174924\n",
      "GD iter. 378/499: loss=0.3776992046243307\n",
      "GD iter. 379/499: loss=0.37766707714634085\n",
      "GD iter. 380/499: loss=0.3776351189663488\n",
      "GD iter. 381/499: loss=0.37760332878027636\n",
      "GD iter. 382/499: loss=0.3775717052969813\n",
      "GD iter. 383/499: loss=0.3775402472381009\n",
      "GD iter. 384/499: loss=0.37750895333789813\n",
      "GD iter. 385/499: loss=0.3774778223431081\n",
      "GD iter. 386/499: loss=0.3774468530127893\n",
      "GD iter. 387/499: loss=0.3774160441181748\n",
      "GD iter. 388/499: loss=0.37738539444252656\n",
      "GD iter. 389/499: loss=0.3773549027809917\n",
      "GD iter. 390/499: loss=0.3773245679404607\n",
      "GD iter. 391/499: loss=0.3772943887394277\n",
      "GD iter. 392/499: loss=0.3772643640078523\n",
      "GD iter. 393/499: loss=0.37723449258702413\n",
      "GD iter. 394/499: loss=0.3772047733294285\n",
      "GD iter. 395/499: loss=0.37717520509861463\n",
      "GD iter. 396/499: loss=0.37714578676906524\n",
      "GD iter. 397/499: loss=0.37711651722606787\n",
      "GD iter. 398/499: loss=0.37708739536558816\n",
      "GD iter. 399/499: loss=0.3770584200941454\n",
      "GD iter. 400/499: loss=0.3770295903286889\n",
      "GD iter. 401/499: loss=0.37700090499647665\n",
      "GD iter. 402/499: loss=0.3769723630349553\n",
      "GD iter. 403/499: loss=0.3769439633916422\n",
      "GD iter. 404/499: loss=0.37691570502400856\n",
      "GD iter. 405/499: loss=0.3768875868993648\n",
      "GD iter. 406/499: loss=0.37685960799474666\n",
      "GD iter. 407/499: loss=0.37683176729680395\n",
      "GD iter. 408/499: loss=0.37680406380168946\n",
      "GD iter. 409/499: loss=0.3767764965149509\n",
      "GD iter. 410/499: loss=0.37674906445142264\n",
      "GD iter. 411/499: loss=0.3767217666351207\n",
      "GD iter. 412/499: loss=0.37669460209913724\n",
      "GD iter. 413/499: loss=0.37666756988553846\n",
      "GD iter. 414/499: loss=0.37664066904526217\n",
      "GD iter. 415/499: loss=0.3766138986380175\n",
      "GD iter. 416/499: loss=0.3765872577321862\n",
      "GD iter. 417/499: loss=0.37656074540472484\n",
      "GD iter. 418/499: loss=0.37653436074106805\n",
      "GD iter. 419/499: loss=0.37650810283503394\n",
      "GD iter. 420/499: loss=0.37648197078872975\n",
      "GD iter. 421/499: loss=0.3764559637124595\n",
      "GD iter. 422/499: loss=0.3764300807246325\n",
      "GD iter. 423/499: loss=0.37640432095167314\n",
      "GD iter. 424/499: loss=0.37637868352793225\n",
      "GD iter. 425/499: loss=0.37635316759559834\n",
      "GD iter. 426/499: loss=0.37632777230461195\n",
      "GD iter. 427/499: loss=0.3763024968125794\n",
      "GD iter. 428/499: loss=0.3762773402846884\n",
      "GD iter. 429/499: loss=0.3762523018936253\n",
      "GD iter. 430/499: loss=0.37622738081949203\n",
      "GD iter. 431/499: loss=0.3762025762497253\n",
      "GD iter. 432/499: loss=0.3761778873790163\n",
      "GD iter. 433/499: loss=0.37615331340923197\n",
      "GD iter. 434/499: loss=0.37612885354933634\n",
      "GD iter. 435/499: loss=0.37610450701531367\n",
      "GD iter. 436/499: loss=0.3760802730300926\n",
      "GD iter. 437/499: loss=0.37605615082347055\n",
      "GD iter. 438/499: loss=0.37603213963203996\n",
      "GD iter. 439/499: loss=0.37600823869911476\n",
      "GD iter. 440/499: loss=0.37598444727465813\n",
      "GD iter. 441/499: loss=0.37596076461521155\n",
      "GD iter. 442/499: loss=0.37593718998382364\n",
      "GD iter. 443/499: loss=0.375913722649981\n",
      "GD iter. 444/499: loss=0.3758903618895394\n",
      "GD iter. 445/499: loss=0.37586710698465603\n",
      "GD iter. 446/499: loss=0.3758439572237225\n",
      "GD iter. 447/499: loss=0.37582091190129846\n",
      "GD iter. 448/499: loss=0.37579797031804674\n",
      "GD iter. 449/499: loss=0.37577513178066835\n",
      "GD iter. 450/499: loss=0.37575239560183926\n",
      "GD iter. 451/499: loss=0.37572976110014716\n",
      "GD iter. 452/499: loss=0.37570722760002945\n",
      "GD iter. 453/499: loss=0.37568479443171193\n",
      "GD iter. 454/499: loss=0.3756624609311483\n",
      "GD iter. 455/499: loss=0.37564022643996\n",
      "GD iter. 456/499: loss=0.37561809030537746\n",
      "GD iter. 457/499: loss=0.3755960518801818\n",
      "GD iter. 458/499: loss=0.37557411052264666\n",
      "GD iter. 459/499: loss=0.3755522655964818\n",
      "GD iter. 460/499: loss=0.3755305164707764\n",
      "GD iter. 461/499: loss=0.375508862519944\n",
      "GD iter. 462/499: loss=0.3754873031236672\n",
      "GD iter. 463/499: loss=0.3754658376668435\n",
      "GD iter. 464/499: loss=0.3754444655395323\n",
      "GD iter. 465/499: loss=0.37542318613690084\n",
      "GD iter. 466/499: loss=0.37540199885917325\n",
      "GD iter. 467/499: loss=0.37538090311157796\n",
      "GD iter. 468/499: loss=0.37535989830429717\n",
      "GD iter. 469/499: loss=0.3753389838524161\n",
      "GD iter. 470/499: loss=0.37531815917587374\n",
      "GD iter. 471/499: loss=0.37529742369941327\n",
      "GD iter. 472/499: loss=0.37527677685253313\n",
      "GD iter. 473/499: loss=0.3752562180694398\n",
      "GD iter. 474/499: loss=0.3752357467889999\n",
      "GD iter. 475/499: loss=0.37521536245469306\n",
      "GD iter. 476/499: loss=0.3751950645145662\n",
      "GD iter. 477/499: loss=0.37517485242118714\n",
      "GD iter. 478/499: loss=0.3751547256315999\n",
      "GD iter. 479/499: loss=0.37513468360727964\n",
      "GD iter. 480/499: loss=0.37511472581408845\n",
      "GD iter. 481/499: loss=0.37509485172223195\n",
      "GD iter. 482/499: loss=0.3750750608062161\n",
      "GD iter. 483/499: loss=0.3750553525448045\n",
      "GD iter. 484/499: loss=0.375035726420976\n",
      "GD iter. 485/499: loss=0.37501618192188363\n",
      "GD iter. 486/499: loss=0.3749967185388129\n",
      "GD iter. 487/499: loss=0.37497733576714165\n",
      "GD iter. 488/499: loss=0.374958033106299\n",
      "GD iter. 489/499: loss=0.3749388100597268\n",
      "GD iter. 490/499: loss=0.3749196661348392\n",
      "GD iter. 491/499: loss=0.37490060084298454\n",
      "GD iter. 492/499: loss=0.3748816136994068\n",
      "GD iter. 493/499: loss=0.3748627042232076\n",
      "GD iter. 494/499: loss=0.37484387193730867\n",
      "GD iter. 495/499: loss=0.374825116368415\n",
      "GD iter. 496/499: loss=0.3748064370469778\n",
      "GD iter. 497/499: loss=0.3747878335071588\n",
      "GD iter. 498/499: loss=0.3747693052867941\n",
      "GD iter. 499/499: loss=0.37475085192735874\n",
      "The Accuracy is: 0.8443\n",
      "The F1 score is: 0.3357\n",
      "The precision is: 0.2553\n",
      "The recall is: 0.4898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3356643356643356"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression using all the features except for those having NaN values over 50% ##\n",
    "x_t, y_t, x_v, y_v = split_data(add_bias(x_train_processed), y_train_processed, 0.9)\n",
    "x_t, y_t = data_augmentation(x_t, y_t)\n",
    "initial_w = np.random.randn(x_t.shape[1]) * 0.01\n",
    "w, loss = logistic_regression(y_t, x_t, initial_w, max_iters=500, gamma=0.1)\n",
    "y_pred = sigmoid(x_v @ w)\n",
    "y_pred = (y_pred >= 0.7).astype(int)\n",
    "predict_acc_pure(y_pred, y_v)\n",
    "predict_f1_pure(y_pred, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/499: loss=0.6841652468260004\n",
      "GD iter. 1/499: loss=0.537219050339916\n",
      "GD iter. 2/499: loss=0.5245618808876236\n",
      "GD iter. 3/499: loss=0.516075298782938\n",
      "GD iter. 4/499: loss=0.5095856970366582\n",
      "GD iter. 5/499: loss=0.5043150077699387\n",
      "GD iter. 6/499: loss=0.49987862532614075\n",
      "GD iter. 7/499: loss=0.4960497151284852\n",
      "GD iter. 8/499: loss=0.4926841566476931\n",
      "GD iter. 9/499: loss=0.4896856679653233\n",
      "GD iter. 10/499: loss=0.4869869961749231\n",
      "GD iter. 11/499: loss=0.4845392200872446\n",
      "GD iter. 12/499: loss=0.4823054525791568\n",
      "GD iter. 13/499: loss=0.48025700842599084\n",
      "GD iter. 14/499: loss=0.478370992728854\n",
      "GD iter. 15/499: loss=0.47662873164397923\n",
      "GD iter. 16/499: loss=0.4750147175076968\n",
      "GD iter. 17/499: loss=0.4735158776149945\n",
      "GD iter. 18/499: loss=0.4721210527320731\n",
      "GD iter. 19/499: loss=0.4708206154638343\n",
      "GD iter. 20/499: loss=0.46960618445396396\n",
      "GD iter. 21/499: loss=0.4684704059456871\n",
      "GD iter. 22/499: loss=0.46740678381145956\n",
      "GD iter. 23/499: loss=0.4664095452053542\n",
      "GD iter. 24/499: loss=0.4654735328984904\n",
      "GD iter. 25/499: loss=0.46459411794157\n",
      "GD iter. 26/499: loss=0.46376712804608733\n",
      "GD iter. 27/499: loss=0.4629887882831016\n",
      "GD iter. 28/499: loss=0.4622556715493263\n",
      "GD iter. 29/499: loss=0.4615646568610057\n",
      "GD iter. 30/499: loss=0.4609128939817534\n",
      "GD iter. 31/499: loss=0.46029777322072174\n",
      "GD iter. 32/499: loss=0.4597168994853914\n",
      "GD iter. 33/499: loss=0.45916806986168\n",
      "GD iter. 34/499: loss=0.45864925413878904\n",
      "GD iter. 35/499: loss=0.45815857780846797\n",
      "GD iter. 36/499: loss=0.4576943071562151\n",
      "GD iter. 37/499: loss=0.45725483613123147\n",
      "GD iter. 38/499: loss=0.4568386747370178\n",
      "GD iter. 39/499: loss=0.45644443872858287\n",
      "GD iter. 40/499: loss=0.4560708404377402\n",
      "GD iter. 41/499: loss=0.45571668057675807\n",
      "GD iter. 42/499: loss=0.45538084089410186\n",
      "GD iter. 43/499: loss=0.45506227757526063\n",
      "GD iter. 44/499: loss=0.4547600152975329\n",
      "GD iter. 45/499: loss=0.4544731418608062\n",
      "GD iter. 46/499: loss=0.4542008033273408\n",
      "GD iter. 47/499: loss=0.4539421996127552\n",
      "GD iter. 48/499: loss=0.45369658047814093\n",
      "GD iter. 49/499: loss=0.4534632418797713\n",
      "GD iter. 50/499: loss=0.45324152263842044\n",
      "GD iter. 51/499: loss=0.4530308013950356\n",
      "GD iter. 52/499: loss=0.4528304938235614\n",
      "GD iter. 53/499: loss=0.45264005007519137\n",
      "GD iter. 54/499: loss=0.4524589524313306\n",
      "GD iter. 55/499: loss=0.45228671314514374\n",
      "GD iter. 56/499: loss=0.45212287245383026\n",
      "GD iter. 57/499: loss=0.45196699674572316\n",
      "GD iter. 58/499: loss=0.4518186768680391\n",
      "GD iter. 59/499: loss=0.4516775265625989\n",
      "GD iter. 60/499: loss=0.4515431810181715\n",
      "GD iter. 61/499: loss=0.45141529552925463\n",
      "GD iter. 62/499: loss=0.45129354425213397\n",
      "GD iter. 63/499: loss=0.4511776190499742\n",
      "GD iter. 64/499: loss=0.45106722841950253\n",
      "GD iter. 65/499: loss=0.4509620964925639\n",
      "GD iter. 66/499: loss=0.4508619621064627\n",
      "GD iter. 67/499: loss=0.45076657793758085\n",
      "GD iter. 68/499: loss=0.4506757096932668\n",
      "GD iter. 69/499: loss=0.4505891353574503\n",
      "GD iter. 70/499: loss=0.45050664448584365\n",
      "GD iter. 71/499: loss=0.45042803754695904\n",
      "GD iter. 72/499: loss=0.45035312530550164\n",
      "GD iter. 73/499: loss=0.45028172824499557\n",
      "GD iter. 74/499: loss=0.4502136760267701\n",
      "GD iter. 75/499: loss=0.45014880698267146\n",
      "GD iter. 76/499: loss=0.45008696763909056\n",
      "GD iter. 77/499: loss=0.45002801227009154\n",
      "GD iter. 78/499: loss=0.44997180247760726\n",
      "GD iter. 79/499: loss=0.44991820679683275\n",
      "GD iter. 80/499: loss=0.44986710032509236\n",
      "GD iter. 81/499: loss=0.4498183643725974\n",
      "GD iter. 82/499: loss=0.4497718861336281\n",
      "GD iter. 83/499: loss=0.4497275583767892\n",
      "GD iter. 84/499: loss=0.4496852791530913\n",
      "GD iter. 85/499: loss=0.4496449515207029\n",
      "GD iter. 86/499: loss=0.4496064832853016\n",
      "GD iter. 87/499: loss=0.4495697867550363\n",
      "GD iter. 88/499: loss=0.4495347785091795\n",
      "GD iter. 89/499: loss=0.449501379179616\n",
      "GD iter. 90/499: loss=0.4494695132443771\n",
      "GD iter. 91/499: loss=0.4494391088324822\n",
      "GD iter. 92/499: loss=0.4494100975394014\n",
      "GD iter. 93/499: loss=0.4493824142525015\n",
      "GD iter. 94/499: loss=0.4493559969858806\n",
      "GD iter. 95/499: loss=0.4493307867240339\n",
      "GD iter. 96/499: loss=0.449306727273836\n",
      "GD iter. 97/499: loss=0.4492837651243525\n",
      "GD iter. 98/499: loss=0.4492618493140302\n",
      "GD iter. 99/499: loss=0.4492409313048448\n",
      "GD iter. 100/499: loss=0.4492209648630061\n",
      "GD iter. 101/499: loss=0.44920190594585396\n",
      "GD iter. 102/499: loss=0.4491837125945951\n",
      "GD iter. 103/499: loss=0.4491663448325569\n",
      "GD iter. 104/499: loss=0.44914976456865235\n",
      "GD iter. 105/499: loss=0.44913393550576725\n",
      "GD iter. 106/499: loss=0.4491188230538042\n",
      "GD iter. 107/499: loss=0.44910439424712684\n",
      "GD iter. 108/499: loss=0.44909061766616887\n",
      "GD iter. 109/499: loss=0.4490774633629817\n",
      "GD iter. 110/499: loss=0.4490649027905127\n",
      "GD iter. 111/499: loss=0.4490529087354133\n",
      "GD iter. 112/499: loss=0.44904145525419203\n",
      "GD iter. 113/499: loss=0.4490305176125349\n",
      "GD iter. 114/499: loss=0.44902007222762846\n",
      "GD iter. 115/499: loss=0.4490100966133278\n",
      "GD iter. 116/499: loss=0.44900056932802224\n",
      "GD iter. 117/499: loss=0.4489914699250603\n",
      "GD iter. 118/499: loss=0.448982778905599\n",
      "GD iter. 119/499: loss=0.44897447767375753\n",
      "GD iter. 120/499: loss=0.44896654849395423\n",
      "GD iter. 121/499: loss=0.4489589744503166\n",
      "GD iter. 122/499: loss=0.4489517394080608\n",
      "GD iter. 123/499: loss=0.44894482797673857\n",
      "GD iter. 124/499: loss=0.4489382254752594\n",
      "GD iter. 125/499: loss=0.4489319178985987\n",
      "GD iter. 126/499: loss=0.44892589188610665\n",
      "GD iter. 127/499: loss=0.4489201346913384\n",
      "GD iter. 128/499: loss=0.4489146341533309\n",
      "GD iter. 129/499: loss=0.44890937866925296\n",
      "GD iter. 130/499: loss=0.4489043571683615\n",
      "GD iter. 131/499: loss=0.4488995590872008\n",
      "GD iter. 132/499: loss=0.44889497434598\n",
      "GD iter. 133/499: loss=0.44889059332607617\n",
      "GD iter. 134/499: loss=0.4488864068486025\n",
      "GD iter. 135/499: loss=0.4488824061539947\n",
      "GD iter. 136/499: loss=0.4488785828825612\n",
      "GD iter. 137/499: loss=0.4488749290559537\n",
      "GD iter. 138/499: loss=0.44887143705951305\n",
      "GD iter. 139/499: loss=0.44886809962544516\n",
      "GD iter. 140/499: loss=0.4488649098167919\n",
      "GD iter. 141/499: loss=0.44886186101215286\n",
      "GD iter. 142/499: loss=0.4488589468911266\n",
      "GD iter. 143/499: loss=0.4488561614204349\n",
      "GD iter. 144/499: loss=0.44885349884069586\n",
      "GD iter. 145/499: loss=0.44885095365381766\n",
      "GD iter. 146/499: loss=0.44884852061098107\n",
      "GD iter. 147/499: loss=0.44884619470118436\n",
      "GD iter. 148/499: loss=0.4488439711403205\n",
      "GD iter. 149/499: loss=0.44884184536076716\n",
      "GD iter. 150/499: loss=0.44883981300145775\n",
      "GD iter. 151/499: loss=0.4488378698984176\n",
      "GD iter. 152/499: loss=0.4488360120757388\n",
      "GD iter. 153/499: loss=0.4488342357369738\n",
      "GD iter. 154/499: loss=0.4488325372569296\n",
      "GD iter. 155/499: loss=0.4488309131738423\n",
      "GD iter. 156/499: loss=0.448829360181913\n",
      "GD iter. 157/499: loss=0.4488278751241907\n",
      "GD iter. 158/499: loss=0.4488264549857838\n",
      "GD iter. 159/499: loss=0.44882509688738553\n",
      "GD iter. 160/499: loss=0.44882379807909856\n",
      "GD iter. 161/499: loss=0.4488225559345436\n",
      "GD iter. 162/499: loss=0.44882136794524186\n",
      "GD iter. 163/499: loss=0.44882023171525376\n",
      "GD iter. 164/499: loss=0.4488191449560667\n",
      "GD iter. 165/499: loss=0.44881810548171697\n",
      "GD iter. 166/499: loss=0.448817111204136\n",
      "GD iter. 167/499: loss=0.4488161601287111\n",
      "GD iter. 168/499: loss=0.44881525035004993\n",
      "GD iter. 169/499: loss=0.4488143800479381\n",
      "GD iter. 170/499: loss=0.4488135474834843\n",
      "GD iter. 171/499: loss=0.4488127509954403\n",
      "GD iter. 172/499: loss=0.4488119889966906\n",
      "GD iter. 173/499: loss=0.44881125997090215\n",
      "GD iter. 174/499: loss=0.4488105624693275\n",
      "GD iter. 175/499: loss=0.4488098951077544\n",
      "GD iter. 176/499: loss=0.4488092565635945\n",
      "GD iter. 177/499: loss=0.4488086455731048\n",
      "GD iter. 178/499: loss=0.44880806092873615\n",
      "GD iter. 179/499: loss=0.4488075014766029\n",
      "GD iter. 180/499: loss=0.4488069661140674\n",
      "GD iter. 181/499: loss=0.44880645378743456\n",
      "GD iter. 182/499: loss=0.44880596348975205\n",
      "GD iter. 183/499: loss=0.44880549425870947\n",
      "GD iter. 184/499: loss=0.4488050451746346\n",
      "GD iter. 185/499: loss=0.4488046153585787\n",
      "GD iter. 186/499: loss=0.44880420397049076\n",
      "GD iter. 187/499: loss=0.44880381020747295\n",
      "GD iter. 188/499: loss=0.4488034333021169\n",
      "GD iter. 189/499: loss=0.44880307252091395\n",
      "GD iter. 190/499: loss=0.44880272716273795\n",
      "GD iter. 191/499: loss=0.4488023965573973\n",
      "GD iter. 192/499: loss=0.4488020800642517\n",
      "GD iter. 193/499: loss=0.44880177707089225\n",
      "GD iter. 194/499: loss=0.44880148699188044\n",
      "GD iter. 195/499: loss=0.448801209267545\n",
      "GD iter. 196/499: loss=0.4488009433628323\n",
      "GD iter. 197/499: loss=0.448800688766209\n",
      "GD iter. 198/499: loss=0.44880044498861443\n",
      "GD iter. 199/499: loss=0.44880021156246014\n",
      "GD iter. 200/499: loss=0.44879998804067384\n",
      "GD iter. 201/499: loss=0.4487997739957874\n",
      "GD iter. 202/499: loss=0.44879956901906515\n",
      "GD iter. 203/499: loss=0.44879937271967235\n",
      "GD iter. 204/499: loss=0.44879918472387964\n",
      "GD iter. 205/499: loss=0.4487990046743044\n",
      "GD iter. 206/499: loss=0.4487988322291861\n",
      "GD iter. 207/499: loss=0.44879866706169347\n",
      "GD iter. 208/499: loss=0.44879850885926337\n",
      "GD iter. 209/499: loss=0.4487983573229694\n",
      "GD iter. 210/499: loss=0.4487982121669179\n",
      "GD iter. 211/499: loss=0.4487980731176727\n",
      "GD iter. 212/499: loss=0.4487979399137035\n",
      "GD iter. 213/499: loss=0.4487978123048608\n",
      "GD iter. 214/499: loss=0.44879769005187353\n",
      "GD iter. 215/499: loss=0.44879757292586847\n",
      "GD iter. 216/499: loss=0.4487974607079129\n",
      "GD iter. 217/499: loss=0.4487973531885756\n",
      "GD iter. 218/499: loss=0.44879725016750915\n",
      "GD iter. 219/499: loss=0.4487971514530499\n",
      "GD iter. 220/499: loss=0.448797056861836\n",
      "GD iter. 221/499: loss=0.4487969662184426\n",
      "GD iter. 222/499: loss=0.4487968793550332\n",
      "GD iter. 223/499: loss=0.44879679611102646\n",
      "GD iter. 224/499: loss=0.44879671633277773\n",
      "GD iter. 225/499: loss=0.4487966398732754\n",
      "GD iter. 226/499: loss=0.44879656659184947\n",
      "GD iter. 227/499: loss=0.44879649635389446\n",
      "GD iter. 228/499: loss=0.44879642903060385\n",
      "GD iter. 229/499: loss=0.44879636449871607\n",
      "GD iter. 230/499: loss=0.4487963026402727\n",
      "GD iter. 231/499: loss=0.44879624334238627\n",
      "GD iter. 232/499: loss=0.44879618649701897\n",
      "GD iter. 233/499: loss=0.4487961320007716\n",
      "GD iter. 234/499: loss=0.4487960797546806\n",
      "GD iter. 235/499: loss=0.44879602966402493\n",
      "GD iter. 236/499: loss=0.44879598163814194\n",
      "GD iter. 237/499: loss=0.44879593559024955\n",
      "GD iter. 238/499: loss=0.4487958914372789\n",
      "GD iter. 239/499: loss=0.44879584909971176\n",
      "GD iter. 240/499: loss=0.44879580850142703\n",
      "GD iter. 241/499: loss=0.4487957695695529\n",
      "GD iter. 242/499: loss=0.44879573223432623\n",
      "GD iter. 243/499: loss=0.44879569642895734\n",
      "GD iter. 244/499: loss=0.4487956620895014\n",
      "GD iter. 245/499: loss=0.4487956291547357\n",
      "GD iter. 246/499: loss=0.4487955975660412\n",
      "GD iter. 247/499: loss=0.44879556726729014\n",
      "GD iter. 248/499: loss=0.44879553820473905\n",
      "GD iter. 249/499: loss=0.44879551032692455\n",
      "GD iter. 250/499: loss=0.4487954835845661\n",
      "GD iter. 251/499: loss=0.4487954579304713\n",
      "GD iter. 252/499: loss=0.44879543331944605\n",
      "GD iter. 253/499: loss=0.4487954097082085\n",
      "GD iter. 254/499: loss=0.4487953870553069\n",
      "GD iter. 255/499: loss=0.44879536532104053\n",
      "GD iter. 256/499: loss=0.4487953444673847\n",
      "GD iter. 257/499: loss=0.44879532445791903\n",
      "GD iter. 258/499: loss=0.44879530525775796\n",
      "GD iter. 259/499: loss=0.44879528683348535\n",
      "GD iter. 260/499: loss=0.448795269153092\n",
      "GD iter. 261/499: loss=0.4487952521859139\n",
      "GD iter. 262/499: loss=0.4487952359025765\n",
      "GD iter. 263/499: loss=0.448795220274938\n",
      "GD iter. 264/499: loss=0.4487952052760377\n",
      "GD iter. 265/499: loss=0.44879519088004544\n",
      "GD iter. 266/499: loss=0.4487951770622124\n",
      "GD iter. 267/499: loss=0.4487951637988263\n",
      "GD iter. 268/499: loss=0.44879515106716655\n",
      "GD iter. 269/499: loss=0.4487951388454619\n",
      "GD iter. 270/499: loss=0.4487951271128505\n",
      "GD iter. 271/499: loss=0.448795115849341\n",
      "GD iter. 272/499: loss=0.44879510503577535\n",
      "GD iter. 273/499: loss=0.4487950946537936\n",
      "GD iter. 274/499: loss=0.4487950846858003\n",
      "GD iter. 275/499: loss=0.44879507511493166\n",
      "GD iter. 276/499: loss=0.4487950659250248\n",
      "GD iter. 277/499: loss=0.4487950571005883\n",
      "GD iter. 278/499: loss=0.44879504862677283\n",
      "GD iter. 279/499: loss=0.4487950404893454\n",
      "GD iter. 280/499: loss=0.4487950326746623\n",
      "GD iter. 281/499: loss=0.44879502516964453\n",
      "GD iter. 282/499: loss=0.4487950179617541\n",
      "GD iter. 283/499: loss=0.44879501103897107\n",
      "GD iter. 284/499: loss=0.4487950043897718\n",
      "GD iter. 285/499: loss=0.4487949980031082\n",
      "GD iter. 286/499: loss=0.44879499186838745\n",
      "GD iter. 287/499: loss=0.44879498597545303\n",
      "GD iter. 288/499: loss=0.4487949803145664\n",
      "GD iter. 289/499: loss=0.4487949748763894\n",
      "GD iter. 290/499: loss=0.4487949696519679\n",
      "GD iter. 291/499: loss=0.4487949646327148\n",
      "GD iter. 292/499: loss=0.4487949598103956\n",
      "GD iter. 293/499: loss=0.448794955177113\n",
      "GD iter. 294/499: loss=0.44879495072529335\n",
      "GD iter. 295/499: loss=0.4487949464476725\n",
      "GD iter. 296/499: loss=0.4487949423372836\n",
      "GD iter. 297/499: loss=0.4487949383874442\n",
      "GD iter. 298/499: loss=0.4487949345917444\n",
      "GD iter. 299/499: loss=0.4487949309440361\n",
      "GD iter. 300/499: loss=0.44879492743842103\n",
      "GD iter. 301/499: loss=0.4487949240692418\n",
      "GD iter. 302/499: loss=0.44879492083107037\n",
      "GD iter. 303/499: loss=0.44879491771869956\n",
      "GD iter. 304/499: loss=0.4487949147271338\n",
      "GD iter. 305/499: loss=0.44879491185157977\n",
      "GD iter. 306/499: loss=0.44879490908743885\n",
      "GD iter. 307/499: loss=0.44879490643029835\n",
      "GD iter. 308/499: loss=0.4487949038759242\n",
      "GD iter. 309/499: loss=0.4487949014202537\n",
      "GD iter. 310/499: loss=0.4487948990593878\n",
      "GD iter. 311/499: loss=0.44879489678958523\n",
      "GD iter. 312/499: loss=0.44879489460725536\n",
      "GD iter. 313/499: loss=0.44879489250895227\n",
      "GD iter. 314/499: loss=0.4487948904913687\n",
      "GD iter. 315/499: loss=0.4487948885513306\n",
      "GD iter. 316/499: loss=0.4487948866857912\n",
      "GD iter. 317/499: loss=0.44879488489182595\n",
      "GD iter. 318/499: loss=0.44879488316662797\n",
      "GD iter. 319/499: loss=0.44879488150750274\n",
      "GD iter. 320/499: loss=0.4487948799118637\n",
      "GD iter. 321/499: loss=0.4487948783772272\n",
      "GD iter. 322/499: loss=0.4487948769012098\n",
      "GD iter. 323/499: loss=0.4487948754815224\n",
      "GD iter. 324/499: loss=0.448794874115968\n",
      "GD iter. 325/499: loss=0.44879487280243635\n",
      "GD iter. 326/499: loss=0.4487948715389021\n",
      "GD iter. 327/499: loss=0.44879487032341975\n",
      "GD iter. 328/499: loss=0.4487948691541217\n",
      "GD iter. 329/499: loss=0.44879486802921437\n",
      "GD iter. 330/499: loss=0.4487948669469751\n",
      "GD iter. 331/499: loss=0.44879486590575\n",
      "GD iter. 332/499: loss=0.44879486490395054\n",
      "GD iter. 333/499: loss=0.44879486394005075\n",
      "GD iter. 334/499: loss=0.4487948630125855\n",
      "GD iter. 335/499: loss=0.4487948621201473\n",
      "GD iter. 336/499: loss=0.44879486126138407\n",
      "GD iter. 337/499: loss=0.4487948604349977\n",
      "GD iter. 338/499: loss=0.4487948596397404\n",
      "GD iter. 339/499: loss=0.44879485887441406\n",
      "GD iter. 340/499: loss=0.44879485813786757\n",
      "GD iter. 341/499: loss=0.4487948574289951\n",
      "GD iter. 342/499: loss=0.4487948567467341\n",
      "GD iter. 343/499: loss=0.4487948560900638\n",
      "GD iter. 344/499: loss=0.44879485545800374\n",
      "GD iter. 345/499: loss=0.44879485484961124\n",
      "GD iter. 346/499: loss=0.44879485426398097\n",
      "GD iter. 347/499: loss=0.44879485370024297\n",
      "GD iter. 348/499: loss=0.4487948531575611\n",
      "GD iter. 349/499: loss=0.44879485263513197\n",
      "GD iter. 350/499: loss=0.4487948521321834\n",
      "GD iter. 351/499: loss=0.44879485164797356\n",
      "GD iter. 352/499: loss=0.4487948511817891\n",
      "GD iter. 353/499: loss=0.4487948507329446\n",
      "GD iter. 354/499: loss=0.4487948503007815\n",
      "GD iter. 355/499: loss=0.4487948498846664\n",
      "GD iter. 356/499: loss=0.4487948494839909\n",
      "GD iter. 357/499: loss=0.4487948490981697\n",
      "GD iter. 358/499: loss=0.44879484872664055\n",
      "GD iter. 359/499: loss=0.4487948483688629\n",
      "GD iter. 360/499: loss=0.44879484802431685\n",
      "GD iter. 361/499: loss=0.44879484769250283\n",
      "GD iter. 362/499: loss=0.44879484737294034\n",
      "GD iter. 363/499: loss=0.44879484706516753\n",
      "GD iter. 364/499: loss=0.44879484676874043\n",
      "GD iter. 365/499: loss=0.4487948464832321\n",
      "GD iter. 366/499: loss=0.44879484620823173\n",
      "GD iter. 367/499: loss=0.44879484594334484\n",
      "GD iter. 368/499: loss=0.4487948456881914\n",
      "GD iter. 369/499: loss=0.44879484544240655\n",
      "GD iter. 370/499: loss=0.4487948452056393\n",
      "GD iter. 371/499: loss=0.4487948449775518\n",
      "GD iter. 372/499: loss=0.4487948447578193\n",
      "GD iter. 373/499: loss=0.44879484454612956\n",
      "GD iter. 374/499: loss=0.4487948443421822\n",
      "GD iter. 375/499: loss=0.4487948441456882\n",
      "GD iter. 376/499: loss=0.44879484395636965\n",
      "GD iter. 377/499: loss=0.4487948437739593\n",
      "GD iter. 378/499: loss=0.4487948435981997\n",
      "GD iter. 379/499: loss=0.44879484342884385\n",
      "GD iter. 380/499: loss=0.44879484326565333\n",
      "GD iter. 381/499: loss=0.44879484310839957\n",
      "GD iter. 382/499: loss=0.448794842956862\n",
      "GD iter. 383/499: loss=0.4487948428108287\n",
      "GD iter. 384/499: loss=0.448794842670096\n",
      "GD iter. 385/499: loss=0.4487948425344676\n",
      "GD iter. 386/499: loss=0.4487948424037544\n",
      "GD iter. 387/499: loss=0.4487948422777752\n",
      "GD iter. 388/499: loss=0.44879484215635485\n",
      "GD iter. 389/499: loss=0.44879484203932535\n",
      "GD iter. 390/499: loss=0.44879484192652463\n",
      "GD iter. 391/499: loss=0.44879484181779716\n",
      "GD iter. 392/499: loss=0.4487948417129927\n",
      "GD iter. 393/499: loss=0.4487948416119673\n",
      "GD iter. 394/499: loss=0.4487948415145817\n",
      "GD iter. 395/499: loss=0.44879484142070253\n",
      "GD iter. 396/499: loss=0.448794841330201\n",
      "GD iter. 397/499: loss=0.4487948412429532\n",
      "GD iter. 398/499: loss=0.4487948411588402\n",
      "GD iter. 399/499: loss=0.44879484107774686\n",
      "GD iter. 400/499: loss=0.44879484099956296\n",
      "GD iter. 401/499: loss=0.44879484092418204\n",
      "GD iter. 402/499: loss=0.44879484085150184\n",
      "GD iter. 403/499: loss=0.44879484078142373\n",
      "GD iter. 404/499: loss=0.44879484071385284\n",
      "GD iter. 405/499: loss=0.4487948406486977\n",
      "GD iter. 406/499: loss=0.4487948405858704\n",
      "GD iter. 407/499: loss=0.4487948405252863\n",
      "GD iter. 408/499: loss=0.44879484046686363\n",
      "GD iter. 409/499: loss=0.44879484041052425\n",
      "GD iter. 410/499: loss=0.44879484035619227\n",
      "GD iter. 411/499: loss=0.4487948403037948\n",
      "GD iter. 412/499: loss=0.44879484025326183\n",
      "GD iter. 413/499: loss=0.44879484020452587\n",
      "GD iter. 414/499: loss=0.44879484015752175\n",
      "GD iter. 415/499: loss=0.4487948401121869\n",
      "GD iter. 416/499: loss=0.4487948400684609\n",
      "GD iter. 417/499: loss=0.4487948400262857\n",
      "GD iter. 418/499: loss=0.4487948399856053\n",
      "GD iter. 419/499: loss=0.4487948399463658\n",
      "GD iter. 420/499: loss=0.4487948399085153\n",
      "GD iter. 421/499: loss=0.44879483987200386\n",
      "GD iter. 422/499: loss=0.4487948398367831\n",
      "GD iter. 423/499: loss=0.4487948398028066\n",
      "GD iter. 424/499: loss=0.4487948397700297\n",
      "GD iter. 425/499: loss=0.44879483973840956\n",
      "GD iter. 426/499: loss=0.4487948397079043\n",
      "GD iter. 427/499: loss=0.44879483967847417\n",
      "GD iter. 428/499: loss=0.44879483965008043\n",
      "GD iter. 429/499: loss=0.44879483962268607\n",
      "GD iter. 430/499: loss=0.4487948395962553\n",
      "GD iter. 431/499: loss=0.4487948395707538\n",
      "GD iter. 432/499: loss=0.4487948395461481\n",
      "GD iter. 433/499: loss=0.4487948395224065\n",
      "GD iter. 434/499: loss=0.44879483949949794\n",
      "GD iter. 435/499: loss=0.44879483947739285\n",
      "GD iter. 436/499: loss=0.44879483945606236\n",
      "GD iter. 437/499: loss=0.4487948394354791\n",
      "GD iter. 438/499: loss=0.4487948394156164\n",
      "GD iter. 439/499: loss=0.44879483939644865\n",
      "GD iter. 440/499: loss=0.44879483937795117\n",
      "GD iter. 441/499: loss=0.4487948393601001\n",
      "GD iter. 442/499: loss=0.44879483934287234\n",
      "GD iter. 443/499: loss=0.44879483932624603\n",
      "GD iter. 444/499: loss=0.4487948393101997\n",
      "GD iter. 445/499: loss=0.44879483929471287\n",
      "GD iter. 446/499: loss=0.44879483927976566\n",
      "GD iter. 447/499: loss=0.448794839265339\n",
      "GD iter. 448/499: loss=0.4487948392514145\n",
      "GD iter. 449/499: loss=0.4487948392379743\n",
      "GD iter. 450/499: loss=0.4487948392250015\n",
      "GD iter. 451/499: loss=0.4487948392124796\n",
      "GD iter. 452/499: loss=0.44879483920039237\n",
      "GD iter. 453/499: loss=0.4487948391887248\n",
      "GD iter. 454/499: loss=0.44879483917746205\n",
      "GD iter. 455/499: loss=0.4487948391665895\n",
      "GD iter. 456/499: loss=0.4487948391560941\n",
      "GD iter. 457/499: loss=0.44879483914596213\n",
      "GD iter. 458/499: loss=0.44879483913618073\n",
      "GD iter. 459/499: loss=0.44879483912673795\n",
      "GD iter. 460/499: loss=0.4487948391176215\n",
      "GD iter. 461/499: loss=0.4487948391088203\n",
      "GD iter. 462/499: loss=0.44879483910032303\n",
      "GD iter. 463/499: loss=0.44879483909211926\n",
      "GD iter. 464/499: loss=0.44879483908419854\n",
      "GD iter. 465/499: loss=0.44879483907655104\n",
      "GD iter. 466/499: loss=0.44879483906916706\n",
      "GD iter. 467/499: loss=0.44879483906203765\n",
      "GD iter. 468/499: loss=0.4487948390551536\n",
      "GD iter. 469/499: loss=0.44879483904850664\n",
      "GD iter. 470/499: loss=0.4487948390420884\n",
      "GD iter. 471/499: loss=0.4487948390358908\n",
      "GD iter. 472/499: loss=0.4487948390299062\n",
      "GD iter. 473/499: loss=0.4487948390241271\n",
      "GD iter. 474/499: loss=0.4487948390185465\n",
      "GD iter. 475/499: loss=0.44879483901315753\n",
      "GD iter. 476/499: loss=0.44879483900795325\n",
      "GD iter. 477/499: loss=0.4487948390029276\n",
      "GD iter. 478/499: loss=0.448794838998074\n",
      "GD iter. 479/499: loss=0.4487948389933868\n",
      "GD iter. 480/499: loss=0.44879483898886\n",
      "GD iter. 481/499: loss=0.448794838984488\n",
      "GD iter. 482/499: loss=0.44879483898026573\n",
      "GD iter. 483/499: loss=0.4487948389761877\n",
      "GD iter. 484/499: loss=0.4487948389722491\n",
      "GD iter. 485/499: loss=0.448794838968445\n",
      "GD iter. 486/499: loss=0.4487948389647708\n",
      "GD iter. 487/499: loss=0.44879483896122196\n",
      "GD iter. 488/499: loss=0.44879483895779426\n",
      "GD iter. 489/499: loss=0.4487948389544833\n",
      "GD iter. 490/499: loss=0.44879483895128536\n",
      "GD iter. 491/499: loss=0.4487948389481962\n",
      "GD iter. 492/499: loss=0.4487948389452122\n",
      "GD iter. 493/499: loss=0.44879483894232985\n",
      "GD iter. 494/499: loss=0.4487948389395455\n",
      "GD iter. 495/499: loss=0.44879483893685584\n",
      "GD iter. 496/499: loss=0.44879483893425764\n",
      "GD iter. 497/499: loss=0.44879483893174765\n",
      "GD iter. 498/499: loss=0.4487948389293229\n",
      "GD iter. 499/499: loss=0.4487948389269806\n",
      "The Accuracy is: 0.8328\n",
      "The F1 score is: 0.3780\n",
      "The precision is: 0.2743\n",
      "The recall is: 0.6078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3780487804878049"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression\n",
    "x_t, y_t, x_v, y_v = split_data(add_bias(x_train_processed), y_train_processed, 0.9)\n",
    "x_t, y_t = data_augmentation(x_t, y_t)\n",
    "initial_w = np.random.randn(x_t.shape[1]) * 0.01\n",
    "w, loss = reg_logistic_regression(y_t, x_t, lambda_=0.1, initial_w=initial_w, max_iters=500, gamma=0.15)\n",
    "y_pred = (x_v @ w >= 0.75).astype(int)\n",
    "predict_acc_pure(y_pred, y_v)\n",
    "predict_f1_pure(y_pred, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 0.5689\n",
      "The F1 score is: 0.2102\n",
      "The precision is: 0.1199\n",
      "The recall is: 0.8537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21021021021021016"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ridge regression using all the features except for those having NaN values over 50% ##\n",
    "x_t, y_t, x_v, y_v = split_data(add_bias(x_train_processed), y_train_processed, 0.9)\n",
    "x_t, y_t = data_augmentation(x_t, y_t)\n",
    "w, loss = ridge_regression(y_t, x_t, lambda_=0.01)\n",
    "y_pred = x_v @ w\n",
    "y_pred_mean = np.mean(y_pred)\n",
    "y_pred = (y_pred > y_pred_mean).astype(int)\n",
    "predict_acc_pure(y_pred, y_v)\n",
    "predict_f1_pure(y_pred, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hinge loss gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/499: loss=0.9913199633809331\n",
      "GD iter. 1/499: loss=0.9185902320125032\n",
      "GD iter. 2/499: loss=0.8469167125992535\n",
      "GD iter. 3/499: loss=0.78115290905863\n",
      "GD iter. 4/499: loss=0.7333532552998508\n",
      "GD iter. 5/499: loss=0.7027635757220305\n",
      "GD iter. 6/499: loss=0.6827822935647762\n",
      "GD iter. 7/499: loss=0.6681868370607503\n",
      "GD iter. 8/499: loss=0.657830379761844\n",
      "GD iter. 9/499: loss=0.649922603159183\n",
      "GD iter. 10/499: loss=0.6438108473792942\n",
      "GD iter. 11/499: loss=0.6391750940974552\n",
      "GD iter. 12/499: loss=0.6350487492049526\n",
      "GD iter. 13/499: loss=0.6313398496896179\n",
      "GD iter. 14/499: loss=0.6280449431716127\n",
      "GD iter. 15/499: loss=0.6251846357292073\n",
      "GD iter. 16/499: loss=0.6226585387470225\n",
      "GD iter. 17/499: loss=0.6202739167661988\n",
      "GD iter. 18/499: loss=0.6181038873375189\n",
      "GD iter. 19/499: loss=0.6162564825106277\n",
      "GD iter. 20/499: loss=0.614491281985601\n",
      "GD iter. 21/499: loss=0.6128041252038765\n",
      "GD iter. 22/499: loss=0.6112090388333594\n",
      "GD iter. 23/499: loss=0.6096361163330936\n",
      "GD iter. 24/499: loss=0.6081419323716293\n",
      "GD iter. 25/499: loss=0.606707474713237\n",
      "GD iter. 26/499: loss=0.6054070703486123\n",
      "GD iter. 27/499: loss=0.6041840910288179\n",
      "GD iter. 28/499: loss=0.6030213699381737\n",
      "GD iter. 29/499: loss=0.6019106902530349\n",
      "GD iter. 30/499: loss=0.600828394679164\n",
      "GD iter. 31/499: loss=0.5997558093845377\n",
      "GD iter. 32/499: loss=0.5987097011684885\n",
      "GD iter. 33/499: loss=0.597737686276703\n",
      "GD iter. 34/499: loss=0.5967841124986566\n",
      "GD iter. 35/499: loss=0.5958667138214163\n",
      "GD iter. 36/499: loss=0.5950119125735466\n",
      "GD iter. 37/499: loss=0.594209898634468\n",
      "GD iter. 38/499: loss=0.593426761081545\n",
      "GD iter. 39/499: loss=0.5926635779391196\n",
      "GD iter. 40/499: loss=0.5919144236649078\n",
      "GD iter. 41/499: loss=0.5911995243989979\n",
      "GD iter. 42/499: loss=0.5904914021242925\n",
      "GD iter. 43/499: loss=0.5898517315509451\n",
      "GD iter. 44/499: loss=0.5892432492928983\n",
      "GD iter. 45/499: loss=0.5886606743382279\n",
      "GD iter. 46/499: loss=0.5880811076006134\n",
      "GD iter. 47/499: loss=0.5875047727332506\n",
      "GD iter. 48/499: loss=0.5869340246779694\n",
      "GD iter. 49/499: loss=0.5863803864817454\n",
      "GD iter. 50/499: loss=0.5858763602810352\n",
      "GD iter. 51/499: loss=0.5854018019988483\n",
      "GD iter. 52/499: loss=0.5849223547162082\n",
      "GD iter. 53/499: loss=0.5844549710421605\n",
      "GD iter. 54/499: loss=0.58401841208936\n",
      "GD iter. 55/499: loss=0.5835957388768322\n",
      "GD iter. 56/499: loss=0.5831910297053118\n",
      "GD iter. 57/499: loss=0.5827732053226277\n",
      "GD iter. 58/499: loss=0.5823722948050991\n",
      "GD iter. 59/499: loss=0.5819745373290213\n",
      "GD iter. 60/499: loss=0.5815988175782965\n",
      "GD iter. 61/499: loss=0.5812295722335774\n",
      "GD iter. 62/499: loss=0.5808588234340196\n",
      "GD iter. 63/499: loss=0.5804960935688523\n",
      "GD iter. 64/499: loss=0.5801397718579459\n",
      "GD iter. 65/499: loss=0.5797939949165192\n",
      "GD iter. 66/499: loss=0.5794403687509563\n",
      "GD iter. 67/499: loss=0.5790917396827245\n",
      "GD iter. 68/499: loss=0.5787437356474946\n",
      "GD iter. 69/499: loss=0.5783972180166888\n",
      "GD iter. 70/499: loss=0.5780601407559016\n",
      "GD iter. 71/499: loss=0.5777153871160201\n",
      "GD iter. 72/499: loss=0.5773891499146998\n",
      "GD iter. 73/499: loss=0.5770742009416723\n",
      "GD iter. 74/499: loss=0.5767653313456061\n",
      "GD iter. 75/499: loss=0.5764587946144312\n",
      "GD iter. 76/499: loss=0.5761628979881142\n",
      "GD iter. 77/499: loss=0.575853185106066\n",
      "GD iter. 78/499: loss=0.5755607323196642\n",
      "GD iter. 79/499: loss=0.5752585054614844\n",
      "GD iter. 80/499: loss=0.5749687514196191\n",
      "GD iter. 81/499: loss=0.574677331842287\n",
      "GD iter. 82/499: loss=0.5743928334132874\n",
      "GD iter. 83/499: loss=0.5741302064119669\n",
      "GD iter. 84/499: loss=0.5738715245142791\n",
      "GD iter. 85/499: loss=0.5736115910061339\n",
      "GD iter. 86/499: loss=0.5733572018664606\n",
      "GD iter. 87/499: loss=0.5731238546420685\n",
      "GD iter. 88/499: loss=0.5728768820201906\n",
      "GD iter. 89/499: loss=0.5726410724824058\n",
      "GD iter. 90/499: loss=0.5724094487045651\n",
      "GD iter. 91/499: loss=0.572173707219824\n",
      "GD iter. 92/499: loss=0.57195036620228\n",
      "GD iter. 93/499: loss=0.5717383010639185\n",
      "GD iter. 94/499: loss=0.5715126978251903\n",
      "GD iter. 95/499: loss=0.5713043621918709\n",
      "GD iter. 96/499: loss=0.5710871870987972\n",
      "GD iter. 97/499: loss=0.5708779824854077\n",
      "GD iter. 98/499: loss=0.5706614800361249\n",
      "GD iter. 99/499: loss=0.5704599280377655\n",
      "GD iter. 100/499: loss=0.5702792665680612\n",
      "GD iter. 101/499: loss=0.5700819604688998\n",
      "GD iter. 102/499: loss=0.5698792762884606\n",
      "GD iter. 103/499: loss=0.5696838234827456\n",
      "GD iter. 104/499: loss=0.5695029724547129\n",
      "GD iter. 105/499: loss=0.5693280844125166\n",
      "GD iter. 106/499: loss=0.569152539980007\n",
      "GD iter. 107/499: loss=0.5689548202414294\n",
      "GD iter. 108/499: loss=0.5687742419152192\n",
      "GD iter. 109/499: loss=0.5685946657156217\n",
      "GD iter. 110/499: loss=0.5684152194358032\n",
      "GD iter. 111/499: loss=0.5682427679794718\n",
      "GD iter. 112/499: loss=0.5680619085599785\n",
      "GD iter. 113/499: loss=0.5678929740828841\n",
      "GD iter. 114/499: loss=0.567723160346189\n",
      "GD iter. 115/499: loss=0.5675483363387701\n",
      "GD iter. 116/499: loss=0.5673769625386137\n",
      "GD iter. 117/499: loss=0.5672049009592667\n",
      "GD iter. 118/499: loss=0.5670527528460176\n",
      "GD iter. 119/499: loss=0.5668899594135038\n",
      "GD iter. 120/499: loss=0.5667313741007307\n",
      "GD iter. 121/499: loss=0.5665772389641952\n",
      "GD iter. 122/499: loss=0.566424333017998\n",
      "GD iter. 123/499: loss=0.5662616557581969\n",
      "GD iter. 124/499: loss=0.5661191546695324\n",
      "GD iter. 125/499: loss=0.5659668464212302\n",
      "GD iter. 126/499: loss=0.565809249988069\n",
      "GD iter. 127/499: loss=0.5656568013587369\n",
      "GD iter. 128/499: loss=0.565521312757415\n",
      "GD iter. 129/499: loss=0.5653708170278158\n",
      "GD iter. 130/499: loss=0.5652192592143863\n",
      "GD iter. 131/499: loss=0.5650637839701013\n",
      "GD iter. 132/499: loss=0.5649198836753838\n",
      "GD iter. 133/499: loss=0.564774004222425\n",
      "GD iter. 134/499: loss=0.564633061887828\n",
      "GD iter. 135/499: loss=0.5645038287901754\n",
      "GD iter. 136/499: loss=0.5643607169761257\n",
      "GD iter. 137/499: loss=0.5642193186728589\n",
      "GD iter. 138/499: loss=0.5640798191280477\n",
      "GD iter. 139/499: loss=0.563946785834864\n",
      "GD iter. 140/499: loss=0.5637971980113894\n",
      "GD iter. 141/499: loss=0.563675876042595\n",
      "GD iter. 142/499: loss=0.5635529232387538\n",
      "GD iter. 143/499: loss=0.5634366749694952\n",
      "GD iter. 144/499: loss=0.5632807573999119\n",
      "GD iter. 145/499: loss=0.5631529575522183\n",
      "GD iter. 146/499: loss=0.563035885654105\n",
      "GD iter. 147/499: loss=0.5629098177929494\n",
      "GD iter. 148/499: loss=0.5627827509100588\n",
      "GD iter. 149/499: loss=0.5626737531041422\n",
      "GD iter. 150/499: loss=0.5625437085724301\n",
      "GD iter. 151/499: loss=0.562410923492229\n",
      "GD iter. 152/499: loss=0.5622896789148233\n",
      "GD iter. 153/499: loss=0.5621769337810547\n",
      "GD iter. 154/499: loss=0.5620613735585164\n",
      "GD iter. 155/499: loss=0.5619514199364836\n",
      "GD iter. 156/499: loss=0.5618393166149068\n",
      "GD iter. 157/499: loss=0.5617185327128101\n",
      "GD iter. 158/499: loss=0.5616174179250603\n",
      "GD iter. 159/499: loss=0.5614974126799147\n",
      "GD iter. 160/499: loss=0.5613995687521441\n",
      "GD iter. 161/499: loss=0.5612893309373368\n",
      "GD iter. 162/499: loss=0.5612060310175269\n",
      "GD iter. 163/499: loss=0.5610864141893079\n",
      "GD iter. 164/499: loss=0.5609766215128186\n",
      "GD iter. 165/499: loss=0.5608843861417354\n",
      "GD iter. 166/499: loss=0.5607795122834665\n",
      "GD iter. 167/499: loss=0.5606883673908312\n",
      "GD iter. 168/499: loss=0.5605785714733794\n",
      "GD iter. 169/499: loss=0.5604783844691767\n",
      "GD iter. 170/499: loss=0.5603842952988528\n",
      "GD iter. 171/499: loss=0.5602769639308592\n",
      "GD iter. 172/499: loss=0.5601826433154969\n",
      "GD iter. 173/499: loss=0.5600921599159319\n",
      "GD iter. 174/499: loss=0.5599898410897193\n",
      "GD iter. 175/499: loss=0.5598895758091298\n",
      "GD iter. 176/499: loss=0.5597946600039551\n",
      "GD iter. 177/499: loss=0.5597042337707159\n",
      "GD iter. 178/499: loss=0.5596100098241439\n",
      "GD iter. 179/499: loss=0.5595051147954428\n",
      "GD iter. 180/499: loss=0.5594179517992374\n",
      "GD iter. 181/499: loss=0.5593443297265271\n",
      "GD iter. 182/499: loss=0.5592406535852797\n",
      "GD iter. 183/499: loss=0.5591452791509336\n",
      "GD iter. 184/499: loss=0.5590499419322902\n",
      "GD iter. 185/499: loss=0.5589571270749787\n",
      "GD iter. 186/499: loss=0.5588958634277655\n",
      "GD iter. 187/499: loss=0.5587908546825561\n",
      "GD iter. 188/499: loss=0.5586933934801358\n",
      "GD iter. 189/499: loss=0.5586134469269914\n",
      "GD iter. 190/499: loss=0.5585266916374639\n",
      "GD iter. 191/499: loss=0.5584291688829213\n",
      "GD iter. 192/499: loss=0.5583471646079088\n",
      "GD iter. 193/499: loss=0.5582652166076698\n",
      "GD iter. 194/499: loss=0.5581688959013403\n",
      "GD iter. 195/499: loss=0.5580842955201463\n",
      "GD iter. 196/499: loss=0.5580152937038569\n",
      "GD iter. 197/499: loss=0.5579291350174657\n",
      "GD iter. 198/499: loss=0.5578410038135756\n",
      "GD iter. 199/499: loss=0.5577574090243956\n",
      "GD iter. 200/499: loss=0.5576766158607317\n",
      "GD iter. 201/499: loss=0.5575816952137419\n",
      "GD iter. 202/499: loss=0.5574931178659095\n",
      "GD iter. 203/499: loss=0.5574229043651717\n",
      "GD iter. 204/499: loss=0.5573440120821332\n",
      "GD iter. 205/499: loss=0.557281196335169\n",
      "GD iter. 206/499: loss=0.5572076308622557\n",
      "GD iter. 207/499: loss=0.5571076279930546\n",
      "GD iter. 208/499: loss=0.5570276600539193\n",
      "GD iter. 209/499: loss=0.5569486005863896\n",
      "GD iter. 210/499: loss=0.5568789187513843\n",
      "GD iter. 211/499: loss=0.5568063626009905\n",
      "GD iter. 212/499: loss=0.5567460334123424\n",
      "GD iter. 213/499: loss=0.5566676203896735\n",
      "GD iter. 214/499: loss=0.5565805125620618\n",
      "GD iter. 215/499: loss=0.5565002097321383\n",
      "GD iter. 216/499: loss=0.5564337580906232\n",
      "GD iter. 217/499: loss=0.5563493043627137\n",
      "GD iter. 218/499: loss=0.5562834124858651\n",
      "GD iter. 219/499: loss=0.5562156004157722\n",
      "GD iter. 220/499: loss=0.5561321274791023\n",
      "GD iter. 221/499: loss=0.5560803885589556\n",
      "GD iter. 222/499: loss=0.5560113337158528\n",
      "GD iter. 223/499: loss=0.555939932747587\n",
      "GD iter. 224/499: loss=0.55588656931053\n",
      "GD iter. 225/499: loss=0.5558029213359243\n",
      "GD iter. 226/499: loss=0.5557582903442867\n",
      "GD iter. 227/499: loss=0.5556914405905051\n",
      "GD iter. 228/499: loss=0.5556229898605902\n",
      "GD iter. 229/499: loss=0.5555299696026053\n",
      "GD iter. 230/499: loss=0.5554641110662117\n",
      "GD iter. 231/499: loss=0.5554006266516036\n",
      "GD iter. 232/499: loss=0.5553369111853348\n",
      "GD iter. 233/499: loss=0.5552709818816222\n",
      "GD iter. 234/499: loss=0.555199422562581\n",
      "GD iter. 235/499: loss=0.5551262844806919\n",
      "GD iter. 236/499: loss=0.5550768601193372\n",
      "GD iter. 237/499: loss=0.5550003507117643\n",
      "GD iter. 238/499: loss=0.5549429695798102\n",
      "GD iter. 239/499: loss=0.5548602200703705\n",
      "GD iter. 240/499: loss=0.5548146015350086\n",
      "GD iter. 241/499: loss=0.5547475504878232\n",
      "GD iter. 242/499: loss=0.5546960503451847\n",
      "GD iter. 243/499: loss=0.5546111664176498\n",
      "GD iter. 244/499: loss=0.5545487531605716\n",
      "GD iter. 245/499: loss=0.5544771832230783\n",
      "GD iter. 246/499: loss=0.5544237097637736\n",
      "GD iter. 247/499: loss=0.5543592191273483\n",
      "GD iter. 248/499: loss=0.5543068845559945\n",
      "GD iter. 249/499: loss=0.5542545780379919\n",
      "GD iter. 250/499: loss=0.5541877262852907\n",
      "GD iter. 251/499: loss=0.5541111053214287\n",
      "GD iter. 252/499: loss=0.5540591263795768\n",
      "GD iter. 253/499: loss=0.554025649118293\n",
      "GD iter. 254/499: loss=0.5539275689896527\n",
      "GD iter. 255/499: loss=0.5538729985200571\n",
      "GD iter. 256/499: loss=0.5537932076123622\n",
      "GD iter. 257/499: loss=0.5537633858244988\n",
      "GD iter. 258/499: loss=0.5537087586722829\n",
      "GD iter. 259/499: loss=0.553646043753747\n",
      "GD iter. 260/499: loss=0.5535947036245369\n",
      "GD iter. 261/499: loss=0.5535394222363657\n",
      "GD iter. 262/499: loss=0.5534923145392217\n",
      "GD iter. 263/499: loss=0.5534261915586249\n",
      "GD iter. 264/499: loss=0.5533651539623483\n",
      "GD iter. 265/499: loss=0.5533125414105465\n",
      "GD iter. 266/499: loss=0.5532453187193309\n",
      "GD iter. 267/499: loss=0.5532001135012375\n",
      "GD iter. 268/499: loss=0.5531422427715376\n",
      "GD iter. 269/499: loss=0.5530912351323121\n",
      "GD iter. 270/499: loss=0.553032619895041\n",
      "GD iter. 271/499: loss=0.5529648335728762\n",
      "GD iter. 272/499: loss=0.5529501160532058\n",
      "GD iter. 273/499: loss=0.5528698704288757\n",
      "GD iter. 274/499: loss=0.5528254984929816\n",
      "GD iter. 275/499: loss=0.552773732029459\n",
      "GD iter. 276/499: loss=0.5527236651780469\n",
      "GD iter. 277/499: loss=0.55269301274663\n",
      "GD iter. 278/499: loss=0.5526540235723725\n",
      "GD iter. 279/499: loss=0.5525674607439268\n",
      "GD iter. 280/499: loss=0.5525160466347235\n",
      "GD iter. 281/499: loss=0.5524662068878821\n",
      "GD iter. 282/499: loss=0.5524149780899057\n",
      "GD iter. 283/499: loss=0.5523933593084962\n",
      "GD iter. 284/499: loss=0.5523232728307461\n",
      "GD iter. 285/499: loss=0.5522766408393698\n",
      "GD iter. 286/499: loss=0.5522177739898729\n",
      "GD iter. 287/499: loss=0.5521717016242673\n",
      "GD iter. 288/499: loss=0.5521554343320415\n",
      "GD iter. 289/499: loss=0.5520750951386043\n",
      "GD iter. 290/499: loss=0.5520062493845033\n",
      "GD iter. 291/499: loss=0.5519563854855335\n",
      "GD iter. 292/499: loss=0.5519175485864297\n",
      "GD iter. 293/499: loss=0.5518835285042681\n",
      "GD iter. 294/499: loss=0.5518452064918633\n",
      "GD iter. 295/499: loss=0.5517827481500956\n",
      "GD iter. 296/499: loss=0.5517199318699247\n",
      "GD iter. 297/499: loss=0.5516963918550475\n",
      "GD iter. 298/499: loss=0.5516873587911145\n",
      "GD iter. 299/499: loss=0.5516089502627171\n",
      "GD iter. 300/499: loss=0.5515735406410247\n",
      "GD iter. 301/499: loss=0.5515203398461689\n",
      "GD iter. 302/499: loss=0.5514571205058375\n",
      "GD iter. 303/499: loss=0.5514390599861629\n",
      "GD iter. 304/499: loss=0.5513871821795835\n",
      "GD iter. 305/499: loss=0.5513380288578332\n",
      "GD iter. 306/499: loss=0.5513183179751753\n",
      "GD iter. 307/499: loss=0.5512470032223502\n",
      "GD iter. 308/499: loss=0.5512057660338789\n",
      "GD iter. 309/499: loss=0.5511751437313164\n",
      "GD iter. 310/499: loss=0.551162077490833\n",
      "GD iter. 311/499: loss=0.5511073427607168\n",
      "GD iter. 312/499: loss=0.5510436389295359\n",
      "GD iter. 313/499: loss=0.5510273673458395\n",
      "GD iter. 314/499: loss=0.5510040507541091\n",
      "GD iter. 315/499: loss=0.5509421515840947\n",
      "GD iter. 316/499: loss=0.5508752370683649\n",
      "GD iter. 317/499: loss=0.5508390824471349\n",
      "GD iter. 318/499: loss=0.5508186033506092\n",
      "GD iter. 319/499: loss=0.5507523402537663\n",
      "GD iter. 320/499: loss=0.5507281110013718\n",
      "GD iter. 321/499: loss=0.5506916341132155\n",
      "GD iter. 322/499: loss=0.5506468379609721\n",
      "GD iter. 323/499: loss=0.5506211836268687\n",
      "GD iter. 324/499: loss=0.5506023274985843\n",
      "GD iter. 325/499: loss=0.5505624623609022\n",
      "GD iter. 326/499: loss=0.5505040727493253\n",
      "GD iter. 327/499: loss=0.5504804996691628\n",
      "GD iter. 328/499: loss=0.5504380232521733\n",
      "GD iter. 329/499: loss=0.5503846866864723\n",
      "GD iter. 330/499: loss=0.5503535339645468\n",
      "GD iter. 331/499: loss=0.5503457325629091\n",
      "GD iter. 332/499: loss=0.550281422343579\n",
      "GD iter. 333/499: loss=0.5502405707601373\n",
      "GD iter. 334/499: loss=0.5501997484839106\n",
      "GD iter. 335/499: loss=0.5501555714551152\n",
      "GD iter. 336/499: loss=0.5501544462448759\n",
      "GD iter. 337/499: loss=0.5501121000315797\n",
      "GD iter. 338/499: loss=0.5500450805318267\n",
      "GD iter. 339/499: loss=0.5500286653695389\n",
      "GD iter. 340/499: loss=0.5499784648223462\n",
      "GD iter. 341/499: loss=0.5499368630760767\n",
      "GD iter. 342/499: loss=0.5499212151794793\n",
      "GD iter. 343/499: loss=0.5498974891914673\n",
      "GD iter. 344/499: loss=0.5498426321362101\n",
      "GD iter. 345/499: loss=0.5497895548039022\n",
      "GD iter. 346/499: loss=0.5497746196803859\n",
      "GD iter. 347/499: loss=0.5497207791919939\n",
      "GD iter. 348/499: loss=0.549685216370603\n",
      "GD iter. 349/499: loss=0.5496593560798947\n",
      "GD iter. 350/499: loss=0.5496113504609601\n",
      "GD iter. 351/499: loss=0.5495878699417497\n",
      "GD iter. 352/499: loss=0.5495503096859912\n",
      "GD iter. 353/499: loss=0.5494978231098548\n",
      "GD iter. 354/499: loss=0.5494670325489657\n",
      "GD iter. 355/499: loss=0.549450154350468\n",
      "GD iter. 356/499: loss=0.5493946799057244\n",
      "GD iter. 357/499: loss=0.5493738143665586\n",
      "GD iter. 358/499: loss=0.5493527379031773\n",
      "GD iter. 359/499: loss=0.5493026482634525\n",
      "GD iter. 360/499: loss=0.549275261518377\n",
      "GD iter. 361/499: loss=0.5492399770551172\n",
      "GD iter. 362/499: loss=0.5492120334921949\n",
      "GD iter. 363/499: loss=0.549200034413521\n",
      "GD iter. 364/499: loss=0.5491522800850626\n",
      "GD iter. 365/499: loss=0.5491154828588937\n",
      "GD iter. 366/499: loss=0.5490870523994322\n",
      "GD iter. 367/499: loss=0.5490698746414053\n",
      "GD iter. 368/499: loss=0.549030066452316\n",
      "GD iter. 369/499: loss=0.5489932288155109\n",
      "GD iter. 370/499: loss=0.5489674743599957\n",
      "GD iter. 371/499: loss=0.5489315948017658\n",
      "GD iter. 372/499: loss=0.5488820009982568\n",
      "GD iter. 373/499: loss=0.5488570654927366\n",
      "GD iter. 374/499: loss=0.5488315661795948\n",
      "GD iter. 375/499: loss=0.5488425129087513\n",
      "GD iter. 376/499: loss=0.5487511079046573\n",
      "GD iter. 377/499: loss=0.5487394252739501\n",
      "GD iter. 378/499: loss=0.5486902340085476\n",
      "GD iter. 379/499: loss=0.5486498186555423\n",
      "GD iter. 380/499: loss=0.5486322349464173\n",
      "GD iter. 381/499: loss=0.5485829941582518\n",
      "GD iter. 382/499: loss=0.5485729220548929\n",
      "GD iter. 383/499: loss=0.5485338670088159\n",
      "GD iter. 384/499: loss=0.5485404595169338\n",
      "GD iter. 385/499: loss=0.5484824576149564\n",
      "GD iter. 386/499: loss=0.5484582548648909\n",
      "GD iter. 387/499: loss=0.5484415620677238\n",
      "GD iter. 388/499: loss=0.5483986641959965\n",
      "GD iter. 389/499: loss=0.5483640737219393\n",
      "GD iter. 390/499: loss=0.5483615853007024\n",
      "GD iter. 391/499: loss=0.5483350793296838\n",
      "GD iter. 392/499: loss=0.5482983976321468\n",
      "GD iter. 393/499: loss=0.5482482637726384\n",
      "GD iter. 394/499: loss=0.5482224858644885\n",
      "GD iter. 395/499: loss=0.5482091948515979\n",
      "GD iter. 396/499: loss=0.5481567339603881\n",
      "GD iter. 397/499: loss=0.5481408888379934\n",
      "GD iter. 398/499: loss=0.5480973569079851\n",
      "GD iter. 399/499: loss=0.5480820984615059\n",
      "GD iter. 400/499: loss=0.5480149122881692\n",
      "GD iter. 401/499: loss=0.5480109746890006\n",
      "GD iter. 402/499: loss=0.5480016003030039\n",
      "GD iter. 403/499: loss=0.5479589723606679\n",
      "GD iter. 404/499: loss=0.5479256810201707\n",
      "GD iter. 405/499: loss=0.5479214493683614\n",
      "GD iter. 406/499: loss=0.5478667969777461\n",
      "GD iter. 407/499: loss=0.5478699891149282\n",
      "GD iter. 408/499: loss=0.5478245084404059\n",
      "GD iter. 409/499: loss=0.5478113262516423\n",
      "GD iter. 410/499: loss=0.5477993234483373\n",
      "GD iter. 411/499: loss=0.5477617722395757\n",
      "GD iter. 412/499: loss=0.5477334601939203\n",
      "GD iter. 413/499: loss=0.5477096107991887\n",
      "GD iter. 414/499: loss=0.5476777786870431\n",
      "GD iter. 415/499: loss=0.547648512066829\n",
      "GD iter. 416/499: loss=0.5476507862210028\n",
      "GD iter. 417/499: loss=0.5476057039602112\n",
      "GD iter. 418/499: loss=0.5475908739982249\n",
      "GD iter. 419/499: loss=0.5475811249269728\n",
      "GD iter. 420/499: loss=0.5475378526288261\n",
      "GD iter. 421/499: loss=0.5475171756368505\n",
      "GD iter. 422/499: loss=0.5474731295784772\n",
      "GD iter. 423/499: loss=0.5474530840299366\n",
      "GD iter. 424/499: loss=0.5474437550578517\n",
      "GD iter. 425/499: loss=0.5474402083687309\n",
      "GD iter. 426/499: loss=0.5473941163659852\n",
      "GD iter. 427/499: loss=0.5473685434946303\n",
      "GD iter. 428/499: loss=0.5473452444616157\n",
      "GD iter. 429/499: loss=0.5473017907835551\n",
      "GD iter. 430/499: loss=0.5473210422678975\n",
      "GD iter. 431/499: loss=0.5472722265389676\n",
      "GD iter. 432/499: loss=0.5472360436669353\n",
      "GD iter. 433/499: loss=0.547244953497621\n",
      "GD iter. 434/499: loss=0.5471830503642313\n",
      "GD iter. 435/499: loss=0.5471533372596731\n",
      "GD iter. 436/499: loss=0.5471375612888535\n",
      "GD iter. 437/499: loss=0.5471139158806518\n",
      "GD iter. 438/499: loss=0.5470883022208114\n",
      "GD iter. 439/499: loss=0.547068921797425\n",
      "GD iter. 440/499: loss=0.5470880259511497\n",
      "GD iter. 441/499: loss=0.5470628062100747\n",
      "GD iter. 442/499: loss=0.5470193792520281\n",
      "GD iter. 443/499: loss=0.5469767122020991\n",
      "GD iter. 444/499: loss=0.5469550614147121\n",
      "GD iter. 445/499: loss=0.5469522280808446\n",
      "GD iter. 446/499: loss=0.5469516814849452\n",
      "GD iter. 447/499: loss=0.5469289032776645\n",
      "GD iter. 448/499: loss=0.5468764040591456\n",
      "GD iter. 449/499: loss=0.5468635772496894\n",
      "GD iter. 450/499: loss=0.5468292726504524\n",
      "GD iter. 451/499: loss=0.5468212791291556\n",
      "GD iter. 452/499: loss=0.5467803690315155\n",
      "GD iter. 453/499: loss=0.5467626518296411\n",
      "GD iter. 454/499: loss=0.5467337761666758\n",
      "GD iter. 455/499: loss=0.5466893096307952\n",
      "GD iter. 456/499: loss=0.5467182367217538\n",
      "GD iter. 457/499: loss=0.5466744553890697\n",
      "GD iter. 458/499: loss=0.5466801712496745\n",
      "GD iter. 459/499: loss=0.5466390739006588\n",
      "GD iter. 460/499: loss=0.5466110318586843\n",
      "GD iter. 461/499: loss=0.5465924216489572\n",
      "GD iter. 462/499: loss=0.5465775088527751\n",
      "GD iter. 463/499: loss=0.5465835202698176\n",
      "GD iter. 464/499: loss=0.5465640221061284\n",
      "GD iter. 465/499: loss=0.5465092609645488\n",
      "GD iter. 466/499: loss=0.5464825032417904\n",
      "GD iter. 467/499: loss=0.5464874537727302\n",
      "GD iter. 468/499: loss=0.5465002857793354\n",
      "GD iter. 469/499: loss=0.5464753541110104\n",
      "GD iter. 470/499: loss=0.5464068040532095\n",
      "GD iter. 471/499: loss=0.546362979111876\n",
      "GD iter. 472/499: loss=0.5463526569267769\n",
      "GD iter. 473/499: loss=0.5463401030363867\n",
      "GD iter. 474/499: loss=0.5463439418667639\n",
      "GD iter. 475/499: loss=0.5463515419363228\n",
      "GD iter. 476/499: loss=0.5462879968844294\n",
      "GD iter. 477/499: loss=0.5462863039149278\n",
      "GD iter. 478/499: loss=0.5463025955515185\n",
      "GD iter. 479/499: loss=0.5462799602536101\n",
      "GD iter. 480/499: loss=0.5462452755301447\n",
      "GD iter. 481/499: loss=0.546232626610795\n",
      "GD iter. 482/499: loss=0.546191643059224\n",
      "GD iter. 483/499: loss=0.5461763621504149\n",
      "GD iter. 484/499: loss=0.5461646870989492\n",
      "GD iter. 485/499: loss=0.5461788724905537\n",
      "GD iter. 486/499: loss=0.5461430047559818\n",
      "GD iter. 487/499: loss=0.5461520139933258\n",
      "GD iter. 488/499: loss=0.5460936060072311\n",
      "GD iter. 489/499: loss=0.5460520454008064\n",
      "GD iter. 490/499: loss=0.5460460042491566\n",
      "GD iter. 491/499: loss=0.5460402521627662\n",
      "GD iter. 492/499: loss=0.5460636389090359\n",
      "GD iter. 493/499: loss=0.5460786133020419\n",
      "GD iter. 494/499: loss=0.5459976261617966\n",
      "GD iter. 495/499: loss=0.5459945935965269\n",
      "GD iter. 496/499: loss=0.5459682435304033\n",
      "GD iter. 497/499: loss=0.5459871585626703\n",
      "GD iter. 498/499: loss=0.5459271983706746\n",
      "GD iter. 499/499: loss=0.5459125190949753\n",
      "The Accuracy is: 0.6902\n",
      "The F1 score is: 0.3322\n",
      "The precision is: 0.2080\n",
      "The recall is: 0.8246\n",
      "GD iter. 0/499: loss=0.9995797927690094\n",
      "GD iter. 1/499: loss=0.924614845137386\n",
      "GD iter. 2/499: loss=0.8527190164361145\n",
      "GD iter. 3/499: loss=0.7931822379894717\n",
      "GD iter. 4/499: loss=0.7509137127133462\n",
      "GD iter. 5/499: loss=0.721908914830924\n",
      "GD iter. 6/499: loss=0.701703790389714\n",
      "GD iter. 7/499: loss=0.6864140575503144\n",
      "GD iter. 8/499: loss=0.6743573044813366\n",
      "GD iter. 9/499: loss=0.6649689869252631\n",
      "GD iter. 10/499: loss=0.6572100318003198\n",
      "GD iter. 11/499: loss=0.6503090845802451\n",
      "GD iter. 12/499: loss=0.6449824567116228\n",
      "GD iter. 13/499: loss=0.640461739673346\n",
      "GD iter. 14/499: loss=0.6365415940656712\n",
      "GD iter. 15/499: loss=0.6329351832986613\n",
      "GD iter. 16/499: loss=0.6296398383213848\n",
      "GD iter. 17/499: loss=0.6266997079789873\n",
      "GD iter. 18/499: loss=0.6241974722618819\n",
      "GD iter. 19/499: loss=0.6217983982338463\n",
      "GD iter. 20/499: loss=0.6195709143998885\n",
      "GD iter. 21/499: loss=0.6176125669160443\n",
      "GD iter. 22/499: loss=0.6157597437588254\n",
      "GD iter. 23/499: loss=0.6140111997094959\n",
      "GD iter. 24/499: loss=0.6123975756332792\n",
      "GD iter. 25/499: loss=0.6108512305580305\n",
      "GD iter. 26/499: loss=0.6093578522370281\n",
      "GD iter. 27/499: loss=0.6079751577881723\n",
      "GD iter. 28/499: loss=0.606617064832276\n",
      "GD iter. 29/499: loss=0.6053197910610084\n",
      "GD iter. 30/499: loss=0.6041113167046097\n",
      "GD iter. 31/499: loss=0.6029918433004102\n",
      "GD iter. 32/499: loss=0.6019295314773974\n",
      "GD iter. 33/499: loss=0.6009290294941874\n",
      "GD iter. 34/499: loss=0.5999440078746932\n",
      "GD iter. 35/499: loss=0.5989875932040784\n",
      "GD iter. 36/499: loss=0.5980649391066262\n",
      "GD iter. 37/499: loss=0.5971702922870018\n",
      "GD iter. 38/499: loss=0.5963288206698657\n",
      "GD iter. 39/499: loss=0.5955201636885161\n",
      "GD iter. 40/499: loss=0.5947727910353394\n",
      "GD iter. 41/499: loss=0.5940619145371714\n",
      "GD iter. 42/499: loss=0.5933491182273887\n",
      "GD iter. 43/499: loss=0.5926778065593702\n",
      "GD iter. 44/499: loss=0.5920447344445828\n",
      "GD iter. 45/499: loss=0.59142482934951\n",
      "GD iter. 46/499: loss=0.5908110514694945\n",
      "GD iter. 47/499: loss=0.5901984771666242\n",
      "GD iter. 48/499: loss=0.5895974152834791\n",
      "GD iter. 49/499: loss=0.5890247359027004\n",
      "GD iter. 50/499: loss=0.5884656852559947\n",
      "GD iter. 51/499: loss=0.5879177225595468\n",
      "GD iter. 52/499: loss=0.5873909109479388\n",
      "GD iter. 53/499: loss=0.5868566661708833\n",
      "GD iter. 54/499: loss=0.5863217678469387\n",
      "GD iter. 55/499: loss=0.5858026464433965\n",
      "GD iter. 56/499: loss=0.5852824893645805\n",
      "GD iter. 57/499: loss=0.5847678328491986\n",
      "GD iter. 58/499: loss=0.5842515486003771\n",
      "GD iter. 59/499: loss=0.5837585993091179\n",
      "GD iter. 60/499: loss=0.5832569497310931\n",
      "GD iter. 61/499: loss=0.5827716932382672\n",
      "GD iter. 62/499: loss=0.5823097675515482\n",
      "GD iter. 63/499: loss=0.5818718908390051\n",
      "GD iter. 64/499: loss=0.581438916371837\n",
      "GD iter. 65/499: loss=0.5810198062791601\n",
      "GD iter. 66/499: loss=0.5806051101254435\n",
      "GD iter. 67/499: loss=0.5801946789237813\n",
      "GD iter. 68/499: loss=0.5797965008503289\n",
      "GD iter. 69/499: loss=0.579401664974249\n",
      "GD iter. 70/499: loss=0.5790126652225016\n",
      "GD iter. 71/499: loss=0.5786434263529616\n",
      "GD iter. 72/499: loss=0.5782759515875344\n",
      "GD iter. 73/499: loss=0.5779092552556262\n",
      "GD iter. 74/499: loss=0.577550043535653\n",
      "GD iter. 75/499: loss=0.5771993641546971\n",
      "GD iter. 76/499: loss=0.5768622238301728\n",
      "GD iter. 77/499: loss=0.5765221238268317\n",
      "GD iter. 78/499: loss=0.5761835278506496\n",
      "GD iter. 79/499: loss=0.57585391576458\n",
      "GD iter. 80/499: loss=0.5755368081899899\n",
      "GD iter. 81/499: loss=0.5752355601831901\n",
      "GD iter. 82/499: loss=0.5749406949398437\n",
      "GD iter. 83/499: loss=0.5746479163814001\n",
      "GD iter. 84/499: loss=0.5743592116625702\n",
      "GD iter. 85/499: loss=0.5740798072942912\n",
      "GD iter. 86/499: loss=0.5737887988402046\n",
      "GD iter. 87/499: loss=0.5735070930408442\n",
      "GD iter. 88/499: loss=0.5732247898975015\n",
      "GD iter. 89/499: loss=0.5729488319514284\n",
      "GD iter. 90/499: loss=0.5726621804190012\n",
      "GD iter. 91/499: loss=0.5723944576864931\n",
      "GD iter. 92/499: loss=0.5721315883254559\n",
      "GD iter. 93/499: loss=0.5718643829738702\n",
      "GD iter. 94/499: loss=0.571612488474567\n",
      "GD iter. 95/499: loss=0.5713427333012984\n",
      "GD iter. 96/499: loss=0.5710749020426067\n",
      "GD iter. 97/499: loss=0.5708190632688396\n",
      "GD iter. 98/499: loss=0.5705625646820186\n",
      "GD iter. 99/499: loss=0.5702978748257022\n",
      "GD iter. 100/499: loss=0.5700590269720726\n",
      "GD iter. 101/499: loss=0.5698196788174126\n",
      "GD iter. 102/499: loss=0.5695802545702369\n",
      "GD iter. 103/499: loss=0.569343998965607\n",
      "GD iter. 104/499: loss=0.5691159331779977\n",
      "GD iter. 105/499: loss=0.5688768805539711\n",
      "GD iter. 106/499: loss=0.5686524323919261\n",
      "GD iter. 107/499: loss=0.5684311390431738\n",
      "GD iter. 108/499: loss=0.5682192984963136\n",
      "GD iter. 109/499: loss=0.5679959822699243\n",
      "GD iter. 110/499: loss=0.5677775358261746\n",
      "GD iter. 111/499: loss=0.5675678507539743\n",
      "GD iter. 112/499: loss=0.5673610154857167\n",
      "GD iter. 113/499: loss=0.5671561488054199\n",
      "GD iter. 114/499: loss=0.5669677582550327\n",
      "GD iter. 115/499: loss=0.5667825213580074\n",
      "GD iter. 116/499: loss=0.5665978044914268\n",
      "GD iter. 117/499: loss=0.5664199757362199\n",
      "GD iter. 118/499: loss=0.5662715151749529\n",
      "GD iter. 119/499: loss=0.5661070974639121\n",
      "GD iter. 120/499: loss=0.5659305271395612\n",
      "GD iter. 121/499: loss=0.5657703912708398\n",
      "GD iter. 122/499: loss=0.5655976240684293\n",
      "GD iter. 123/499: loss=0.5654287741876584\n",
      "GD iter. 124/499: loss=0.5652658071244749\n",
      "GD iter. 125/499: loss=0.5651285769243081\n",
      "GD iter. 126/499: loss=0.5649530889791223\n",
      "GD iter. 127/499: loss=0.5647776991104138\n",
      "GD iter. 128/499: loss=0.5646271932579442\n",
      "GD iter. 129/499: loss=0.5644679886413819\n",
      "GD iter. 130/499: loss=0.5643121493533692\n",
      "GD iter. 131/499: loss=0.5641647877326462\n",
      "GD iter. 132/499: loss=0.5639961346397053\n",
      "GD iter. 133/499: loss=0.5638388364613114\n",
      "GD iter. 134/499: loss=0.5636966283112979\n",
      "GD iter. 135/499: loss=0.5635367975894094\n",
      "GD iter. 136/499: loss=0.5633924977552418\n",
      "GD iter. 137/499: loss=0.5632321755186585\n",
      "GD iter. 138/499: loss=0.5631003938897601\n",
      "GD iter. 139/499: loss=0.5629411216970068\n",
      "GD iter. 140/499: loss=0.5628107174464326\n",
      "GD iter. 141/499: loss=0.5626782061444895\n",
      "GD iter. 142/499: loss=0.5625244568448723\n",
      "GD iter. 143/499: loss=0.5623951850534217\n",
      "GD iter. 144/499: loss=0.5622419520257138\n",
      "GD iter. 145/499: loss=0.5621058644516275\n",
      "GD iter. 146/499: loss=0.5619596902173774\n",
      "GD iter. 147/499: loss=0.5618444077398802\n",
      "GD iter. 148/499: loss=0.5616957049015204\n",
      "GD iter. 149/499: loss=0.5615551478825982\n",
      "GD iter. 150/499: loss=0.5614215328776047\n",
      "GD iter. 151/499: loss=0.5612871268764628\n",
      "GD iter. 152/499: loss=0.5611605056175264\n",
      "GD iter. 153/499: loss=0.5610483495809363\n",
      "GD iter. 154/499: loss=0.560922107431366\n",
      "GD iter. 155/499: loss=0.5608104759997121\n",
      "GD iter. 156/499: loss=0.560696891098076\n",
      "GD iter. 157/499: loss=0.5605664376654695\n",
      "GD iter. 158/499: loss=0.5604616405430519\n",
      "GD iter. 159/499: loss=0.5603459384208385\n",
      "GD iter. 160/499: loss=0.5602353094851625\n",
      "GD iter. 161/499: loss=0.560132444265197\n",
      "GD iter. 162/499: loss=0.5600263440118453\n",
      "GD iter. 163/499: loss=0.5599422664088444\n",
      "GD iter. 164/499: loss=0.559832064503659\n",
      "GD iter. 165/499: loss=0.5597316611906921\n",
      "GD iter. 166/499: loss=0.559628299422364\n",
      "GD iter. 167/499: loss=0.5595254649916878\n",
      "GD iter. 168/499: loss=0.5593990366401855\n",
      "GD iter. 169/499: loss=0.5593183933370308\n",
      "GD iter. 170/499: loss=0.5592019485937831\n",
      "GD iter. 171/499: loss=0.559108586115641\n",
      "GD iter. 172/499: loss=0.559010185204267\n",
      "GD iter. 173/499: loss=0.5589238652197325\n",
      "GD iter. 174/499: loss=0.5588404302371569\n",
      "GD iter. 175/499: loss=0.558736513877112\n",
      "GD iter. 176/499: loss=0.558650347878033\n",
      "GD iter. 177/499: loss=0.558570720092159\n",
      "GD iter. 178/499: loss=0.558481996087669\n",
      "GD iter. 179/499: loss=0.5584101761078542\n",
      "GD iter. 180/499: loss=0.5583383750819118\n",
      "GD iter. 181/499: loss=0.5582465275632436\n",
      "GD iter. 182/499: loss=0.5581541520538227\n",
      "GD iter. 183/499: loss=0.5580798342847492\n",
      "GD iter. 184/499: loss=0.5579907102235452\n",
      "GD iter. 185/499: loss=0.557901504170429\n",
      "GD iter. 186/499: loss=0.5578279928347714\n",
      "GD iter. 187/499: loss=0.5577342043983907\n",
      "GD iter. 188/499: loss=0.5576655858586554\n",
      "GD iter. 189/499: loss=0.5575885486177112\n",
      "GD iter. 190/499: loss=0.5575135580224997\n",
      "GD iter. 191/499: loss=0.5574332068101109\n",
      "GD iter. 192/499: loss=0.5573336819666158\n",
      "GD iter. 193/499: loss=0.5572818329674831\n",
      "GD iter. 194/499: loss=0.5571796771055065\n",
      "GD iter. 195/499: loss=0.5571044712711133\n",
      "GD iter. 196/499: loss=0.5570203683411276\n",
      "GD iter. 197/499: loss=0.5569506457579265\n",
      "GD iter. 198/499: loss=0.5568763514069481\n",
      "GD iter. 199/499: loss=0.5567962535221644\n",
      "GD iter. 200/499: loss=0.5567163939879668\n",
      "GD iter. 201/499: loss=0.5566537367526888\n",
      "GD iter. 202/499: loss=0.5565782240797879\n",
      "GD iter. 203/499: loss=0.5564793256398143\n",
      "GD iter. 204/499: loss=0.556430545777018\n",
      "GD iter. 205/499: loss=0.5563370735848479\n",
      "GD iter. 206/499: loss=0.5562487549689116\n",
      "GD iter. 207/499: loss=0.5561931883976811\n",
      "GD iter. 208/499: loss=0.5561119397159865\n",
      "GD iter. 209/499: loss=0.5560268466390482\n",
      "GD iter. 210/499: loss=0.5559731795931934\n",
      "GD iter. 211/499: loss=0.5558852339893171\n",
      "GD iter. 212/499: loss=0.5558433962417724\n",
      "GD iter. 213/499: loss=0.5557486603854954\n",
      "GD iter. 214/499: loss=0.5556709817986429\n",
      "GD iter. 215/499: loss=0.5555903018536522\n",
      "GD iter. 216/499: loss=0.5555300570054744\n",
      "GD iter. 217/499: loss=0.5554620666525026\n",
      "GD iter. 218/499: loss=0.5553840490596602\n",
      "GD iter. 219/499: loss=0.5553098318768696\n",
      "GD iter. 220/499: loss=0.5552393965234934\n",
      "GD iter. 221/499: loss=0.5551666693967972\n",
      "GD iter. 222/499: loss=0.5550909320832805\n",
      "GD iter. 223/499: loss=0.5550372310259493\n",
      "GD iter. 224/499: loss=0.5549507521086933\n",
      "GD iter. 225/499: loss=0.5549047207600748\n",
      "GD iter. 226/499: loss=0.5548333555578604\n",
      "GD iter. 227/499: loss=0.5547660167183409\n",
      "GD iter. 228/499: loss=0.5547027374296245\n",
      "GD iter. 229/499: loss=0.5546285155642462\n",
      "GD iter. 230/499: loss=0.5545713270399326\n",
      "GD iter. 231/499: loss=0.5545296534282166\n",
      "GD iter. 232/499: loss=0.554458985710405\n",
      "GD iter. 233/499: loss=0.5543794068143019\n",
      "GD iter. 234/499: loss=0.5543307153485537\n",
      "GD iter. 235/499: loss=0.5542541011056121\n",
      "GD iter. 236/499: loss=0.5542053894046994\n",
      "GD iter. 237/499: loss=0.5541807217725627\n",
      "GD iter. 238/499: loss=0.5541164324697126\n",
      "GD iter. 239/499: loss=0.554067881562464\n",
      "GD iter. 240/499: loss=0.5539971243111829\n",
      "GD iter. 241/499: loss=0.5539457808525775\n",
      "GD iter. 242/499: loss=0.5538686131920331\n",
      "GD iter. 243/499: loss=0.5538469511813234\n",
      "GD iter. 244/499: loss=0.5537882387063491\n",
      "GD iter. 245/499: loss=0.5537403863237421\n",
      "GD iter. 246/499: loss=0.5536617925706167\n",
      "GD iter. 247/499: loss=0.5536057979330504\n",
      "GD iter. 248/499: loss=0.5535668119480858\n",
      "GD iter. 249/499: loss=0.5535273410639749\n",
      "GD iter. 250/499: loss=0.5534475544781874\n",
      "GD iter. 251/499: loss=0.5534199332845151\n",
      "GD iter. 252/499: loss=0.553364659932603\n",
      "GD iter. 253/499: loss=0.5533108341402599\n",
      "GD iter. 254/499: loss=0.5532489470821512\n",
      "GD iter. 255/499: loss=0.5531873259871337\n",
      "GD iter. 256/499: loss=0.5531425807385262\n",
      "GD iter. 257/499: loss=0.5531333239556318\n",
      "GD iter. 258/499: loss=0.5530581808992495\n",
      "GD iter. 259/499: loss=0.5530130593696404\n",
      "GD iter. 260/499: loss=0.5529322264372643\n",
      "GD iter. 261/499: loss=0.5529067212422678\n",
      "GD iter. 262/499: loss=0.5528372565663209\n",
      "GD iter. 263/499: loss=0.5528002779838674\n",
      "GD iter. 264/499: loss=0.5527374649188713\n",
      "GD iter. 265/499: loss=0.5526947457950908\n",
      "GD iter. 266/499: loss=0.5526328331916948\n",
      "GD iter. 267/499: loss=0.5525974449431424\n",
      "GD iter. 268/499: loss=0.5525543695779436\n",
      "GD iter. 269/499: loss=0.5524896289532224\n",
      "GD iter. 270/499: loss=0.5524860334544851\n",
      "GD iter. 271/499: loss=0.5524181040002645\n",
      "GD iter. 272/499: loss=0.55235956241858\n",
      "GD iter. 273/499: loss=0.5523206999937811\n",
      "GD iter. 274/499: loss=0.5522698472375227\n",
      "GD iter. 275/499: loss=0.5522188394154443\n",
      "GD iter. 276/499: loss=0.5521553599577826\n",
      "GD iter. 277/499: loss=0.552126675883785\n",
      "GD iter. 278/499: loss=0.5520713347370306\n",
      "GD iter. 279/499: loss=0.5520321779225655\n",
      "GD iter. 280/499: loss=0.5519508776364223\n",
      "GD iter. 281/499: loss=0.5519544060150334\n",
      "GD iter. 282/499: loss=0.5519029926488125\n",
      "GD iter. 283/499: loss=0.5518408195344644\n",
      "GD iter. 284/499: loss=0.5517732338857411\n",
      "GD iter. 285/499: loss=0.5517345872572618\n",
      "GD iter. 286/499: loss=0.5516838978934324\n",
      "GD iter. 287/499: loss=0.55161423273824\n",
      "GD iter. 288/499: loss=0.5515991050592028\n",
      "GD iter. 289/499: loss=0.5515613052562899\n",
      "GD iter. 290/499: loss=0.5514974952791707\n",
      "GD iter. 291/499: loss=0.5514713905100251\n",
      "GD iter. 292/499: loss=0.5514271634301242\n",
      "GD iter. 293/499: loss=0.551361673337302\n",
      "GD iter. 294/499: loss=0.5513157145821167\n",
      "GD iter. 295/499: loss=0.55127962030083\n",
      "GD iter. 296/499: loss=0.551242295658657\n",
      "GD iter. 297/499: loss=0.5512171040688632\n",
      "GD iter. 298/499: loss=0.5511808560395971\n",
      "GD iter. 299/499: loss=0.5511171067983808\n",
      "GD iter. 300/499: loss=0.5510723159975193\n",
      "GD iter. 301/499: loss=0.5510423558117845\n",
      "GD iter. 302/499: loss=0.5510330779679782\n",
      "GD iter. 303/499: loss=0.5509453522039082\n",
      "GD iter. 304/499: loss=0.550898521749912\n",
      "GD iter. 305/499: loss=0.5508420037424289\n",
      "GD iter. 306/499: loss=0.550825155547187\n",
      "GD iter. 307/499: loss=0.5507875709952073\n",
      "GD iter. 308/499: loss=0.5507368647082074\n",
      "GD iter. 309/499: loss=0.550679074968675\n",
      "GD iter. 310/499: loss=0.5506454967010215\n",
      "GD iter. 311/499: loss=0.5506479155877152\n",
      "GD iter. 312/499: loss=0.5505988949979354\n",
      "GD iter. 313/499: loss=0.5505465552043077\n",
      "GD iter. 314/499: loss=0.5504812827081501\n",
      "GD iter. 315/499: loss=0.5504391762805768\n",
      "GD iter. 316/499: loss=0.5504211666082882\n",
      "GD iter. 317/499: loss=0.5503689091929594\n",
      "GD iter. 318/499: loss=0.5503661890615698\n",
      "GD iter. 319/499: loss=0.5503109765910658\n",
      "GD iter. 320/499: loss=0.5502755056365196\n",
      "GD iter. 321/499: loss=0.5502251217860754\n",
      "GD iter. 322/499: loss=0.5501747386132622\n",
      "GD iter. 323/499: loss=0.5501302710817962\n",
      "GD iter. 324/499: loss=0.5501410664082678\n",
      "GD iter. 325/499: loss=0.5500716834741637\n",
      "GD iter. 326/499: loss=0.5500307362489195\n",
      "GD iter. 327/499: loss=0.5500018641806326\n",
      "GD iter. 328/499: loss=0.5499386701246758\n",
      "GD iter. 329/499: loss=0.549941370705603\n",
      "GD iter. 330/499: loss=0.5499031935272582\n",
      "GD iter. 331/499: loss=0.5498269799112357\n",
      "GD iter. 332/499: loss=0.5497864010462328\n",
      "GD iter. 333/499: loss=0.5497451989946088\n",
      "GD iter. 334/499: loss=0.5497303897267013\n",
      "GD iter. 335/499: loss=0.5496678572326315\n",
      "GD iter. 336/499: loss=0.5496418153130239\n",
      "GD iter. 337/499: loss=0.549606903618726\n",
      "GD iter. 338/499: loss=0.5495674365510752\n",
      "GD iter. 339/499: loss=0.5495337407052665\n",
      "GD iter. 340/499: loss=0.549523964527386\n",
      "GD iter. 341/499: loss=0.5494651309310923\n",
      "GD iter. 342/499: loss=0.5494226447868947\n",
      "GD iter. 343/499: loss=0.5494035421335083\n",
      "GD iter. 344/499: loss=0.549384861480403\n",
      "GD iter. 345/499: loss=0.5493291041137676\n",
      "GD iter. 346/499: loss=0.5492970496467696\n",
      "GD iter. 347/499: loss=0.5492806520542352\n",
      "GD iter. 348/499: loss=0.5492166437971121\n",
      "GD iter. 349/499: loss=0.5491796148956949\n",
      "GD iter. 350/499: loss=0.5491688111342987\n",
      "GD iter. 351/499: loss=0.5491023986397039\n",
      "GD iter. 352/499: loss=0.5490670531094725\n",
      "GD iter. 353/499: loss=0.5490630891963854\n",
      "GD iter. 354/499: loss=0.5490178716564389\n",
      "GD iter. 355/499: loss=0.5489713676574295\n",
      "GD iter. 356/499: loss=0.5489267220431676\n",
      "GD iter. 357/499: loss=0.5488877348183421\n",
      "GD iter. 358/499: loss=0.5488852026902602\n",
      "GD iter. 359/499: loss=0.548844164339863\n",
      "GD iter. 360/499: loss=0.5488056114613109\n",
      "GD iter. 361/499: loss=0.5487759431846243\n",
      "GD iter. 362/499: loss=0.5487163973767442\n",
      "GD iter. 363/499: loss=0.5486783068181692\n",
      "GD iter. 364/499: loss=0.5486561298065243\n",
      "GD iter. 365/499: loss=0.548622451515242\n",
      "GD iter. 366/499: loss=0.5485985034914058\n",
      "GD iter. 367/499: loss=0.5485751830829796\n",
      "GD iter. 368/499: loss=0.5485184205625487\n",
      "GD iter. 369/499: loss=0.5484819308113423\n",
      "GD iter. 370/499: loss=0.54845054141896\n",
      "GD iter. 371/499: loss=0.548454466065295\n",
      "GD iter. 372/499: loss=0.5484271761765431\n",
      "GD iter. 373/499: loss=0.5483741624147672\n",
      "GD iter. 374/499: loss=0.548321647695184\n",
      "GD iter. 375/499: loss=0.5483134681218195\n",
      "GD iter. 376/499: loss=0.548274710569804\n",
      "GD iter. 377/499: loss=0.5482615856870305\n",
      "GD iter. 378/499: loss=0.5482473870620173\n",
      "GD iter. 379/499: loss=0.5481887262826686\n",
      "GD iter. 380/499: loss=0.5481459935719971\n",
      "GD iter. 381/499: loss=0.5481197593043031\n",
      "GD iter. 382/499: loss=0.5480940238524499\n",
      "GD iter. 383/499: loss=0.5480440102945283\n",
      "GD iter. 384/499: loss=0.5480381216442597\n",
      "GD iter. 385/499: loss=0.5480142845995445\n",
      "GD iter. 386/499: loss=0.5480308424488874\n",
      "GD iter. 387/499: loss=0.5479476388307569\n",
      "GD iter. 388/499: loss=0.5479238986972593\n",
      "GD iter. 389/499: loss=0.5478685918051374\n",
      "GD iter. 390/499: loss=0.5478738341812918\n",
      "GD iter. 391/499: loss=0.5478249592285289\n",
      "GD iter. 392/499: loss=0.5477936424580057\n",
      "GD iter. 393/499: loss=0.5477576325797068\n",
      "GD iter. 394/499: loss=0.5477241592081015\n",
      "GD iter. 395/499: loss=0.5477152716647424\n",
      "GD iter. 396/499: loss=0.5476776885588803\n",
      "GD iter. 397/499: loss=0.5476865034372419\n",
      "GD iter. 398/499: loss=0.5476523131242619\n",
      "GD iter. 399/499: loss=0.5476090939143156\n",
      "GD iter. 400/499: loss=0.5475686219314819\n",
      "GD iter. 401/499: loss=0.5475541807201446\n",
      "GD iter. 402/499: loss=0.5475202236037751\n",
      "GD iter. 403/499: loss=0.5474878459440092\n",
      "GD iter. 404/499: loss=0.5474902127100743\n",
      "GD iter. 405/499: loss=0.5474625472904067\n",
      "GD iter. 406/499: loss=0.5474242200466624\n",
      "GD iter. 407/499: loss=0.5473791179040346\n",
      "GD iter. 408/499: loss=0.5473488231431481\n",
      "GD iter. 409/499: loss=0.5473130245751846\n",
      "GD iter. 410/499: loss=0.5472902490385765\n",
      "GD iter. 411/499: loss=0.5472579359405688\n",
      "GD iter. 412/499: loss=0.5472279510966094\n",
      "GD iter. 413/499: loss=0.547210360958166\n",
      "GD iter. 414/499: loss=0.5471701282861801\n",
      "GD iter. 415/499: loss=0.5471546440709514\n",
      "GD iter. 416/499: loss=0.5471191945836538\n",
      "GD iter. 417/499: loss=0.5471383830001918\n",
      "GD iter. 418/499: loss=0.5471273736466004\n",
      "GD iter. 419/499: loss=0.5470809960338692\n",
      "GD iter. 420/499: loss=0.5470484323656767\n",
      "GD iter. 421/499: loss=0.5469918950205381\n",
      "GD iter. 422/499: loss=0.5469809199568887\n",
      "GD iter. 423/499: loss=0.5469561556640613\n",
      "GD iter. 424/499: loss=0.5469607893344025\n",
      "GD iter. 425/499: loss=0.5469210874056034\n",
      "GD iter. 426/499: loss=0.5469008586149768\n",
      "GD iter. 427/499: loss=0.5468932571705898\n",
      "GD iter. 428/499: loss=0.5468287565475926\n",
      "GD iter. 429/499: loss=0.5468075354132602\n",
      "GD iter. 430/499: loss=0.5468031516483219\n",
      "GD iter. 431/499: loss=0.5467633777280718\n",
      "GD iter. 432/499: loss=0.546777102789741\n",
      "GD iter. 433/499: loss=0.5467471295997575\n",
      "GD iter. 434/499: loss=0.5467036621994069\n",
      "GD iter. 435/499: loss=0.5466741835135306\n",
      "GD iter. 436/499: loss=0.5466948568878225\n",
      "GD iter. 437/499: loss=0.5466728059153416\n",
      "GD iter. 438/499: loss=0.5466306743520299\n",
      "GD iter. 439/499: loss=0.5465862274794432\n",
      "GD iter. 440/499: loss=0.5466095623241356\n",
      "GD iter. 441/499: loss=0.5465437567545828\n",
      "GD iter. 442/499: loss=0.5465377376854643\n",
      "GD iter. 443/499: loss=0.5464732291627877\n",
      "GD iter. 444/499: loss=0.5464829961502105\n",
      "GD iter. 445/499: loss=0.5464459213968309\n",
      "GD iter. 446/499: loss=0.5464582669517449\n",
      "GD iter. 447/499: loss=0.5464145046793323\n",
      "GD iter. 448/499: loss=0.5463964621773589\n",
      "GD iter. 449/499: loss=0.5463711226061588\n",
      "GD iter. 450/499: loss=0.5463384340616432\n",
      "GD iter. 451/499: loss=0.5463389189432784\n",
      "GD iter. 452/499: loss=0.5463398849598983\n",
      "GD iter. 453/499: loss=0.5462878549740205\n",
      "GD iter. 454/499: loss=0.5463310755342131\n",
      "GD iter. 455/499: loss=0.5462801063600004\n",
      "GD iter. 456/499: loss=0.546217558627338\n",
      "GD iter. 457/499: loss=0.5461915637219006\n",
      "GD iter. 458/499: loss=0.546180448671263\n",
      "GD iter. 459/499: loss=0.5461519336679073\n",
      "GD iter. 460/499: loss=0.5462017102573038\n",
      "GD iter. 461/499: loss=0.5461788951483586\n",
      "GD iter. 462/499: loss=0.5461628946357345\n",
      "GD iter. 463/499: loss=0.5460909857939813\n",
      "GD iter. 464/499: loss=0.546065856850624\n",
      "GD iter. 465/499: loss=0.5460581811208539\n",
      "GD iter. 466/499: loss=0.546048860908001\n",
      "GD iter. 467/499: loss=0.5460240563748116\n",
      "GD iter. 468/499: loss=0.5460102178282261\n",
      "GD iter. 469/499: loss=0.5459968776043229\n",
      "GD iter. 470/499: loss=0.5459721561568411\n",
      "GD iter. 471/499: loss=0.5459197186769078\n",
      "GD iter. 472/499: loss=0.5458825866432531\n",
      "GD iter. 473/499: loss=0.5459021088649313\n",
      "GD iter. 474/499: loss=0.5458595728265087\n",
      "GD iter. 475/499: loss=0.5458703864915138\n",
      "GD iter. 476/499: loss=0.5458776620284216\n",
      "GD iter. 477/499: loss=0.5458213397719222\n",
      "GD iter. 478/499: loss=0.5458045884814099\n",
      "GD iter. 479/499: loss=0.5457997690573032\n",
      "GD iter. 480/499: loss=0.5457595888243525\n",
      "GD iter. 481/499: loss=0.5457603943902791\n",
      "GD iter. 482/499: loss=0.5457298626406063\n",
      "GD iter. 483/499: loss=0.5457254938098869\n",
      "GD iter. 484/499: loss=0.5457101744991624\n",
      "GD iter. 485/499: loss=0.545706404411577\n",
      "GD iter. 486/499: loss=0.5456638813399508\n",
      "GD iter. 487/499: loss=0.5456722311567379\n",
      "GD iter. 488/499: loss=0.5456030636727975\n",
      "GD iter. 489/499: loss=0.5455577102195943\n",
      "GD iter. 490/499: loss=0.5455612545174064\n",
      "GD iter. 491/499: loss=0.5455511073861954\n",
      "GD iter. 492/499: loss=0.5455570608443374\n",
      "GD iter. 493/499: loss=0.5455199255670453\n",
      "GD iter. 494/499: loss=0.5454929682579625\n",
      "GD iter. 495/499: loss=0.5454600363775627\n",
      "GD iter. 496/499: loss=0.5454576220085051\n",
      "GD iter. 497/499: loss=0.5454487126223789\n",
      "GD iter. 498/499: loss=0.5454719455007256\n",
      "GD iter. 499/499: loss=0.5454220059609927\n",
      "The Accuracy is: 0.6607\n",
      "The F1 score is: 0.2935\n",
      "The precision is: 0.1807\n",
      "The recall is: 0.7818\n",
      "GD iter. 0/499: loss=1.068751419552652\n",
      "GD iter. 1/499: loss=0.9935958432221836\n",
      "GD iter. 2/499: loss=0.9186656217868813\n",
      "GD iter. 3/499: loss=0.8447122661646675\n",
      "GD iter. 4/499: loss=0.7812304585229641\n",
      "GD iter. 5/499: loss=0.7391852604305167\n",
      "GD iter. 6/499: loss=0.7125793716200552\n",
      "GD iter. 7/499: loss=0.6935865352468714\n",
      "GD iter. 8/499: loss=0.6786692846286384\n",
      "GD iter. 9/499: loss=0.6663511723365304\n",
      "GD iter. 10/499: loss=0.6571672832982449\n",
      "GD iter. 11/499: loss=0.6499575096947003\n",
      "GD iter. 12/499: loss=0.6438878446712397\n",
      "GD iter. 13/499: loss=0.6386549580247631\n",
      "GD iter. 14/499: loss=0.6343471985966348\n",
      "GD iter. 15/499: loss=0.630849619860712\n",
      "GD iter. 16/499: loss=0.6280853084242617\n",
      "GD iter. 17/499: loss=0.6256458847502673\n",
      "GD iter. 18/499: loss=0.6234247559250443\n",
      "GD iter. 19/499: loss=0.6213623056979178\n",
      "GD iter. 20/499: loss=0.6194967446164306\n",
      "GD iter. 21/499: loss=0.6177407226487097\n",
      "GD iter. 22/499: loss=0.6160577694382231\n",
      "GD iter. 23/499: loss=0.614496925897039\n",
      "GD iter. 24/499: loss=0.6129616693821613\n",
      "GD iter. 25/499: loss=0.6114859991673052\n",
      "GD iter. 26/499: loss=0.6100714570508251\n",
      "GD iter. 27/499: loss=0.6086757710916879\n",
      "GD iter. 28/499: loss=0.6073639753280624\n",
      "GD iter. 29/499: loss=0.6061277125403909\n",
      "GD iter. 30/499: loss=0.6049693659190625\n",
      "GD iter. 31/499: loss=0.6038435017944137\n",
      "GD iter. 32/499: loss=0.602742575960282\n",
      "GD iter. 33/499: loss=0.6016584430317159\n",
      "GD iter. 34/499: loss=0.6006561357632928\n",
      "GD iter. 35/499: loss=0.599704647055223\n",
      "GD iter. 36/499: loss=0.5987772598446406\n",
      "GD iter. 37/499: loss=0.5978805649460385\n",
      "GD iter. 38/499: loss=0.5970053674045961\n",
      "GD iter. 39/499: loss=0.596169889543079\n",
      "GD iter. 40/499: loss=0.5953662563879284\n",
      "GD iter. 41/499: loss=0.5945847288740903\n",
      "GD iter. 42/499: loss=0.5938508086016913\n",
      "GD iter. 43/499: loss=0.5931442446865457\n",
      "GD iter. 44/499: loss=0.5924455188176911\n",
      "GD iter. 45/499: loss=0.5917560828828476\n",
      "GD iter. 46/499: loss=0.5910819268097347\n",
      "GD iter. 47/499: loss=0.5904093356030485\n",
      "GD iter. 48/499: loss=0.589754792626641\n",
      "GD iter. 49/499: loss=0.5891460750229646\n",
      "GD iter. 50/499: loss=0.588541034539522\n",
      "GD iter. 51/499: loss=0.5879618524269915\n",
      "GD iter. 52/499: loss=0.5874100091225349\n",
      "GD iter. 53/499: loss=0.5868722944423196\n",
      "GD iter. 54/499: loss=0.5863434001699535\n",
      "GD iter. 55/499: loss=0.5858365843688546\n",
      "GD iter. 56/499: loss=0.5853309640513166\n",
      "GD iter. 57/499: loss=0.58482683940042\n",
      "GD iter. 58/499: loss=0.5843198095494426\n",
      "GD iter. 59/499: loss=0.583827543165628\n",
      "GD iter. 60/499: loss=0.5833467915636831\n",
      "GD iter. 61/499: loss=0.5828762168354727\n",
      "GD iter. 62/499: loss=0.5824381612961432\n",
      "GD iter. 63/499: loss=0.5820151148667664\n",
      "GD iter. 64/499: loss=0.5816001506557736\n",
      "GD iter. 65/499: loss=0.5811979420255818\n",
      "GD iter. 66/499: loss=0.5807963587716385\n",
      "GD iter. 67/499: loss=0.5804021235563103\n",
      "GD iter. 68/499: loss=0.580000635736408\n",
      "GD iter. 69/499: loss=0.5796238490052228\n",
      "GD iter. 70/499: loss=0.5792457649078565\n",
      "GD iter. 71/499: loss=0.5788697066491467\n",
      "GD iter. 72/499: loss=0.5785091620479813\n",
      "GD iter. 73/499: loss=0.578156464015284\n",
      "GD iter. 74/499: loss=0.5778222047428525\n",
      "GD iter. 75/499: loss=0.5774903617235123\n",
      "GD iter. 76/499: loss=0.5771562514930977\n",
      "GD iter. 77/499: loss=0.5768311806868218\n",
      "GD iter. 78/499: loss=0.5765150159569132\n",
      "GD iter. 79/499: loss=0.5761799007397308\n",
      "GD iter. 80/499: loss=0.5758602538056181\n",
      "GD iter. 81/499: loss=0.5755335901023952\n",
      "GD iter. 82/499: loss=0.5752181712104585\n",
      "GD iter. 83/499: loss=0.5748975115481504\n",
      "GD iter. 84/499: loss=0.5745910624051684\n",
      "GD iter. 85/499: loss=0.5742708937775599\n",
      "GD iter. 86/499: loss=0.573976380859837\n",
      "GD iter. 87/499: loss=0.5736739726295081\n",
      "GD iter. 88/499: loss=0.5734068331536225\n",
      "GD iter. 89/499: loss=0.57312954034893\n",
      "GD iter. 90/499: loss=0.5728826193148272\n",
      "GD iter. 91/499: loss=0.5726363146769105\n",
      "GD iter. 92/499: loss=0.5723768467303061\n",
      "GD iter. 93/499: loss=0.5721388708734028\n",
      "GD iter. 94/499: loss=0.5719191100531306\n",
      "GD iter. 95/499: loss=0.5716720223601924\n",
      "GD iter. 96/499: loss=0.5714346390499717\n",
      "GD iter. 97/499: loss=0.5712044458928378\n",
      "GD iter. 98/499: loss=0.5709819411645192\n",
      "GD iter. 99/499: loss=0.5707518570609452\n",
      "GD iter. 100/499: loss=0.5705308113902571\n",
      "GD iter. 101/499: loss=0.570307513499195\n",
      "GD iter. 102/499: loss=0.5700822378530661\n",
      "GD iter. 103/499: loss=0.5698532251257604\n",
      "GD iter. 104/499: loss=0.5696389911214842\n",
      "GD iter. 105/499: loss=0.5694266090735737\n",
      "GD iter. 106/499: loss=0.5691993886305723\n",
      "GD iter. 107/499: loss=0.5689847662997838\n",
      "GD iter. 108/499: loss=0.5687772306171566\n",
      "GD iter. 109/499: loss=0.5685808436705989\n",
      "GD iter. 110/499: loss=0.5683755660899377\n",
      "GD iter. 111/499: loss=0.568190396976382\n",
      "GD iter. 112/499: loss=0.567997861902724\n",
      "GD iter. 113/499: loss=0.5678007517533652\n",
      "GD iter. 114/499: loss=0.567613226698317\n",
      "GD iter. 115/499: loss=0.5674345231920931\n",
      "GD iter. 116/499: loss=0.5672218141121013\n",
      "GD iter. 117/499: loss=0.5670426389877018\n",
      "GD iter. 118/499: loss=0.5668451311749686\n",
      "GD iter. 119/499: loss=0.5666658235135928\n",
      "GD iter. 120/499: loss=0.5664881114026459\n",
      "GD iter. 121/499: loss=0.5663213289843325\n",
      "GD iter. 122/499: loss=0.5661273999622412\n",
      "GD iter. 123/499: loss=0.5659398751949938\n",
      "GD iter. 124/499: loss=0.5657720821942809\n",
      "GD iter. 125/499: loss=0.5656017796852848\n",
      "GD iter. 126/499: loss=0.5654256900913546\n",
      "GD iter. 127/499: loss=0.5652763495123453\n",
      "GD iter. 128/499: loss=0.5651265456529103\n",
      "GD iter. 129/499: loss=0.5649484939155741\n",
      "GD iter. 130/499: loss=0.5647887707031718\n",
      "GD iter. 131/499: loss=0.5646427085408763\n",
      "GD iter. 132/499: loss=0.5644908626478465\n",
      "GD iter. 133/499: loss=0.5643387954309309\n",
      "GD iter. 134/499: loss=0.5641977825013205\n",
      "GD iter. 135/499: loss=0.5640334580639713\n",
      "GD iter. 136/499: loss=0.5638865261824156\n",
      "GD iter. 137/499: loss=0.5637516935476191\n",
      "GD iter. 138/499: loss=0.5636097945145232\n",
      "GD iter. 139/499: loss=0.5634814008893494\n",
      "GD iter. 140/499: loss=0.5633429628389344\n",
      "GD iter. 141/499: loss=0.5631952868188819\n",
      "GD iter. 142/499: loss=0.563039410474408\n",
      "GD iter. 143/499: loss=0.5629110587447269\n",
      "GD iter. 144/499: loss=0.5627828617979498\n",
      "GD iter. 145/499: loss=0.5626446996579468\n",
      "GD iter. 146/499: loss=0.562492630718502\n",
      "GD iter. 147/499: loss=0.5623712716680713\n",
      "GD iter. 148/499: loss=0.5622212366233397\n",
      "GD iter. 149/499: loss=0.5620978427275278\n",
      "GD iter. 150/499: loss=0.5619738657515518\n",
      "GD iter. 151/499: loss=0.561851715366227\n",
      "GD iter. 152/499: loss=0.561706129239773\n",
      "GD iter. 153/499: loss=0.5615733278555278\n",
      "GD iter. 154/499: loss=0.5614776492534914\n",
      "GD iter. 155/499: loss=0.561362571311318\n",
      "GD iter. 156/499: loss=0.5612081817137382\n",
      "GD iter. 157/499: loss=0.5610809365763705\n",
      "GD iter. 158/499: loss=0.5609692344166626\n",
      "GD iter. 159/499: loss=0.5608464599152322\n",
      "GD iter. 160/499: loss=0.5607056724083413\n",
      "GD iter. 161/499: loss=0.5605920398104711\n",
      "GD iter. 162/499: loss=0.5604801395108991\n",
      "GD iter. 163/499: loss=0.5603445859657746\n",
      "GD iter. 164/499: loss=0.5602282674265241\n",
      "GD iter. 165/499: loss=0.5601203069284801\n",
      "GD iter. 166/499: loss=0.559991721307672\n",
      "GD iter. 167/499: loss=0.559858312724689\n",
      "GD iter. 168/499: loss=0.5597592152094136\n",
      "GD iter. 169/499: loss=0.5596441501865461\n",
      "GD iter. 170/499: loss=0.5595191793970429\n",
      "GD iter. 171/499: loss=0.5593885633047067\n",
      "GD iter. 172/499: loss=0.5593012364755312\n",
      "GD iter. 173/499: loss=0.5591896822226008\n",
      "GD iter. 174/499: loss=0.559065746975408\n",
      "GD iter. 175/499: loss=0.5589566699843329\n",
      "GD iter. 176/499: loss=0.5588503866407806\n",
      "GD iter. 177/499: loss=0.5587478367966184\n",
      "GD iter. 178/499: loss=0.5586380237364632\n",
      "GD iter. 179/499: loss=0.5585380009513952\n",
      "GD iter. 180/499: loss=0.5584306284079751\n",
      "GD iter. 181/499: loss=0.5583191098557427\n",
      "GD iter. 182/499: loss=0.5582170528270661\n",
      "GD iter. 183/499: loss=0.5581051650140997\n",
      "GD iter. 184/499: loss=0.5579995682936234\n",
      "GD iter. 185/499: loss=0.5579034651888993\n",
      "GD iter. 186/499: loss=0.5578260900034496\n",
      "GD iter. 187/499: loss=0.5577169399662766\n",
      "GD iter. 188/499: loss=0.5576058138964539\n",
      "GD iter. 189/499: loss=0.5575021876137242\n",
      "GD iter. 190/499: loss=0.557421249548942\n",
      "GD iter. 191/499: loss=0.5573164561887612\n",
      "GD iter. 192/499: loss=0.5572188930278102\n",
      "GD iter. 193/499: loss=0.5571194579757626\n",
      "GD iter. 194/499: loss=0.5570210666598362\n",
      "GD iter. 195/499: loss=0.5569415243013872\n",
      "GD iter. 196/499: loss=0.5568318486877643\n",
      "GD iter. 197/499: loss=0.5567686087017787\n",
      "GD iter. 198/499: loss=0.5566748161916857\n",
      "GD iter. 199/499: loss=0.5565589564591066\n",
      "GD iter. 200/499: loss=0.5564576570787368\n",
      "GD iter. 201/499: loss=0.5563826804954511\n",
      "GD iter. 202/499: loss=0.5563003887355701\n",
      "GD iter. 203/499: loss=0.5562124683112926\n",
      "GD iter. 204/499: loss=0.556118329937736\n",
      "GD iter. 205/499: loss=0.5560332079540791\n",
      "GD iter. 206/499: loss=0.5559773168941246\n",
      "GD iter. 207/499: loss=0.5558807740599241\n",
      "GD iter. 208/499: loss=0.5557939897768119\n",
      "GD iter. 209/499: loss=0.5557150771893923\n",
      "GD iter. 210/499: loss=0.5556278163343321\n",
      "GD iter. 211/499: loss=0.555562784183225\n",
      "GD iter. 212/499: loss=0.5554856103944709\n",
      "GD iter. 213/499: loss=0.5553924563875364\n",
      "GD iter. 214/499: loss=0.5553386795479133\n",
      "GD iter. 215/499: loss=0.5552692585613586\n",
      "GD iter. 216/499: loss=0.5551888366816589\n",
      "GD iter. 217/499: loss=0.5551118452063566\n",
      "GD iter. 218/499: loss=0.555040582307688\n",
      "GD iter. 219/499: loss=0.5549704258721696\n",
      "GD iter. 220/499: loss=0.5548921887274292\n",
      "GD iter. 221/499: loss=0.554824168591324\n",
      "GD iter. 222/499: loss=0.5547387655040503\n",
      "GD iter. 223/499: loss=0.5546716061988773\n",
      "GD iter. 224/499: loss=0.5546008474661752\n",
      "GD iter. 225/499: loss=0.5545626797179247\n",
      "GD iter. 226/499: loss=0.5544815010010534\n",
      "GD iter. 227/499: loss=0.5544347889109382\n",
      "GD iter. 228/499: loss=0.5543305083360457\n",
      "GD iter. 229/499: loss=0.5542671648598634\n",
      "GD iter. 230/499: loss=0.5542077239301608\n",
      "GD iter. 231/499: loss=0.5541703741679246\n",
      "GD iter. 232/499: loss=0.554093267322477\n",
      "GD iter. 233/499: loss=0.554018664045254\n",
      "GD iter. 234/499: loss=0.5539349907275783\n",
      "GD iter. 235/499: loss=0.5538809133668078\n",
      "GD iter. 236/499: loss=0.5537920104158964\n",
      "GD iter. 237/499: loss=0.5537303684234859\n",
      "GD iter. 238/499: loss=0.55368146672031\n",
      "GD iter. 239/499: loss=0.5536209598804144\n",
      "GD iter. 240/499: loss=0.55354909208285\n",
      "GD iter. 241/499: loss=0.553485602480379\n",
      "GD iter. 242/499: loss=0.5534182073957886\n",
      "GD iter. 243/499: loss=0.5533724906390148\n",
      "GD iter. 244/499: loss=0.5532982129975125\n",
      "GD iter. 245/499: loss=0.5532234675558546\n",
      "GD iter. 246/499: loss=0.5531432371248012\n",
      "GD iter. 247/499: loss=0.5530963753141969\n",
      "GD iter. 248/499: loss=0.55305032468561\n",
      "GD iter. 249/499: loss=0.5529582225251967\n",
      "GD iter. 250/499: loss=0.5529112404998847\n",
      "GD iter. 251/499: loss=0.5528458004918445\n",
      "GD iter. 252/499: loss=0.5527838613762552\n",
      "GD iter. 253/499: loss=0.5527254391840187\n",
      "GD iter. 254/499: loss=0.5526702501107915\n",
      "GD iter. 255/499: loss=0.5526066395373903\n",
      "GD iter. 256/499: loss=0.5525577776816238\n",
      "GD iter. 257/499: loss=0.5524989397808094\n",
      "GD iter. 258/499: loss=0.5524203178359651\n",
      "GD iter. 259/499: loss=0.5523883957175839\n",
      "GD iter. 260/499: loss=0.5523680265156624\n",
      "GD iter. 261/499: loss=0.5522700398789225\n",
      "GD iter. 262/499: loss=0.5521938579254777\n",
      "GD iter. 263/499: loss=0.5521428989583536\n",
      "GD iter. 264/499: loss=0.5520849140220901\n",
      "GD iter. 265/499: loss=0.5520072367523383\n",
      "GD iter. 266/499: loss=0.551975215972972\n",
      "GD iter. 267/499: loss=0.551939942831216\n",
      "GD iter. 268/499: loss=0.5518689932144829\n",
      "GD iter. 269/499: loss=0.5518219497733179\n",
      "GD iter. 270/499: loss=0.5517774092480016\n",
      "GD iter. 271/499: loss=0.551716413431466\n",
      "GD iter. 272/499: loss=0.5516546419311064\n",
      "GD iter. 273/499: loss=0.5516148615953377\n",
      "GD iter. 274/499: loss=0.5515687511728607\n",
      "GD iter. 275/499: loss=0.5515123468517779\n",
      "GD iter. 276/499: loss=0.5514410250635352\n",
      "GD iter. 277/499: loss=0.5514056451064253\n",
      "GD iter. 278/499: loss=0.5513529495836735\n",
      "GD iter. 279/499: loss=0.5512952630085651\n",
      "GD iter. 280/499: loss=0.5512425132759948\n",
      "GD iter. 281/499: loss=0.5511867755992831\n",
      "GD iter. 282/499: loss=0.5511396510438318\n",
      "GD iter. 283/499: loss=0.5510900666447194\n",
      "GD iter. 284/499: loss=0.5510499194914924\n",
      "GD iter. 285/499: loss=0.5510027164186941\n",
      "GD iter. 286/499: loss=0.5509644694799406\n",
      "GD iter. 287/499: loss=0.5509094746945793\n",
      "GD iter. 288/499: loss=0.5508670042365771\n",
      "GD iter. 289/499: loss=0.5508152738913706\n",
      "GD iter. 290/499: loss=0.5507694171859459\n",
      "GD iter. 291/499: loss=0.5507182692780966\n",
      "GD iter. 292/499: loss=0.5506687822453503\n",
      "GD iter. 293/499: loss=0.5506368539899144\n",
      "GD iter. 294/499: loss=0.5506080500342806\n",
      "GD iter. 295/499: loss=0.550543075394629\n",
      "GD iter. 296/499: loss=0.550483034574594\n",
      "GD iter. 297/499: loss=0.5504320308253183\n",
      "GD iter. 298/499: loss=0.5503900336619842\n",
      "GD iter. 299/499: loss=0.5503489467707112\n",
      "GD iter. 300/499: loss=0.5503041829626714\n",
      "GD iter. 301/499: loss=0.5502488724763137\n",
      "GD iter. 302/499: loss=0.5502066837690743\n",
      "GD iter. 303/499: loss=0.5501637993401718\n",
      "GD iter. 304/499: loss=0.5501196628406549\n",
      "GD iter. 305/499: loss=0.5500764143461292\n",
      "GD iter. 306/499: loss=0.5500416563793664\n",
      "GD iter. 307/499: loss=0.549994481913781\n",
      "GD iter. 308/499: loss=0.549957384704785\n",
      "GD iter. 309/499: loss=0.5499199468053564\n",
      "GD iter. 310/499: loss=0.5498888709472368\n",
      "GD iter. 311/499: loss=0.5498218199973088\n",
      "GD iter. 312/499: loss=0.5498126035411138\n",
      "GD iter. 313/499: loss=0.5497567821915859\n",
      "GD iter. 314/499: loss=0.5497066171383808\n",
      "GD iter. 315/499: loss=0.5496782433573617\n",
      "GD iter. 316/499: loss=0.5496480883873955\n",
      "GD iter. 317/499: loss=0.5495994149343986\n",
      "GD iter. 318/499: loss=0.5495415423804333\n",
      "GD iter. 319/499: loss=0.5495101474896257\n",
      "GD iter. 320/499: loss=0.5494754675926179\n",
      "GD iter. 321/499: loss=0.5494318997931605\n",
      "GD iter. 322/499: loss=0.5494188794486372\n",
      "GD iter. 323/499: loss=0.5493737191304389\n",
      "GD iter. 324/499: loss=0.5493456992751099\n",
      "GD iter. 325/499: loss=0.5493130899962098\n",
      "GD iter. 326/499: loss=0.5492644656111448\n",
      "GD iter. 327/499: loss=0.5492163503920563\n",
      "GD iter. 328/499: loss=0.5491652646012799\n",
      "GD iter. 329/499: loss=0.5491255001215156\n",
      "GD iter. 330/499: loss=0.5490782176487158\n",
      "GD iter. 331/499: loss=0.5490553795532787\n",
      "GD iter. 332/499: loss=0.5490231664573508\n",
      "GD iter. 333/499: loss=0.5489976990401747\n",
      "GD iter. 334/499: loss=0.5489487485966761\n",
      "GD iter. 335/499: loss=0.548931422075915\n",
      "GD iter. 336/499: loss=0.5488884387757718\n",
      "GD iter. 337/499: loss=0.5488459081287566\n",
      "GD iter. 338/499: loss=0.5487934955054101\n",
      "GD iter. 339/499: loss=0.5487658730185476\n",
      "GD iter. 340/499: loss=0.5487145746870633\n",
      "GD iter. 341/499: loss=0.548672019317404\n",
      "GD iter. 342/499: loss=0.5486537514810154\n",
      "GD iter. 343/499: loss=0.5486271291644966\n",
      "GD iter. 344/499: loss=0.5485810917673692\n",
      "GD iter. 345/499: loss=0.5485424649149092\n",
      "GD iter. 346/499: loss=0.5485149613107058\n",
      "GD iter. 347/499: loss=0.5484674959927638\n",
      "GD iter. 348/499: loss=0.5484443257610555\n",
      "GD iter. 349/499: loss=0.5484172086973598\n",
      "GD iter. 350/499: loss=0.5483969735155994\n",
      "GD iter. 351/499: loss=0.548333532789265\n",
      "GD iter. 352/499: loss=0.5482870810401792\n",
      "GD iter. 353/499: loss=0.5482624976179319\n",
      "GD iter. 354/499: loss=0.5482164839157206\n",
      "GD iter. 355/499: loss=0.5481687199956489\n",
      "GD iter. 356/499: loss=0.5481712389068841\n",
      "GD iter. 357/499: loss=0.5481627713937686\n",
      "GD iter. 358/499: loss=0.5480842791732868\n",
      "GD iter. 359/499: loss=0.5480464696832879\n",
      "GD iter. 360/499: loss=0.5480057719489103\n",
      "GD iter. 361/499: loss=0.5479797353118019\n",
      "GD iter. 362/499: loss=0.5479503963017214\n",
      "GD iter. 363/499: loss=0.54790612198635\n",
      "GD iter. 364/499: loss=0.5478687626744752\n",
      "GD iter. 365/499: loss=0.5478592803625363\n",
      "GD iter. 366/499: loss=0.5478051561639551\n",
      "GD iter. 367/499: loss=0.5477749862261139\n",
      "GD iter. 368/499: loss=0.5477548051381843\n",
      "GD iter. 369/499: loss=0.547722881677243\n",
      "GD iter. 370/499: loss=0.5476609780050602\n",
      "GD iter. 371/499: loss=0.5476532772492692\n",
      "GD iter. 372/499: loss=0.5476097848864034\n",
      "GD iter. 373/499: loss=0.5475854027424696\n",
      "GD iter. 374/499: loss=0.5475349061475523\n",
      "GD iter. 375/499: loss=0.5474962325740423\n",
      "GD iter. 376/499: loss=0.5474775511706478\n",
      "GD iter. 377/499: loss=0.5474373002644379\n",
      "GD iter. 378/499: loss=0.5474046656729347\n",
      "GD iter. 379/499: loss=0.547372605286762\n",
      "GD iter. 380/499: loss=0.5473575152939073\n",
      "GD iter. 381/499: loss=0.5473083495963487\n",
      "GD iter. 382/499: loss=0.5472626981978378\n",
      "GD iter. 383/499: loss=0.5472272424854722\n",
      "GD iter. 384/499: loss=0.547221403080473\n",
      "GD iter. 385/499: loss=0.5472070414017484\n",
      "GD iter. 386/499: loss=0.5471557245433765\n",
      "GD iter. 387/499: loss=0.5471329797929239\n",
      "GD iter. 388/499: loss=0.5470836265117336\n",
      "GD iter. 389/499: loss=0.5470580611007116\n",
      "GD iter. 390/499: loss=0.5470297345305847\n",
      "GD iter. 391/499: loss=0.5470160123312748\n",
      "GD iter. 392/499: loss=0.5469798449676886\n",
      "GD iter. 393/499: loss=0.5469419570446056\n",
      "GD iter. 394/499: loss=0.546903363496903\n",
      "GD iter. 395/499: loss=0.5469029859019344\n",
      "GD iter. 396/499: loss=0.5468884089250297\n",
      "GD iter. 397/499: loss=0.5468419593819539\n",
      "GD iter. 398/499: loss=0.5468061765962741\n",
      "GD iter. 399/499: loss=0.5467949734559583\n",
      "GD iter. 400/499: loss=0.5467914847985926\n",
      "GD iter. 401/499: loss=0.5467219818393078\n",
      "GD iter. 402/499: loss=0.5467059465144475\n",
      "GD iter. 403/499: loss=0.5466761497950935\n",
      "GD iter. 404/499: loss=0.5466380625229347\n",
      "GD iter. 405/499: loss=0.5466064364483815\n",
      "GD iter. 406/499: loss=0.546588294631571\n",
      "GD iter. 407/499: loss=0.5465693029113083\n",
      "GD iter. 408/499: loss=0.5465387659911977\n",
      "GD iter. 409/499: loss=0.5465051685395405\n",
      "GD iter. 410/499: loss=0.5464831597764169\n",
      "GD iter. 411/499: loss=0.5464805685440274\n",
      "GD iter. 412/499: loss=0.5464255633965749\n",
      "GD iter. 413/499: loss=0.5464131695319563\n",
      "GD iter. 414/499: loss=0.5463949292873983\n",
      "GD iter. 415/499: loss=0.5463692650277413\n",
      "GD iter. 416/499: loss=0.5463518533285525\n",
      "GD iter. 417/499: loss=0.5463078232053417\n",
      "GD iter. 418/499: loss=0.5462772950270708\n",
      "GD iter. 419/499: loss=0.5462620770533981\n",
      "GD iter. 420/499: loss=0.5462372904786792\n",
      "GD iter. 421/499: loss=0.546199553122571\n",
      "GD iter. 422/499: loss=0.5461890223006366\n",
      "GD iter. 423/499: loss=0.5461726150589113\n",
      "GD iter. 424/499: loss=0.5461290826609161\n",
      "GD iter. 425/499: loss=0.5461119179014894\n",
      "GD iter. 426/499: loss=0.546087688915423\n",
      "GD iter. 427/499: loss=0.5460617066802849\n",
      "GD iter. 428/499: loss=0.5460456766783194\n",
      "GD iter. 429/499: loss=0.5460001575076606\n",
      "GD iter. 430/499: loss=0.5459802711771538\n",
      "GD iter. 431/499: loss=0.5459479328187464\n",
      "GD iter. 432/499: loss=0.5459204265884894\n",
      "GD iter. 433/499: loss=0.5458906255696363\n",
      "GD iter. 434/499: loss=0.5458702132753077\n",
      "GD iter. 435/499: loss=0.5458517357712253\n",
      "GD iter. 436/499: loss=0.5458334905018409\n",
      "GD iter. 437/499: loss=0.5457993020667852\n",
      "GD iter. 438/499: loss=0.5457906097618089\n",
      "GD iter. 439/499: loss=0.5457739148204375\n",
      "GD iter. 440/499: loss=0.5457659175840714\n",
      "GD iter. 441/499: loss=0.5457050702283609\n",
      "GD iter. 442/499: loss=0.545675307562016\n",
      "GD iter. 443/499: loss=0.545685128354822\n",
      "GD iter. 444/499: loss=0.5456517313575253\n",
      "GD iter. 445/499: loss=0.5456052055851711\n",
      "GD iter. 446/499: loss=0.5455890328355464\n",
      "GD iter. 447/499: loss=0.5455594423730616\n",
      "GD iter. 448/499: loss=0.5455546649197736\n",
      "GD iter. 449/499: loss=0.5455434965172129\n",
      "GD iter. 450/499: loss=0.5454932406310695\n",
      "GD iter. 451/499: loss=0.5454605765422041\n",
      "GD iter. 452/499: loss=0.5454573811460829\n",
      "GD iter. 453/499: loss=0.545433259415685\n",
      "GD iter. 454/499: loss=0.5454164416932378\n",
      "GD iter. 455/499: loss=0.5454034963228646\n",
      "GD iter. 456/499: loss=0.5453879323630406\n",
      "GD iter. 457/499: loss=0.545328009585102\n",
      "GD iter. 458/499: loss=0.5453135595683033\n",
      "GD iter. 459/499: loss=0.5453110549342518\n",
      "GD iter. 460/499: loss=0.5452700266879434\n",
      "GD iter. 461/499: loss=0.545278187340597\n",
      "GD iter. 462/499: loss=0.5452168051567833\n",
      "GD iter. 463/499: loss=0.5451905833294615\n",
      "GD iter. 464/499: loss=0.545190845662292\n",
      "GD iter. 465/499: loss=0.5451758846974164\n",
      "GD iter. 466/499: loss=0.5451607847114314\n",
      "GD iter. 467/499: loss=0.5451249306615198\n",
      "GD iter. 468/499: loss=0.5450996876254106\n",
      "GD iter. 469/499: loss=0.5450638721917781\n",
      "GD iter. 470/499: loss=0.5450582111918698\n",
      "GD iter. 471/499: loss=0.5450282233096791\n",
      "GD iter. 472/499: loss=0.5450102810728864\n",
      "GD iter. 473/499: loss=0.5449796144254616\n",
      "GD iter. 474/499: loss=0.5449510535809364\n",
      "GD iter. 475/499: loss=0.5449563240857203\n",
      "GD iter. 476/499: loss=0.5449178991040916\n",
      "GD iter. 477/499: loss=0.5448935423903163\n",
      "GD iter. 478/499: loss=0.5448749468391954\n",
      "GD iter. 479/499: loss=0.5448637950292448\n",
      "GD iter. 480/499: loss=0.5448477271378347\n",
      "GD iter. 481/499: loss=0.5448202818483527\n",
      "GD iter. 482/499: loss=0.5448166103177375\n",
      "GD iter. 483/499: loss=0.5447804420456537\n",
      "GD iter. 484/499: loss=0.544770681440489\n",
      "GD iter. 485/499: loss=0.5447540436695256\n",
      "GD iter. 486/499: loss=0.5447352505844532\n",
      "GD iter. 487/499: loss=0.5446900632854457\n",
      "GD iter. 488/499: loss=0.544666412924656\n",
      "GD iter. 489/499: loss=0.5446543440199686\n",
      "GD iter. 490/499: loss=0.5446295553262854\n",
      "GD iter. 491/499: loss=0.5446088233222662\n",
      "GD iter. 492/499: loss=0.5446001173812022\n",
      "GD iter. 493/499: loss=0.5445875551307227\n",
      "GD iter. 494/499: loss=0.544581468914729\n",
      "GD iter. 495/499: loss=0.5445655674481152\n",
      "GD iter. 496/499: loss=0.5445413588623258\n",
      "GD iter. 497/499: loss=0.5445051134114012\n",
      "GD iter. 498/499: loss=0.5444719305852481\n",
      "GD iter. 499/499: loss=0.5444601069530145\n",
      "The Accuracy is: 0.6689\n",
      "The F1 score is: 0.3526\n",
      "The precision is: 0.2254\n",
      "The recall is: 0.8088\n",
      "GD iter. 0/499: loss=1.0096768383811299\n",
      "GD iter. 1/499: loss=0.9396698715877039\n",
      "GD iter. 2/499: loss=0.8700314943796913\n",
      "GD iter. 3/499: loss=0.8031919217410569\n",
      "GD iter. 4/499: loss=0.7479502736902705\n",
      "GD iter. 5/499: loss=0.711169609277722\n",
      "GD iter. 6/499: loss=0.6885121093510976\n",
      "GD iter. 7/499: loss=0.6741244207822582\n",
      "GD iter. 8/499: loss=0.6645904240160478\n",
      "GD iter. 9/499: loss=0.6569910863176947\n",
      "GD iter. 10/499: loss=0.6507704392561764\n",
      "GD iter. 11/499: loss=0.6455143063313644\n",
      "GD iter. 12/499: loss=0.6410289147370739\n",
      "GD iter. 13/499: loss=0.6372114568932606\n",
      "GD iter. 14/499: loss=0.633927092110472\n",
      "GD iter. 15/499: loss=0.6312139374761533\n",
      "GD iter. 16/499: loss=0.6287902898589295\n",
      "GD iter. 17/499: loss=0.6266183707242811\n",
      "GD iter. 18/499: loss=0.6246618128163648\n",
      "GD iter. 19/499: loss=0.6228615458563243\n",
      "GD iter. 20/499: loss=0.621182996213913\n",
      "GD iter. 21/499: loss=0.6195816466603545\n",
      "GD iter. 22/499: loss=0.6180578099171878\n",
      "GD iter. 23/499: loss=0.6166670918668498\n",
      "GD iter. 24/499: loss=0.6153475586263502\n",
      "GD iter. 25/499: loss=0.6140743205786087\n",
      "GD iter. 26/499: loss=0.6128597852726374\n",
      "GD iter. 27/499: loss=0.6116558206044249\n",
      "GD iter. 28/499: loss=0.6104676880232004\n",
      "GD iter. 29/499: loss=0.6093058245359193\n",
      "GD iter. 30/499: loss=0.6081779121335664\n",
      "GD iter. 31/499: loss=0.6071005478464806\n",
      "GD iter. 32/499: loss=0.6060677785025795\n",
      "GD iter. 33/499: loss=0.6051102613481268\n",
      "GD iter. 34/499: loss=0.6042091443040929\n",
      "GD iter. 35/499: loss=0.6033299505221306\n",
      "GD iter. 36/499: loss=0.6024836502786478\n",
      "GD iter. 37/499: loss=0.6016851804097273\n",
      "GD iter. 38/499: loss=0.6008943223743952\n",
      "GD iter. 39/499: loss=0.6001258896071302\n",
      "GD iter. 40/499: loss=0.5993970809651816\n",
      "GD iter. 41/499: loss=0.5986995342546967\n",
      "GD iter. 42/499: loss=0.5980083620718226\n",
      "GD iter. 43/499: loss=0.597322968214813\n",
      "GD iter. 44/499: loss=0.5966407300975238\n",
      "GD iter. 45/499: loss=0.5959874854661265\n",
      "GD iter. 46/499: loss=0.5953429857777007\n",
      "GD iter. 47/499: loss=0.5947221019608436\n",
      "GD iter. 48/499: loss=0.594102046110601\n",
      "GD iter. 49/499: loss=0.5934835892442727\n",
      "GD iter. 50/499: loss=0.5928648390755086\n",
      "GD iter. 51/499: loss=0.5922590592978704\n",
      "GD iter. 52/499: loss=0.5916653011289773\n",
      "GD iter. 53/499: loss=0.5910736935389859\n",
      "GD iter. 54/499: loss=0.5904887055565975\n",
      "GD iter. 55/499: loss=0.589921534370504\n",
      "GD iter. 56/499: loss=0.5893664289376637\n",
      "GD iter. 57/499: loss=0.5888520567255597\n",
      "GD iter. 58/499: loss=0.5883497328389101\n",
      "GD iter. 59/499: loss=0.5878557905662997\n",
      "GD iter. 60/499: loss=0.5874027039729371\n",
      "GD iter. 61/499: loss=0.586948945628001\n",
      "GD iter. 62/499: loss=0.5865035979441123\n",
      "GD iter. 63/499: loss=0.5860650531398686\n",
      "GD iter. 64/499: loss=0.5856374360920417\n",
      "GD iter. 65/499: loss=0.5852210964468058\n",
      "GD iter. 66/499: loss=0.5848054043293419\n",
      "GD iter. 67/499: loss=0.5843955541135409\n",
      "GD iter. 68/499: loss=0.5840030022467433\n",
      "GD iter. 69/499: loss=0.5836123011340604\n",
      "GD iter. 70/499: loss=0.5832355516709848\n",
      "GD iter. 71/499: loss=0.5828612955608841\n",
      "GD iter. 72/499: loss=0.5825049204399927\n",
      "GD iter. 73/499: loss=0.5821518855751986\n",
      "GD iter. 74/499: loss=0.5818114453213517\n",
      "GD iter. 75/499: loss=0.5814639465489458\n",
      "GD iter. 76/499: loss=0.581129613540306\n",
      "GD iter. 77/499: loss=0.5808062818043226\n",
      "GD iter. 78/499: loss=0.5804761369792937\n",
      "GD iter. 79/499: loss=0.580152078676565\n",
      "GD iter. 80/499: loss=0.5798529063913608\n",
      "GD iter. 81/499: loss=0.5795479510502762\n",
      "GD iter. 82/499: loss=0.5792649901395428\n",
      "GD iter. 83/499: loss=0.5789831087657351\n",
      "GD iter. 84/499: loss=0.5787044274389974\n",
      "GD iter. 85/499: loss=0.578443985287548\n",
      "GD iter. 86/499: loss=0.5781895403919353\n",
      "GD iter. 87/499: loss=0.577920520099574\n",
      "GD iter. 88/499: loss=0.5776659484354996\n",
      "GD iter. 89/499: loss=0.577402315066661\n",
      "GD iter. 90/499: loss=0.5771519645314285\n",
      "GD iter. 91/499: loss=0.5768914158058288\n",
      "GD iter. 92/499: loss=0.5766360595970168\n",
      "GD iter. 93/499: loss=0.5763833002748496\n",
      "GD iter. 94/499: loss=0.5761300648016556\n",
      "GD iter. 95/499: loss=0.5758893795173604\n",
      "GD iter. 96/499: loss=0.5756476137905273\n",
      "GD iter. 97/499: loss=0.5754048339903476\n",
      "GD iter. 98/499: loss=0.5751598761978395\n",
      "GD iter. 99/499: loss=0.5749230962667781\n",
      "GD iter. 100/499: loss=0.5746873021745824\n",
      "GD iter. 101/499: loss=0.5744468353394813\n",
      "GD iter. 102/499: loss=0.57422274676506\n",
      "GD iter. 103/499: loss=0.5740000795988103\n",
      "GD iter. 104/499: loss=0.5737697831493873\n",
      "GD iter. 105/499: loss=0.5735487207140085\n",
      "GD iter. 106/499: loss=0.5733214765860485\n",
      "GD iter. 107/499: loss=0.5731077185363271\n",
      "GD iter. 108/499: loss=0.5728895335221642\n",
      "GD iter. 109/499: loss=0.5726780067003281\n",
      "GD iter. 110/499: loss=0.5724730062657054\n",
      "GD iter. 111/499: loss=0.5722463361195413\n",
      "GD iter. 112/499: loss=0.5720410952869746\n",
      "GD iter. 113/499: loss=0.5718240222604031\n",
      "GD iter. 114/499: loss=0.5716106420245595\n",
      "GD iter. 115/499: loss=0.5714092130892016\n",
      "GD iter. 116/499: loss=0.5712030778978124\n",
      "GD iter. 117/499: loss=0.570992207657638\n",
      "GD iter. 118/499: loss=0.5707811965345456\n",
      "GD iter. 119/499: loss=0.5705821221280856\n",
      "GD iter. 120/499: loss=0.5703789028362151\n",
      "GD iter. 121/499: loss=0.570194563154031\n",
      "GD iter. 122/499: loss=0.5700043342470872\n",
      "GD iter. 123/499: loss=0.5698265542333038\n",
      "GD iter. 124/499: loss=0.56963701290406\n",
      "GD iter. 125/499: loss=0.5694501504198122\n",
      "GD iter. 126/499: loss=0.5692803586665344\n",
      "GD iter. 127/499: loss=0.5690936452060315\n",
      "GD iter. 128/499: loss=0.5689196733971424\n",
      "GD iter. 129/499: loss=0.5687407276345219\n",
      "GD iter. 130/499: loss=0.5685631846398036\n",
      "GD iter. 131/499: loss=0.5683833778500631\n",
      "GD iter. 132/499: loss=0.5682164598067984\n",
      "GD iter. 133/499: loss=0.5680385972403145\n",
      "GD iter. 134/499: loss=0.5678884511868585\n",
      "GD iter. 135/499: loss=0.567722291427207\n",
      "GD iter. 136/499: loss=0.567559223274713\n",
      "GD iter. 137/499: loss=0.5674128882886073\n",
      "GD iter. 138/499: loss=0.5672404680881432\n",
      "GD iter. 139/499: loss=0.5670848867912056\n",
      "GD iter. 140/499: loss=0.566911935114598\n",
      "GD iter. 141/499: loss=0.566756921992734\n",
      "GD iter. 142/499: loss=0.5666018407360067\n",
      "GD iter. 143/499: loss=0.5664453966064623\n",
      "GD iter. 144/499: loss=0.5662973273666678\n",
      "GD iter. 145/499: loss=0.5661433001600142\n",
      "GD iter. 146/499: loss=0.5659893020964344\n",
      "GD iter. 147/499: loss=0.5658438582245434\n",
      "GD iter. 148/499: loss=0.5656932521021387\n",
      "GD iter. 149/499: loss=0.5655445732590095\n",
      "GD iter. 150/499: loss=0.5653931813751784\n",
      "GD iter. 151/499: loss=0.5652486809915687\n",
      "GD iter. 152/499: loss=0.5651087161200516\n",
      "GD iter. 153/499: loss=0.5649631157747581\n",
      "GD iter. 154/499: loss=0.5648292435694843\n",
      "GD iter. 155/499: loss=0.564697781825111\n",
      "GD iter. 156/499: loss=0.5645609574848994\n",
      "GD iter. 157/499: loss=0.5644277260265567\n",
      "GD iter. 158/499: loss=0.5642871563733308\n",
      "GD iter. 159/499: loss=0.5641724289115327\n",
      "GD iter. 160/499: loss=0.5640194299114025\n",
      "GD iter. 161/499: loss=0.5638810173125999\n",
      "GD iter. 162/499: loss=0.5637438520323333\n",
      "GD iter. 163/499: loss=0.5636203024311418\n",
      "GD iter. 164/499: loss=0.5634931161537714\n",
      "GD iter. 165/499: loss=0.5633516857540255\n",
      "GD iter. 166/499: loss=0.5632171384275473\n",
      "GD iter. 167/499: loss=0.5630925206131241\n",
      "GD iter. 168/499: loss=0.5629685292345458\n",
      "GD iter. 169/499: loss=0.5628423091983344\n",
      "GD iter. 170/499: loss=0.5627069563411651\n",
      "GD iter. 171/499: loss=0.5625927848713305\n",
      "GD iter. 172/499: loss=0.5624641660316559\n",
      "GD iter. 173/499: loss=0.5623568781508598\n",
      "GD iter. 174/499: loss=0.562226966054928\n",
      "GD iter. 175/499: loss=0.5621190717621865\n",
      "GD iter. 176/499: loss=0.5620232512459113\n",
      "GD iter. 177/499: loss=0.5619025565366464\n",
      "GD iter. 178/499: loss=0.5617875863390337\n",
      "GD iter. 179/499: loss=0.5616871138649221\n",
      "GD iter. 180/499: loss=0.5615796389537826\n",
      "GD iter. 181/499: loss=0.5614663572312693\n",
      "GD iter. 182/499: loss=0.5613524329859376\n",
      "GD iter. 183/499: loss=0.5612482357295208\n",
      "GD iter. 184/499: loss=0.5611520388542242\n",
      "GD iter. 185/499: loss=0.5610374949568625\n",
      "GD iter. 186/499: loss=0.5609265157161193\n",
      "GD iter. 187/499: loss=0.5608255875480488\n",
      "GD iter. 188/499: loss=0.5607072065464715\n",
      "GD iter. 189/499: loss=0.5606048881288285\n",
      "GD iter. 190/499: loss=0.5604953563277641\n",
      "GD iter. 191/499: loss=0.5603913019542586\n",
      "GD iter. 192/499: loss=0.5602811139115853\n",
      "GD iter. 193/499: loss=0.5601891694613853\n",
      "GD iter. 194/499: loss=0.5600823885157521\n",
      "GD iter. 195/499: loss=0.5599749887774463\n",
      "GD iter. 196/499: loss=0.5598747059222525\n",
      "GD iter. 197/499: loss=0.5597752081235802\n",
      "GD iter. 198/499: loss=0.5596846146130698\n",
      "GD iter. 199/499: loss=0.5595765780373894\n",
      "GD iter. 200/499: loss=0.5594917481125458\n",
      "GD iter. 201/499: loss=0.5593931883680251\n",
      "GD iter. 202/499: loss=0.55929055761293\n",
      "GD iter. 203/499: loss=0.5592027255732261\n",
      "GD iter. 204/499: loss=0.5591246757612605\n",
      "GD iter. 205/499: loss=0.5590157731247493\n",
      "GD iter. 206/499: loss=0.5589351052402689\n",
      "GD iter. 207/499: loss=0.5588290614640031\n",
      "GD iter. 208/499: loss=0.5587357780708435\n",
      "GD iter. 209/499: loss=0.5586615876982944\n",
      "GD iter. 210/499: loss=0.558560923606853\n",
      "GD iter. 211/499: loss=0.5584754284539729\n",
      "GD iter. 212/499: loss=0.5583959113276209\n",
      "GD iter. 213/499: loss=0.5582957540614271\n",
      "GD iter. 214/499: loss=0.5582106138290216\n",
      "GD iter. 215/499: loss=0.558123671887302\n",
      "GD iter. 216/499: loss=0.5580430114727651\n",
      "GD iter. 217/499: loss=0.5579514209000052\n",
      "GD iter. 218/499: loss=0.5578599500167503\n",
      "GD iter. 219/499: loss=0.5577820697729868\n",
      "GD iter. 220/499: loss=0.5577036988048664\n",
      "GD iter. 221/499: loss=0.5576138180339271\n",
      "GD iter. 222/499: loss=0.5575204346455711\n",
      "GD iter. 223/499: loss=0.557440601170262\n",
      "GD iter. 224/499: loss=0.5573660509083945\n",
      "GD iter. 225/499: loss=0.5572654689725346\n",
      "GD iter. 226/499: loss=0.5571764122272888\n",
      "GD iter. 227/499: loss=0.5571090029876146\n",
      "GD iter. 228/499: loss=0.5570293080548089\n",
      "GD iter. 229/499: loss=0.5569354852494559\n",
      "GD iter. 230/499: loss=0.556870956921224\n",
      "GD iter. 231/499: loss=0.5567702712743068\n",
      "GD iter. 232/499: loss=0.5566875330506139\n",
      "GD iter. 233/499: loss=0.5566090600572132\n",
      "GD iter. 234/499: loss=0.5565232831360128\n",
      "GD iter. 235/499: loss=0.5564371568240422\n",
      "GD iter. 236/499: loss=0.5563588993506592\n",
      "GD iter. 237/499: loss=0.556291056846067\n",
      "GD iter. 238/499: loss=0.5561978746323923\n",
      "GD iter. 239/499: loss=0.5561183785114717\n",
      "GD iter. 240/499: loss=0.5560287585034063\n",
      "GD iter. 241/499: loss=0.555950798234045\n",
      "GD iter. 242/499: loss=0.5558865278031324\n",
      "GD iter. 243/499: loss=0.555801061924753\n",
      "GD iter. 244/499: loss=0.5557142457039596\n",
      "GD iter. 245/499: loss=0.5556485854868726\n",
      "GD iter. 246/499: loss=0.5555673578003378\n",
      "GD iter. 247/499: loss=0.5554831284177653\n",
      "GD iter. 248/499: loss=0.5554012895573013\n",
      "GD iter. 249/499: loss=0.555326780185561\n",
      "GD iter. 250/499: loss=0.5552512268155899\n",
      "GD iter. 251/499: loss=0.555169451047711\n",
      "GD iter. 252/499: loss=0.5550849618816512\n",
      "GD iter. 253/499: loss=0.5550173624118788\n",
      "GD iter. 254/499: loss=0.5549476627837968\n",
      "GD iter. 255/499: loss=0.5548694163100769\n",
      "GD iter. 256/499: loss=0.554788021881268\n",
      "GD iter. 257/499: loss=0.5547149701427587\n",
      "GD iter. 258/499: loss=0.5546483522611432\n",
      "GD iter. 259/499: loss=0.5545930595544384\n",
      "GD iter. 260/499: loss=0.5545088495571123\n",
      "GD iter. 261/499: loss=0.5544196834233449\n",
      "GD iter. 262/499: loss=0.5543542503526468\n",
      "GD iter. 263/499: loss=0.5542900284641811\n",
      "GD iter. 264/499: loss=0.5542303772578098\n",
      "GD iter. 265/499: loss=0.5541436043416238\n",
      "GD iter. 266/499: loss=0.5540982547848934\n",
      "GD iter. 267/499: loss=0.5540145809607577\n",
      "GD iter. 268/499: loss=0.5539585585537565\n",
      "GD iter. 269/499: loss=0.5538769967463696\n",
      "GD iter. 270/499: loss=0.5538204171614867\n",
      "GD iter. 271/499: loss=0.5537537652110583\n",
      "GD iter. 272/499: loss=0.5536883494552572\n",
      "GD iter. 273/499: loss=0.553614414632163\n",
      "GD iter. 274/499: loss=0.5535496094214801\n",
      "GD iter. 275/499: loss=0.5534907712179725\n",
      "GD iter. 276/499: loss=0.553432864868956\n",
      "GD iter. 277/499: loss=0.5533641429336594\n",
      "GD iter. 278/499: loss=0.5533163698828265\n",
      "GD iter. 279/499: loss=0.5532363816128031\n",
      "GD iter. 280/499: loss=0.5531682236739486\n",
      "GD iter. 281/499: loss=0.5530957676815152\n",
      "GD iter. 282/499: loss=0.5530520153130707\n",
      "GD iter. 283/499: loss=0.5529950089921601\n",
      "GD iter. 284/499: loss=0.5529336733580005\n",
      "GD iter. 285/499: loss=0.5528650533941101\n",
      "GD iter. 286/499: loss=0.5528088187502769\n",
      "GD iter. 287/499: loss=0.5527531096466624\n",
      "GD iter. 288/499: loss=0.5526872842969776\n",
      "GD iter. 289/499: loss=0.5526227771760565\n",
      "GD iter. 290/499: loss=0.5525621516545708\n",
      "GD iter. 291/499: loss=0.5525008580381009\n",
      "GD iter. 292/499: loss=0.5524490643421508\n",
      "GD iter. 293/499: loss=0.5524030635769607\n",
      "GD iter. 294/499: loss=0.5523210302632695\n",
      "GD iter. 295/499: loss=0.5522831612816851\n",
      "GD iter. 296/499: loss=0.5522254550017013\n",
      "GD iter. 297/499: loss=0.5521591529395524\n",
      "GD iter. 298/499: loss=0.5520771328985242\n",
      "GD iter. 299/499: loss=0.552045888280635\n",
      "GD iter. 300/499: loss=0.5519999304075958\n",
      "GD iter. 301/499: loss=0.5519455851778367\n",
      "GD iter. 302/499: loss=0.55185169146621\n",
      "GD iter. 303/499: loss=0.5518173991509626\n",
      "GD iter. 304/499: loss=0.5517430137571884\n",
      "GD iter. 305/499: loss=0.551684290680481\n",
      "GD iter. 306/499: loss=0.5516411928351658\n",
      "GD iter. 307/499: loss=0.5515920214107081\n",
      "GD iter. 308/499: loss=0.5515438412961585\n",
      "GD iter. 309/499: loss=0.5514785024201264\n",
      "GD iter. 310/499: loss=0.5514357148457557\n",
      "GD iter. 311/499: loss=0.5513789455358085\n",
      "GD iter. 312/499: loss=0.5513141378450911\n",
      "GD iter. 313/499: loss=0.5512626517188723\n",
      "GD iter. 314/499: loss=0.5512247110979006\n",
      "GD iter. 315/499: loss=0.551164677930385\n",
      "GD iter. 316/499: loss=0.5511055988318406\n",
      "GD iter. 317/499: loss=0.5510611358287159\n",
      "GD iter. 318/499: loss=0.5510288264577868\n",
      "GD iter. 319/499: loss=0.5509519838018119\n",
      "GD iter. 320/499: loss=0.5509253861338854\n",
      "GD iter. 321/499: loss=0.550871752582098\n",
      "GD iter. 322/499: loss=0.550822388021887\n",
      "GD iter. 323/499: loss=0.5507858303982353\n",
      "GD iter. 324/499: loss=0.5507369558486221\n",
      "GD iter. 325/499: loss=0.5506862690386737\n",
      "GD iter. 326/499: loss=0.5506281988188333\n",
      "GD iter. 327/499: loss=0.5505911833761313\n",
      "GD iter. 328/499: loss=0.5505436053390036\n",
      "GD iter. 329/499: loss=0.5505115721546203\n",
      "GD iter. 330/499: loss=0.5504436666030036\n",
      "GD iter. 331/499: loss=0.5504246593131421\n",
      "GD iter. 332/499: loss=0.5503681602604029\n",
      "GD iter. 333/499: loss=0.5503218878075102\n",
      "GD iter. 334/499: loss=0.550274438561441\n",
      "GD iter. 335/499: loss=0.5502696937076691\n",
      "GD iter. 336/499: loss=0.5501874507858587\n",
      "GD iter. 337/499: loss=0.5501693550302905\n",
      "GD iter. 338/499: loss=0.5501005771693057\n",
      "GD iter. 339/499: loss=0.5500517070999825\n",
      "GD iter. 340/499: loss=0.5500221286555625\n",
      "GD iter. 341/499: loss=0.5499777137233162\n",
      "GD iter. 342/499: loss=0.5499263695815966\n",
      "GD iter. 343/499: loss=0.5498955912668521\n",
      "GD iter. 344/499: loss=0.5498823402892761\n",
      "GD iter. 345/499: loss=0.5498212793722873\n",
      "GD iter. 346/499: loss=0.5497864613148339\n",
      "GD iter. 347/499: loss=0.5497746719255456\n",
      "GD iter. 348/499: loss=0.5496989141076015\n",
      "GD iter. 349/499: loss=0.5496940323543064\n",
      "GD iter. 350/499: loss=0.5496377920060525\n",
      "GD iter. 351/499: loss=0.5496193257518076\n",
      "GD iter. 352/499: loss=0.5495633803023292\n",
      "GD iter. 353/499: loss=0.5495247100718321\n",
      "GD iter. 354/499: loss=0.5494854187885767\n",
      "GD iter. 355/499: loss=0.5494596983753401\n",
      "GD iter. 356/499: loss=0.5494150482705548\n",
      "GD iter. 357/499: loss=0.5493706310617126\n",
      "GD iter. 358/499: loss=0.5493383191177731\n",
      "GD iter. 359/499: loss=0.549300737584585\n",
      "GD iter. 360/499: loss=0.5492646005952203\n",
      "GD iter. 361/499: loss=0.5492393840108646\n",
      "GD iter. 362/499: loss=0.5492029270500443\n",
      "GD iter. 363/499: loss=0.5491557099527645\n",
      "GD iter. 364/499: loss=0.5491101197969528\n",
      "GD iter. 365/499: loss=0.5490932749977812\n",
      "GD iter. 366/499: loss=0.5490568794980528\n",
      "GD iter. 367/499: loss=0.5490164423453643\n",
      "GD iter. 368/499: loss=0.54896809790649\n",
      "GD iter. 369/499: loss=0.5489418228675472\n",
      "GD iter. 370/499: loss=0.5489222291550446\n",
      "GD iter. 371/499: loss=0.5488661192362343\n",
      "GD iter. 372/499: loss=0.5488286690018982\n",
      "GD iter. 373/499: loss=0.5488131393319629\n",
      "GD iter. 374/499: loss=0.5487806904687828\n",
      "GD iter. 375/499: loss=0.5487618952215167\n",
      "GD iter. 376/499: loss=0.548690711668735\n",
      "GD iter. 377/499: loss=0.5486804698753261\n",
      "GD iter. 378/499: loss=0.548622617460219\n",
      "GD iter. 379/499: loss=0.5486169508221419\n",
      "GD iter. 380/499: loss=0.548600861576087\n",
      "GD iter. 381/499: loss=0.5485461326705989\n",
      "GD iter. 382/499: loss=0.5485148899136877\n",
      "GD iter. 383/499: loss=0.5484999751105212\n",
      "GD iter. 384/499: loss=0.5484732511153615\n",
      "GD iter. 385/499: loss=0.5484067858845623\n",
      "GD iter. 386/499: loss=0.548381227096668\n",
      "GD iter. 387/499: loss=0.5483299925836198\n",
      "GD iter. 388/499: loss=0.548321217020536\n",
      "GD iter. 389/499: loss=0.5482839236764364\n",
      "GD iter. 390/499: loss=0.5482404106336045\n",
      "GD iter. 391/499: loss=0.5482414657669482\n",
      "GD iter. 392/499: loss=0.5481791659413248\n",
      "GD iter. 393/499: loss=0.548184385044129\n",
      "GD iter. 394/499: loss=0.5481193320714701\n",
      "GD iter. 395/499: loss=0.5481020257228787\n",
      "GD iter. 396/499: loss=0.5480700623072614\n",
      "GD iter. 397/499: loss=0.5480331742821746\n",
      "GD iter. 398/499: loss=0.547999288767874\n",
      "GD iter. 399/499: loss=0.54796222650632\n",
      "GD iter. 400/499: loss=0.5479628941127238\n",
      "GD iter. 401/499: loss=0.547898580791885\n",
      "GD iter. 402/499: loss=0.5478853429328386\n",
      "GD iter. 403/499: loss=0.5478582273802117\n",
      "GD iter. 404/499: loss=0.5478065402807477\n",
      "GD iter. 405/499: loss=0.5478067471638075\n",
      "GD iter. 406/499: loss=0.5477449827433649\n",
      "GD iter. 407/499: loss=0.5477102466941977\n",
      "GD iter. 408/499: loss=0.5476899707767271\n",
      "GD iter. 409/499: loss=0.5476638282613306\n",
      "GD iter. 410/499: loss=0.5476265982922345\n",
      "GD iter. 411/499: loss=0.5476085381994724\n",
      "GD iter. 412/499: loss=0.5475766255304764\n",
      "GD iter. 413/499: loss=0.5475499041077379\n",
      "GD iter. 414/499: loss=0.5475054838802674\n",
      "GD iter. 415/499: loss=0.5475201039715406\n",
      "GD iter. 416/499: loss=0.5474936422417835\n",
      "GD iter. 417/499: loss=0.5474167811397048\n",
      "GD iter. 418/499: loss=0.5473903264859438\n",
      "GD iter. 419/499: loss=0.5473830726382458\n",
      "GD iter. 420/499: loss=0.5473679652072946\n",
      "GD iter. 421/499: loss=0.5473402045137702\n",
      "GD iter. 422/499: loss=0.5472836714803827\n",
      "GD iter. 423/499: loss=0.5472635602271299\n",
      "GD iter. 424/499: loss=0.5472469985267984\n",
      "GD iter. 425/499: loss=0.5472275241257769\n",
      "GD iter. 426/499: loss=0.5471849052245581\n",
      "GD iter. 427/499: loss=0.5471877456874125\n",
      "GD iter. 428/499: loss=0.5471256268237087\n",
      "GD iter. 429/499: loss=0.5471268912758694\n",
      "GD iter. 430/499: loss=0.5470871392381105\n",
      "GD iter. 431/499: loss=0.5470819503944684\n",
      "GD iter. 432/499: loss=0.5470367103817113\n",
      "GD iter. 433/499: loss=0.5470177586323399\n",
      "GD iter. 434/499: loss=0.547011924068766\n",
      "GD iter. 435/499: loss=0.5469590374142532\n",
      "GD iter. 436/499: loss=0.5469503420111341\n",
      "GD iter. 437/499: loss=0.5469184891812688\n",
      "GD iter. 438/499: loss=0.5469064377486144\n",
      "GD iter. 439/499: loss=0.5468719992058864\n",
      "GD iter. 440/499: loss=0.5468429882072072\n",
      "GD iter. 441/499: loss=0.5468072359126425\n",
      "GD iter. 442/499: loss=0.5468127490120778\n",
      "GD iter. 443/499: loss=0.5467961369827989\n",
      "GD iter. 444/499: loss=0.5467717143672929\n",
      "GD iter. 445/499: loss=0.5467238789894471\n",
      "GD iter. 446/499: loss=0.5467099220345604\n",
      "GD iter. 447/499: loss=0.5466761056345645\n",
      "GD iter. 448/499: loss=0.5466775562996735\n",
      "GD iter. 449/499: loss=0.5466403357798226\n",
      "GD iter. 450/499: loss=0.5466137384305639\n",
      "GD iter. 451/499: loss=0.5465939110990873\n",
      "GD iter. 452/499: loss=0.5465849382795738\n",
      "GD iter. 453/499: loss=0.5465430117868767\n",
      "GD iter. 454/499: loss=0.5465293173811072\n",
      "GD iter. 455/499: loss=0.5465051275503419\n",
      "GD iter. 456/499: loss=0.5464965760014029\n",
      "GD iter. 457/499: loss=0.5464494669660337\n",
      "GD iter. 458/499: loss=0.5464363981164051\n",
      "GD iter. 459/499: loss=0.5464052344402789\n",
      "GD iter. 460/499: loss=0.5463895469925873\n",
      "GD iter. 461/499: loss=0.5463596319210563\n",
      "GD iter. 462/499: loss=0.546361535317457\n",
      "GD iter. 463/499: loss=0.5463556845948302\n",
      "GD iter. 464/499: loss=0.5463261616899604\n",
      "GD iter. 465/499: loss=0.5462811040353267\n",
      "GD iter. 466/499: loss=0.5462734435840371\n",
      "GD iter. 467/499: loss=0.5462380123665312\n",
      "GD iter. 468/499: loss=0.5462179671690504\n",
      "GD iter. 469/499: loss=0.5462197736421456\n",
      "GD iter. 470/499: loss=0.5462211716468995\n",
      "GD iter. 471/499: loss=0.5461706665006093\n",
      "GD iter. 472/499: loss=0.5461609509091367\n",
      "GD iter. 473/499: loss=0.5461315023351397\n",
      "GD iter. 474/499: loss=0.5460898130483564\n",
      "GD iter. 475/499: loss=0.5460913858382606\n",
      "GD iter. 476/499: loss=0.5460591352286536\n",
      "GD iter. 477/499: loss=0.5460298164689241\n",
      "GD iter. 478/499: loss=0.5460047520822782\n",
      "GD iter. 479/499: loss=0.5460015959646642\n",
      "GD iter. 480/499: loss=0.5460027467093213\n",
      "GD iter. 481/499: loss=0.5459703145259716\n",
      "GD iter. 482/499: loss=0.5459515654759876\n",
      "GD iter. 483/499: loss=0.5459382672031835\n",
      "GD iter. 484/499: loss=0.545907983816206\n",
      "GD iter. 485/499: loss=0.5458952013619761\n",
      "GD iter. 486/499: loss=0.5458762827685868\n",
      "GD iter. 487/499: loss=0.5458444088043528\n",
      "GD iter. 488/499: loss=0.5458558909362217\n",
      "GD iter. 489/499: loss=0.5458107904320904\n",
      "GD iter. 490/499: loss=0.5457781903312042\n",
      "GD iter. 491/499: loss=0.5457573289125549\n",
      "GD iter. 492/499: loss=0.5457655462664469\n",
      "GD iter. 493/499: loss=0.5457438279118495\n",
      "GD iter. 494/499: loss=0.5457272585417129\n",
      "GD iter. 495/499: loss=0.5457177923139348\n",
      "GD iter. 496/499: loss=0.5456685102031769\n",
      "GD iter. 497/499: loss=0.5456686261122949\n",
      "GD iter. 498/499: loss=0.5456328145237206\n",
      "GD iter. 499/499: loss=0.5456472400893104\n",
      "The Accuracy is: 0.6836\n",
      "The F1 score is: 0.3275\n",
      "The precision is: 0.2009\n",
      "The recall is: 0.8868\n",
      "GD iter. 0/499: loss=1.001443213982749\n",
      "GD iter. 1/499: loss=0.9271951810180062\n",
      "GD iter. 2/499: loss=0.8547421274993583\n",
      "GD iter. 3/499: loss=0.787658287490322\n",
      "GD iter. 4/499: loss=0.7370976360095324\n",
      "GD iter. 5/499: loss=0.7077903398154891\n",
      "GD iter. 6/499: loss=0.6887002485912006\n",
      "GD iter. 7/499: loss=0.6754142942125184\n",
      "GD iter. 8/499: loss=0.6644943601765406\n",
      "GD iter. 9/499: loss=0.6559681535762485\n",
      "GD iter. 10/499: loss=0.6490235560409459\n",
      "GD iter. 11/499: loss=0.643655849297246\n",
      "GD iter. 12/499: loss=0.6390454504078155\n",
      "GD iter. 13/499: loss=0.635164130190213\n",
      "GD iter. 14/499: loss=0.631817292697077\n",
      "GD iter. 15/499: loss=0.6288299654527015\n",
      "GD iter. 16/499: loss=0.62596866662966\n",
      "GD iter. 17/499: loss=0.6234777908247436\n",
      "GD iter. 18/499: loss=0.6210669089326496\n",
      "GD iter. 19/499: loss=0.6188278657898544\n",
      "GD iter. 20/499: loss=0.6166935503305478\n",
      "GD iter. 21/499: loss=0.6147400127104339\n",
      "GD iter. 22/499: loss=0.6129851872047201\n",
      "GD iter. 23/499: loss=0.6112641444879723\n",
      "GD iter. 24/499: loss=0.6096226626063236\n",
      "GD iter. 25/499: loss=0.6080443632086954\n",
      "GD iter. 26/499: loss=0.6065917215309969\n",
      "GD iter. 27/499: loss=0.6052398615649632\n",
      "GD iter. 28/499: loss=0.6038990445143819\n",
      "GD iter. 29/499: loss=0.6026214063856757\n",
      "GD iter. 30/499: loss=0.6014248522064859\n",
      "GD iter. 31/499: loss=0.6002935954843568\n",
      "GD iter. 32/499: loss=0.599231388489328\n",
      "GD iter. 33/499: loss=0.5981916755176606\n",
      "GD iter. 34/499: loss=0.597202111561487\n",
      "GD iter. 35/499: loss=0.596260580993177\n",
      "GD iter. 36/499: loss=0.5953807379398447\n",
      "GD iter. 37/499: loss=0.5945391890853141\n",
      "GD iter. 38/499: loss=0.5937429607062066\n",
      "GD iter. 39/499: loss=0.593005472816222\n",
      "GD iter. 40/499: loss=0.5922916200335059\n",
      "GD iter. 41/499: loss=0.5916204460400499\n",
      "GD iter. 42/499: loss=0.5909568974883254\n",
      "GD iter. 43/499: loss=0.5903011192976284\n",
      "GD iter. 44/499: loss=0.5896561686466727\n",
      "GD iter. 45/499: loss=0.5890132203798026\n",
      "GD iter. 46/499: loss=0.5883868780090321\n",
      "GD iter. 47/499: loss=0.5877654179691845\n",
      "GD iter. 48/499: loss=0.5871468421878756\n",
      "GD iter. 49/499: loss=0.5865383625930521\n",
      "GD iter. 50/499: loss=0.5859360071884238\n",
      "GD iter. 51/499: loss=0.5853581444482874\n",
      "GD iter. 52/499: loss=0.5847989814846307\n",
      "GD iter. 53/499: loss=0.5842592622723594\n",
      "GD iter. 54/499: loss=0.5837248536117082\n",
      "GD iter. 55/499: loss=0.5831955371676498\n",
      "GD iter. 56/499: loss=0.5826893373320984\n",
      "GD iter. 57/499: loss=0.582200954971343\n",
      "GD iter. 58/499: loss=0.5817247339600652\n",
      "GD iter. 59/499: loss=0.5812453760380333\n",
      "GD iter. 60/499: loss=0.5807868656019177\n",
      "GD iter. 61/499: loss=0.5803244283622625\n",
      "GD iter. 62/499: loss=0.5798615066196635\n",
      "GD iter. 63/499: loss=0.5794031379695145\n",
      "GD iter. 64/499: loss=0.5789586123667303\n",
      "GD iter. 65/499: loss=0.5785163361857791\n",
      "GD iter. 66/499: loss=0.5780698815312905\n",
      "GD iter. 67/499: loss=0.5776612238691999\n",
      "GD iter. 68/499: loss=0.5772371343073031\n",
      "GD iter. 69/499: loss=0.5768164472828268\n",
      "GD iter. 70/499: loss=0.5764196821250788\n",
      "GD iter. 71/499: loss=0.576039607252746\n",
      "GD iter. 72/499: loss=0.57565795293711\n",
      "GD iter. 73/499: loss=0.5752739755914781\n",
      "GD iter. 74/499: loss=0.5748942768517488\n",
      "GD iter. 75/499: loss=0.5745165732558439\n",
      "GD iter. 76/499: loss=0.574149984348505\n",
      "GD iter. 77/499: loss=0.5737785203069411\n",
      "GD iter. 78/499: loss=0.5734196671671974\n",
      "GD iter. 79/499: loss=0.5730593575611669\n",
      "GD iter. 80/499: loss=0.5727207027722984\n",
      "GD iter. 81/499: loss=0.5723962415951276\n",
      "GD iter. 82/499: loss=0.5720834068469203\n",
      "GD iter. 83/499: loss=0.5717908511102056\n",
      "GD iter. 84/499: loss=0.5714975141115709\n",
      "GD iter. 85/499: loss=0.5712124318001083\n",
      "GD iter. 86/499: loss=0.5709414841498457\n",
      "GD iter. 87/499: loss=0.5706852860711066\n",
      "GD iter. 88/499: loss=0.5704260041656614\n",
      "GD iter. 89/499: loss=0.5701676758443535\n",
      "GD iter. 90/499: loss=0.5699177164447269\n",
      "GD iter. 91/499: loss=0.5696696261109068\n",
      "GD iter. 92/499: loss=0.5694528799084104\n",
      "GD iter. 93/499: loss=0.5692273669704933\n",
      "GD iter. 94/499: loss=0.5690038906759932\n",
      "GD iter. 95/499: loss=0.568781553030416\n",
      "GD iter. 96/499: loss=0.5685617976796848\n",
      "GD iter. 97/499: loss=0.5683369058245545\n",
      "GD iter. 98/499: loss=0.5681263662945504\n",
      "GD iter. 99/499: loss=0.5679128048663149\n",
      "GD iter. 100/499: loss=0.5676957956049334\n",
      "GD iter. 101/499: loss=0.5674852307560434\n",
      "GD iter. 102/499: loss=0.5672751589210885\n",
      "GD iter. 103/499: loss=0.5670625003566558\n",
      "GD iter. 104/499: loss=0.5668545060439933\n",
      "GD iter. 105/499: loss=0.5666424582323754\n",
      "GD iter. 106/499: loss=0.5664343361747195\n",
      "GD iter. 107/499: loss=0.5662409507334829\n",
      "GD iter. 108/499: loss=0.5660426030782305\n",
      "GD iter. 109/499: loss=0.5658563082774979\n",
      "GD iter. 110/499: loss=0.5656675186757311\n",
      "GD iter. 111/499: loss=0.5654870551109216\n",
      "GD iter. 112/499: loss=0.5652990987883751\n",
      "GD iter. 113/499: loss=0.5651386912544729\n",
      "GD iter. 114/499: loss=0.5649753243756573\n",
      "GD iter. 115/499: loss=0.564799182228966\n",
      "GD iter. 116/499: loss=0.5646306161877811\n",
      "GD iter. 117/499: loss=0.5644747571251398\n",
      "GD iter. 118/499: loss=0.5643185842493186\n",
      "GD iter. 119/499: loss=0.5641386888934542\n",
      "GD iter. 120/499: loss=0.5639901670258615\n",
      "GD iter. 121/499: loss=0.5638470050831176\n",
      "GD iter. 122/499: loss=0.563698074008126\n",
      "GD iter. 123/499: loss=0.5635381081982218\n",
      "GD iter. 124/499: loss=0.5634003902536887\n",
      "GD iter. 125/499: loss=0.5632523541231165\n",
      "GD iter. 126/499: loss=0.5631091801666422\n",
      "GD iter. 127/499: loss=0.5629922721864947\n",
      "GD iter. 128/499: loss=0.5628540505040132\n",
      "GD iter. 129/499: loss=0.5626994667944765\n",
      "GD iter. 130/499: loss=0.5625607117672109\n",
      "GD iter. 131/499: loss=0.5624205351511301\n",
      "GD iter. 132/499: loss=0.5622969430989498\n",
      "GD iter. 133/499: loss=0.5621577626826675\n",
      "GD iter. 134/499: loss=0.5620176648178579\n",
      "GD iter. 135/499: loss=0.561885632167022\n",
      "GD iter. 136/499: loss=0.5617620158225313\n",
      "GD iter. 137/499: loss=0.5616274731894868\n",
      "GD iter. 138/499: loss=0.5614801330766376\n",
      "GD iter. 139/499: loss=0.56136278123305\n",
      "GD iter. 140/499: loss=0.561225562529799\n",
      "GD iter. 141/499: loss=0.5611055327970298\n",
      "GD iter. 142/499: loss=0.560964096864081\n",
      "GD iter. 143/499: loss=0.5608590513618468\n",
      "GD iter. 144/499: loss=0.5607200016040783\n",
      "GD iter. 145/499: loss=0.5606031453431295\n",
      "GD iter. 146/499: loss=0.5604655622925506\n",
      "GD iter. 147/499: loss=0.5603475508682758\n",
      "GD iter. 148/499: loss=0.5602228256458605\n",
      "GD iter. 149/499: loss=0.5601131479281518\n",
      "GD iter. 150/499: loss=0.5599916406332386\n",
      "GD iter. 151/499: loss=0.5598752985325273\n",
      "GD iter. 152/499: loss=0.5597534936338903\n",
      "GD iter. 153/499: loss=0.5596459287937186\n",
      "GD iter. 154/499: loss=0.5595376836946306\n",
      "GD iter. 155/499: loss=0.5594235811787981\n",
      "GD iter. 156/499: loss=0.5593029752542863\n",
      "GD iter. 157/499: loss=0.5591825326958605\n",
      "GD iter. 158/499: loss=0.5590839695180732\n",
      "GD iter. 159/499: loss=0.5589646139272607\n",
      "GD iter. 160/499: loss=0.5588651141937503\n",
      "GD iter. 161/499: loss=0.5587600779584043\n",
      "GD iter. 162/499: loss=0.5586405007717143\n",
      "GD iter. 163/499: loss=0.5585318554934918\n",
      "GD iter. 164/499: loss=0.5584136956336273\n",
      "GD iter. 165/499: loss=0.558317615670815\n",
      "GD iter. 166/499: loss=0.5582048064376413\n",
      "GD iter. 167/499: loss=0.5580980002401281\n",
      "GD iter. 168/499: loss=0.557999726501673\n",
      "GD iter. 169/499: loss=0.5578947866542783\n",
      "GD iter. 170/499: loss=0.5577903413545509\n",
      "GD iter. 171/499: loss=0.5576749323807122\n",
      "GD iter. 172/499: loss=0.5575892970892713\n",
      "GD iter. 173/499: loss=0.5574818920952865\n",
      "GD iter. 174/499: loss=0.5573930864537945\n",
      "GD iter. 175/499: loss=0.5573014772265918\n",
      "GD iter. 176/499: loss=0.5571905302917756\n",
      "GD iter. 177/499: loss=0.5571062261402734\n",
      "GD iter. 178/499: loss=0.5569950739132682\n",
      "GD iter. 179/499: loss=0.556913311886372\n",
      "GD iter. 180/499: loss=0.5568416640133302\n",
      "GD iter. 181/499: loss=0.5567354836208296\n",
      "GD iter. 182/499: loss=0.5566410311919335\n",
      "GD iter. 183/499: loss=0.5565506024932965\n",
      "GD iter. 184/499: loss=0.5564608329650014\n",
      "GD iter. 185/499: loss=0.5563672543595625\n",
      "GD iter. 186/499: loss=0.5562936570694534\n",
      "GD iter. 187/499: loss=0.5561995581747317\n",
      "GD iter. 188/499: loss=0.5561002886604433\n",
      "GD iter. 189/499: loss=0.556011657372128\n",
      "GD iter. 190/499: loss=0.5559193999020337\n",
      "GD iter. 191/499: loss=0.5558369786361244\n",
      "GD iter. 192/499: loss=0.55577331760601\n",
      "GD iter. 193/499: loss=0.5556667450836489\n",
      "GD iter. 194/499: loss=0.5555717982580476\n",
      "GD iter. 195/499: loss=0.5555306183736021\n",
      "GD iter. 196/499: loss=0.5554349010406272\n",
      "GD iter. 197/499: loss=0.5553326434886032\n",
      "GD iter. 198/499: loss=0.5552626601081306\n",
      "GD iter. 199/499: loss=0.5551736313224208\n",
      "GD iter. 200/499: loss=0.5550886398833759\n",
      "GD iter. 201/499: loss=0.5550122180081957\n",
      "GD iter. 202/499: loss=0.5549461548718853\n",
      "GD iter. 203/499: loss=0.5548615099713021\n",
      "GD iter. 204/499: loss=0.5547884739151651\n",
      "GD iter. 205/499: loss=0.5547095263535017\n",
      "GD iter. 206/499: loss=0.554625140821479\n",
      "GD iter. 207/499: loss=0.5545625377534458\n",
      "GD iter. 208/499: loss=0.5544694471658338\n",
      "GD iter. 209/499: loss=0.5543904334439059\n",
      "GD iter. 210/499: loss=0.5543041779192154\n",
      "GD iter. 211/499: loss=0.5542422374430191\n",
      "GD iter. 212/499: loss=0.5541807309624882\n",
      "GD iter. 213/499: loss=0.5540960973754079\n",
      "GD iter. 214/499: loss=0.5539903352580143\n",
      "GD iter. 215/499: loss=0.5539273804621145\n",
      "GD iter. 216/499: loss=0.5538512372891672\n",
      "GD iter. 217/499: loss=0.55378909058754\n",
      "GD iter. 218/499: loss=0.5537019982578104\n",
      "GD iter. 219/499: loss=0.5536359745547904\n",
      "GD iter. 220/499: loss=0.5535577363138517\n",
      "GD iter. 221/499: loss=0.5534774523128617\n",
      "GD iter. 222/499: loss=0.5534016715376606\n",
      "GD iter. 223/499: loss=0.5533473307345518\n",
      "GD iter. 224/499: loss=0.5532641929094354\n",
      "GD iter. 225/499: loss=0.5532233184307602\n",
      "GD iter. 226/499: loss=0.553126697383773\n",
      "GD iter. 227/499: loss=0.5530664252003604\n",
      "GD iter. 228/499: loss=0.5529959072725091\n",
      "GD iter. 229/499: loss=0.5529234722460088\n",
      "GD iter. 230/499: loss=0.5528690503213723\n",
      "GD iter. 231/499: loss=0.5528040295627575\n",
      "GD iter. 232/499: loss=0.552734695054495\n",
      "GD iter. 233/499: loss=0.5526692019095564\n",
      "GD iter. 234/499: loss=0.5526182324689307\n",
      "GD iter. 235/499: loss=0.5525278888696887\n",
      "GD iter. 236/499: loss=0.5524923440183221\n",
      "GD iter. 237/499: loss=0.5524188642969555\n",
      "GD iter. 238/499: loss=0.5523507538400138\n",
      "GD iter. 239/499: loss=0.5522777161338742\n",
      "GD iter. 240/499: loss=0.5522110103964466\n",
      "GD iter. 241/499: loss=0.5521571783483563\n",
      "GD iter. 242/499: loss=0.5520963175282337\n",
      "GD iter. 243/499: loss=0.5520208166437883\n",
      "GD iter. 244/499: loss=0.5519654033475647\n",
      "GD iter. 245/499: loss=0.5518935636079596\n",
      "GD iter. 246/499: loss=0.551846057933294\n",
      "GD iter. 247/499: loss=0.5517813486612754\n",
      "GD iter. 248/499: loss=0.5517304342762851\n",
      "GD iter. 249/499: loss=0.5516644543009976\n",
      "GD iter. 250/499: loss=0.5516043522369771\n",
      "GD iter. 251/499: loss=0.5515617261814704\n",
      "GD iter. 252/499: loss=0.5514795930405428\n",
      "GD iter. 253/499: loss=0.5514167739370122\n",
      "GD iter. 254/499: loss=0.5513549732326047\n",
      "GD iter. 255/499: loss=0.5512900704964653\n",
      "GD iter. 256/499: loss=0.5512313914316557\n",
      "GD iter. 257/499: loss=0.5511710667904418\n",
      "GD iter. 258/499: loss=0.5511208996069727\n",
      "GD iter. 259/499: loss=0.5510561508861634\n",
      "GD iter. 260/499: loss=0.551014974231459\n",
      "GD iter. 261/499: loss=0.5509408814614782\n",
      "GD iter. 262/499: loss=0.5508787117037174\n",
      "GD iter. 263/499: loss=0.5508138304885827\n",
      "GD iter. 264/499: loss=0.5507679984367814\n",
      "GD iter. 265/499: loss=0.5507132808581252\n",
      "GD iter. 266/499: loss=0.5506569437398273\n",
      "GD iter. 267/499: loss=0.5505896691447797\n",
      "GD iter. 268/499: loss=0.5505426275362097\n",
      "GD iter. 269/499: loss=0.5504864555099621\n",
      "GD iter. 270/499: loss=0.5504254103233451\n",
      "GD iter. 271/499: loss=0.5503525065620537\n",
      "GD iter. 272/499: loss=0.5503187462122718\n",
      "GD iter. 273/499: loss=0.5502795469856809\n",
      "GD iter. 274/499: loss=0.5502062416293911\n",
      "GD iter. 275/499: loss=0.5501369622247687\n",
      "GD iter. 276/499: loss=0.5500987181445984\n",
      "GD iter. 277/499: loss=0.5500492707326496\n",
      "GD iter. 278/499: loss=0.5499867348462109\n",
      "GD iter. 279/499: loss=0.549938445842265\n",
      "GD iter. 280/499: loss=0.5498895442023626\n",
      "GD iter. 281/499: loss=0.5498615375518139\n",
      "GD iter. 282/499: loss=0.5497766032835277\n",
      "GD iter. 283/499: loss=0.5497394275426685\n",
      "GD iter. 284/499: loss=0.5497001747607312\n",
      "GD iter. 285/499: loss=0.5496643034778685\n",
      "GD iter. 286/499: loss=0.5495855668729969\n",
      "GD iter. 287/499: loss=0.5495260286755582\n",
      "GD iter. 288/499: loss=0.5494940098795636\n",
      "GD iter. 289/499: loss=0.549441419059247\n",
      "GD iter. 290/499: loss=0.5493780262992566\n",
      "GD iter. 291/499: loss=0.5493356763115336\n",
      "GD iter. 292/499: loss=0.5492780327397963\n",
      "GD iter. 293/499: loss=0.5492314413791676\n",
      "GD iter. 294/499: loss=0.5491913214903924\n",
      "GD iter. 295/499: loss=0.5491187698399179\n",
      "GD iter. 296/499: loss=0.5490818747046315\n",
      "GD iter. 297/499: loss=0.5490244592823625\n",
      "GD iter. 298/499: loss=0.5489822597083375\n",
      "GD iter. 299/499: loss=0.5489525035318126\n",
      "GD iter. 300/499: loss=0.5488951842254048\n",
      "GD iter. 301/499: loss=0.5488641147889008\n",
      "GD iter. 302/499: loss=0.5487984588009933\n",
      "GD iter. 303/499: loss=0.5487763437124031\n",
      "GD iter. 304/499: loss=0.5487175927013644\n",
      "GD iter. 305/499: loss=0.5486795980922782\n",
      "GD iter. 306/499: loss=0.5486207857377022\n",
      "GD iter. 307/499: loss=0.5485789605119714\n",
      "GD iter. 308/499: loss=0.5485509550824129\n",
      "GD iter. 309/499: loss=0.5485281240861303\n",
      "GD iter. 310/499: loss=0.5484530492232584\n",
      "GD iter. 311/499: loss=0.5484259582946968\n",
      "GD iter. 312/499: loss=0.548390203837297\n",
      "GD iter. 313/499: loss=0.5483362466242931\n",
      "GD iter. 314/499: loss=0.5482948569055954\n",
      "GD iter. 315/499: loss=0.5482556895210936\n",
      "GD iter. 316/499: loss=0.5482298409698414\n",
      "GD iter. 317/499: loss=0.548176453491044\n",
      "GD iter. 318/499: loss=0.5481476445779367\n",
      "GD iter. 319/499: loss=0.548109980395166\n",
      "GD iter. 320/499: loss=0.5480776051210904\n",
      "GD iter. 321/499: loss=0.5480254025879128\n",
      "GD iter. 322/499: loss=0.5479731888443724\n",
      "GD iter. 323/499: loss=0.5479535088246695\n",
      "GD iter. 324/499: loss=0.5479058755850268\n",
      "GD iter. 325/499: loss=0.5478499716006847\n",
      "GD iter. 326/499: loss=0.5478286957063943\n",
      "GD iter. 327/499: loss=0.5477726753772701\n",
      "GD iter. 328/499: loss=0.5477334997712994\n",
      "GD iter. 329/499: loss=0.5476969981163876\n",
      "GD iter. 330/499: loss=0.5476747073984585\n",
      "GD iter. 331/499: loss=0.5476203558255046\n",
      "GD iter. 332/499: loss=0.5475866211948607\n",
      "GD iter. 333/499: loss=0.5475688037975841\n",
      "GD iter. 334/499: loss=0.5475135593380843\n",
      "GD iter. 335/499: loss=0.5474752677420274\n",
      "GD iter. 336/499: loss=0.5474596057444693\n",
      "GD iter. 337/499: loss=0.5474071281650539\n",
      "GD iter. 338/499: loss=0.5473558398764302\n",
      "GD iter. 339/499: loss=0.5473292782002994\n",
      "GD iter. 340/499: loss=0.5473054849135434\n",
      "GD iter. 341/499: loss=0.5472607338559652\n",
      "GD iter. 342/499: loss=0.5472326515858991\n",
      "GD iter. 343/499: loss=0.5471698551274315\n",
      "GD iter. 344/499: loss=0.5471355687664132\n",
      "GD iter. 345/499: loss=0.5470851714969203\n",
      "GD iter. 346/499: loss=0.5470719533042142\n",
      "GD iter. 347/499: loss=0.5470346114016686\n",
      "GD iter. 348/499: loss=0.5470096974365273\n",
      "GD iter. 349/499: loss=0.5469896980862803\n",
      "GD iter. 350/499: loss=0.5469235801666272\n",
      "GD iter. 351/499: loss=0.5468867758568958\n",
      "GD iter. 352/499: loss=0.5468481593475746\n",
      "GD iter. 353/499: loss=0.5468585488707712\n",
      "GD iter. 354/499: loss=0.5468152552191564\n",
      "GD iter. 355/499: loss=0.546779879901363\n",
      "GD iter. 356/499: loss=0.5467377063280793\n",
      "GD iter. 357/499: loss=0.5466930584781089\n",
      "GD iter. 358/499: loss=0.5466581475897966\n",
      "GD iter. 359/499: loss=0.546627237071081\n",
      "GD iter. 360/499: loss=0.5466128715255888\n",
      "GD iter. 361/499: loss=0.5465678707069674\n",
      "GD iter. 362/499: loss=0.5465335943505765\n",
      "GD iter. 363/499: loss=0.5465070270599591\n",
      "GD iter. 364/499: loss=0.5464884870184189\n",
      "GD iter. 365/499: loss=0.5464721224890571\n",
      "GD iter. 366/499: loss=0.5464252416534036\n",
      "GD iter. 367/499: loss=0.5464122007076385\n",
      "GD iter. 368/499: loss=0.5463996390760546\n",
      "GD iter. 369/499: loss=0.5463316317149071\n",
      "GD iter. 370/499: loss=0.546296384857855\n",
      "GD iter. 371/499: loss=0.5462631328022233\n",
      "GD iter. 372/499: loss=0.5462510674840503\n",
      "GD iter. 373/499: loss=0.5462131153834365\n",
      "GD iter. 374/499: loss=0.5461930092033146\n",
      "GD iter. 375/499: loss=0.546169031209881\n",
      "GD iter. 376/499: loss=0.5461295256812105\n",
      "GD iter. 377/499: loss=0.5461122974281856\n",
      "GD iter. 378/499: loss=0.546063467823412\n",
      "GD iter. 379/499: loss=0.5460601130621872\n",
      "GD iter. 380/499: loss=0.5460027137277229\n",
      "GD iter. 381/499: loss=0.5459865723056391\n",
      "GD iter. 382/499: loss=0.54597577398571\n",
      "GD iter. 383/499: loss=0.545955988889506\n",
      "GD iter. 384/499: loss=0.545898197904137\n",
      "GD iter. 385/499: loss=0.5458726110767398\n",
      "GD iter. 386/499: loss=0.5458647858228519\n",
      "GD iter. 387/499: loss=0.5458122942708852\n",
      "GD iter. 388/499: loss=0.5458120801142213\n",
      "GD iter. 389/499: loss=0.545821773989175\n",
      "GD iter. 390/499: loss=0.5457379301463341\n",
      "GD iter. 391/499: loss=0.5457304360570392\n",
      "GD iter. 392/499: loss=0.5456833257668948\n",
      "GD iter. 393/499: loss=0.545648714393392\n",
      "GD iter. 394/499: loss=0.5456390771760075\n",
      "GD iter. 395/499: loss=0.5456024437467462\n",
      "GD iter. 396/499: loss=0.5455598027349844\n",
      "GD iter. 397/499: loss=0.5455675744049887\n",
      "GD iter. 398/499: loss=0.5455572072627431\n",
      "GD iter. 399/499: loss=0.5454872491003705\n",
      "GD iter. 400/499: loss=0.545463523011991\n",
      "GD iter. 401/499: loss=0.5454721350631146\n",
      "GD iter. 402/499: loss=0.5454520272989142\n",
      "GD iter. 403/499: loss=0.5454057284696079\n",
      "GD iter. 404/499: loss=0.5453686230437719\n",
      "GD iter. 405/499: loss=0.5453372998150283\n",
      "GD iter. 406/499: loss=0.545307107340803\n",
      "GD iter. 407/499: loss=0.5453113812222107\n",
      "GD iter. 408/499: loss=0.5452729227935746\n",
      "GD iter. 409/499: loss=0.5452546384094691\n",
      "GD iter. 410/499: loss=0.5452143664201256\n",
      "GD iter. 411/499: loss=0.5451837662221822\n",
      "GD iter. 412/499: loss=0.5451539229085891\n",
      "GD iter. 413/499: loss=0.5451709839453658\n",
      "GD iter. 414/499: loss=0.5451014239875454\n",
      "GD iter. 415/499: loss=0.5450831425095458\n",
      "GD iter. 416/499: loss=0.5450768609424018\n",
      "GD iter. 417/499: loss=0.545044043386152\n",
      "GD iter. 418/499: loss=0.545014311634482\n",
      "GD iter. 419/499: loss=0.5449807900342285\n",
      "GD iter. 420/499: loss=0.5449519185161372\n",
      "GD iter. 421/499: loss=0.5449449971119785\n",
      "GD iter. 422/499: loss=0.5449481842823121\n",
      "GD iter. 423/499: loss=0.5449126258088022\n",
      "GD iter. 424/499: loss=0.544878610187574\n",
      "GD iter. 425/499: loss=0.5448395483223171\n",
      "GD iter. 426/499: loss=0.5448136190468198\n",
      "GD iter. 427/499: loss=0.5447774219536319\n",
      "GD iter. 428/499: loss=0.5447927981221358\n",
      "GD iter. 429/499: loss=0.5448019425675052\n",
      "GD iter. 430/499: loss=0.5447244595199808\n",
      "GD iter. 431/499: loss=0.5446985087782648\n",
      "GD iter. 432/499: loss=0.5446978052113052\n",
      "GD iter. 433/499: loss=0.5446707982117778\n",
      "GD iter. 434/499: loss=0.5446427212457173\n",
      "GD iter. 435/499: loss=0.5446145834066426\n",
      "GD iter. 436/499: loss=0.5446057422800684\n",
      "GD iter. 437/499: loss=0.5445835729949184\n",
      "GD iter. 438/499: loss=0.5445406210145247\n",
      "GD iter. 439/499: loss=0.5445116362438398\n",
      "GD iter. 440/499: loss=0.5444861046659274\n",
      "GD iter. 441/499: loss=0.544466628822784\n",
      "GD iter. 442/499: loss=0.5444694999349061\n",
      "GD iter. 443/499: loss=0.544422112322203\n",
      "GD iter. 444/499: loss=0.5443999817804168\n",
      "GD iter. 445/499: loss=0.5443940330943928\n",
      "GD iter. 446/499: loss=0.5443575134302844\n",
      "GD iter. 447/499: loss=0.5443277159804241\n",
      "GD iter. 448/499: loss=0.5443020473682312\n",
      "GD iter. 449/499: loss=0.5442972386873632\n",
      "GD iter. 450/499: loss=0.5442981278036115\n",
      "GD iter. 451/499: loss=0.5442463389855389\n",
      "GD iter. 452/499: loss=0.5442138438119025\n",
      "GD iter. 453/499: loss=0.5442187941174705\n",
      "GD iter. 454/499: loss=0.5441683284246794\n",
      "GD iter. 455/499: loss=0.5441679109468213\n",
      "GD iter. 456/499: loss=0.5441466705608528\n",
      "GD iter. 457/499: loss=0.5441299743727255\n",
      "GD iter. 458/499: loss=0.5441176487380069\n",
      "GD iter. 459/499: loss=0.5441083747164526\n",
      "GD iter. 460/499: loss=0.5440501055673694\n",
      "GD iter. 461/499: loss=0.5440268963795972\n",
      "GD iter. 462/499: loss=0.5440128428712155\n",
      "GD iter. 463/499: loss=0.5440046857721369\n",
      "GD iter. 464/499: loss=0.5439665408950721\n",
      "GD iter. 465/499: loss=0.5439463170932388\n",
      "GD iter. 466/499: loss=0.5439175010145931\n",
      "GD iter. 467/499: loss=0.5439154343175275\n",
      "GD iter. 468/499: loss=0.5438868630941448\n",
      "GD iter. 469/499: loss=0.5438762546261424\n",
      "GD iter. 470/499: loss=0.5438417809896204\n",
      "GD iter. 471/499: loss=0.5438452993617677\n",
      "GD iter. 472/499: loss=0.5438012989610845\n",
      "GD iter. 473/499: loss=0.5437767174226669\n",
      "GD iter. 474/499: loss=0.5437381788572635\n",
      "GD iter. 475/499: loss=0.5437542101624475\n",
      "GD iter. 476/499: loss=0.5437304876251375\n",
      "GD iter. 477/499: loss=0.5437048790528455\n",
      "GD iter. 478/499: loss=0.5436775308697903\n",
      "GD iter. 479/499: loss=0.5436666602452638\n",
      "GD iter. 480/499: loss=0.5436313225812502\n",
      "GD iter. 481/499: loss=0.5436176859739361\n",
      "GD iter. 482/499: loss=0.543611473735676\n",
      "GD iter. 483/499: loss=0.5435953020502052\n",
      "GD iter. 484/499: loss=0.5435567877174482\n",
      "GD iter. 485/499: loss=0.5435453456767823\n",
      "GD iter. 486/499: loss=0.5435470246295203\n",
      "GD iter. 487/499: loss=0.5435173894129812\n",
      "GD iter. 488/499: loss=0.5434825227213677\n",
      "GD iter. 489/499: loss=0.5435029234524285\n",
      "GD iter. 490/499: loss=0.5434603614898215\n",
      "GD iter. 491/499: loss=0.5434291505550009\n",
      "GD iter. 492/499: loss=0.543454110268879\n",
      "GD iter. 493/499: loss=0.5433844249380463\n",
      "GD iter. 494/499: loss=0.5434055615179613\n",
      "GD iter. 495/499: loss=0.5433641828772595\n",
      "GD iter. 496/499: loss=0.5433528848165925\n",
      "GD iter. 497/499: loss=0.5433443829841192\n",
      "GD iter. 498/499: loss=0.5433515262041483\n",
      "GD iter. 499/499: loss=0.5432952866015283\n",
      "The Accuracy is: 0.6902\n",
      "The F1 score is: 0.2703\n",
      "The precision is: 0.1613\n",
      "The recall is: 0.8333\n",
      "GD iter. 0/499: loss=1.0008279464859295\n",
      "GD iter. 1/499: loss=0.9311857372672219\n",
      "GD iter. 2/499: loss=0.8617522897070671\n",
      "GD iter. 3/499: loss=0.7957043936484348\n",
      "GD iter. 4/499: loss=0.7488010492705798\n",
      "GD iter. 5/499: loss=0.7202230637994145\n",
      "GD iter. 6/499: loss=0.7020249998762622\n",
      "GD iter. 7/499: loss=0.6892879631456769\n",
      "GD iter. 8/499: loss=0.6798449601363188\n",
      "GD iter. 9/499: loss=0.6720268681191401\n",
      "GD iter. 10/499: loss=0.6655869670292994\n",
      "GD iter. 11/499: loss=0.6600043867926366\n",
      "GD iter. 12/499: loss=0.6550707074371396\n",
      "GD iter. 13/499: loss=0.6506467856662503\n",
      "GD iter. 14/499: loss=0.6466966446624367\n",
      "GD iter. 15/499: loss=0.6433716886224703\n",
      "GD iter. 16/499: loss=0.640330311090651\n",
      "GD iter. 17/499: loss=0.6375119330917202\n",
      "GD iter. 18/499: loss=0.6349728026478959\n",
      "GD iter. 19/499: loss=0.63279914081664\n",
      "GD iter. 20/499: loss=0.630828516736796\n",
      "GD iter. 21/499: loss=0.628963497437035\n",
      "GD iter. 22/499: loss=0.627176878649932\n",
      "GD iter. 23/499: loss=0.6254618925075947\n",
      "GD iter. 24/499: loss=0.62377968801787\n",
      "GD iter. 25/499: loss=0.6221904717743302\n",
      "GD iter. 26/499: loss=0.6206833471420728\n",
      "GD iter. 27/499: loss=0.6192351474897537\n",
      "GD iter. 28/499: loss=0.6179288617128789\n",
      "GD iter. 29/499: loss=0.616715126115544\n",
      "GD iter. 30/499: loss=0.6155841686707557\n",
      "GD iter. 31/499: loss=0.614490156143207\n",
      "GD iter. 32/499: loss=0.6134204248236118\n",
      "GD iter. 33/499: loss=0.6123965864509001\n",
      "GD iter. 34/499: loss=0.6114573257535438\n",
      "GD iter. 35/499: loss=0.6105659686232151\n",
      "GD iter. 36/499: loss=0.60971042335211\n",
      "GD iter. 37/499: loss=0.6088602403979737\n",
      "GD iter. 38/499: loss=0.6080463440416666\n",
      "GD iter. 39/499: loss=0.607280009517663\n",
      "GD iter. 40/499: loss=0.6065377570096147\n",
      "GD iter. 41/499: loss=0.6058183083767854\n",
      "GD iter. 42/499: loss=0.6051121856033073\n",
      "GD iter. 43/499: loss=0.6044435305615338\n",
      "GD iter. 44/499: loss=0.603809587719339\n",
      "GD iter. 45/499: loss=0.6031886395704623\n",
      "GD iter. 46/499: loss=0.602580474922446\n",
      "GD iter. 47/499: loss=0.6019950139709225\n",
      "GD iter. 48/499: loss=0.6014198047275409\n",
      "GD iter. 49/499: loss=0.6008441584746615\n",
      "GD iter. 50/499: loss=0.6002728551401924\n",
      "GD iter. 51/499: loss=0.5997002400077374\n",
      "GD iter. 52/499: loss=0.5991534333982853\n",
      "GD iter. 53/499: loss=0.5986311067814755\n",
      "GD iter. 54/499: loss=0.5981105448585908\n",
      "GD iter. 55/499: loss=0.5975966822051931\n",
      "GD iter. 56/499: loss=0.5971072581681902\n",
      "GD iter. 57/499: loss=0.5966229982010425\n",
      "GD iter. 58/499: loss=0.596144437734525\n",
      "GD iter. 59/499: loss=0.5956824291932864\n",
      "GD iter. 60/499: loss=0.5952254500129144\n",
      "GD iter. 61/499: loss=0.5947851216336292\n",
      "GD iter. 62/499: loss=0.5943456949407061\n",
      "GD iter. 63/499: loss=0.5939168630697929\n",
      "GD iter. 64/499: loss=0.593487619366253\n",
      "GD iter. 65/499: loss=0.5930751719412286\n",
      "GD iter. 66/499: loss=0.5926617702463582\n",
      "GD iter. 67/499: loss=0.5922577982574713\n",
      "GD iter. 68/499: loss=0.5918684055174027\n",
      "GD iter. 69/499: loss=0.5914811945479053\n",
      "GD iter. 70/499: loss=0.5911003057159787\n",
      "GD iter. 71/499: loss=0.5907219695288197\n",
      "GD iter. 72/499: loss=0.590361327491218\n",
      "GD iter. 73/499: loss=0.5899876574560321\n",
      "GD iter. 74/499: loss=0.5896267560749989\n",
      "GD iter. 75/499: loss=0.5892960570393908\n",
      "GD iter. 76/499: loss=0.588955157632101\n",
      "GD iter. 77/499: loss=0.588618153928036\n",
      "GD iter. 78/499: loss=0.5883107694427774\n",
      "GD iter. 79/499: loss=0.5879861754709135\n",
      "GD iter. 80/499: loss=0.5876718611110667\n",
      "GD iter. 81/499: loss=0.5873577112233872\n",
      "GD iter. 82/499: loss=0.5870388899022307\n",
      "GD iter. 83/499: loss=0.5867332774443245\n",
      "GD iter. 84/499: loss=0.5864170416367369\n",
      "GD iter. 85/499: loss=0.5861059707064328\n",
      "GD iter. 86/499: loss=0.5857988147959798\n",
      "GD iter. 87/499: loss=0.5855001317678902\n",
      "GD iter. 88/499: loss=0.585188538577936\n",
      "GD iter. 89/499: loss=0.584898976204039\n",
      "GD iter. 90/499: loss=0.5846024584445931\n",
      "GD iter. 91/499: loss=0.5843105426903122\n",
      "GD iter. 92/499: loss=0.5840594994478836\n",
      "GD iter. 93/499: loss=0.583778613313731\n",
      "GD iter. 94/499: loss=0.5835143967863362\n",
      "GD iter. 95/499: loss=0.5832505292796922\n",
      "GD iter. 96/499: loss=0.5829888991106605\n",
      "GD iter. 97/499: loss=0.5827317273195962\n",
      "GD iter. 98/499: loss=0.5824775236004048\n",
      "GD iter. 99/499: loss=0.5822364417788086\n",
      "GD iter. 100/499: loss=0.5819784646634778\n",
      "GD iter. 101/499: loss=0.5817468880222411\n",
      "GD iter. 102/499: loss=0.5814997810160348\n",
      "GD iter. 103/499: loss=0.5812594076045511\n",
      "GD iter. 104/499: loss=0.5810152812584255\n",
      "GD iter. 105/499: loss=0.5807790433019687\n",
      "GD iter. 106/499: loss=0.5805583902020484\n",
      "GD iter. 107/499: loss=0.5803124394210627\n",
      "GD iter. 108/499: loss=0.5800867122871988\n",
      "GD iter. 109/499: loss=0.5798732999132984\n",
      "GD iter. 110/499: loss=0.579639148621514\n",
      "GD iter. 111/499: loss=0.5794386694736435\n",
      "GD iter. 112/499: loss=0.5791903889442569\n",
      "GD iter. 113/499: loss=0.578996840817831\n",
      "GD iter. 114/499: loss=0.5787749888463677\n",
      "GD iter. 115/499: loss=0.5785744089766937\n",
      "GD iter. 116/499: loss=0.5783810951273315\n",
      "GD iter. 117/499: loss=0.578180622643306\n",
      "GD iter. 118/499: loss=0.5779800040473964\n",
      "GD iter. 119/499: loss=0.5777940050494983\n",
      "GD iter. 120/499: loss=0.577590032813425\n",
      "GD iter. 121/499: loss=0.5773999068910074\n",
      "GD iter. 122/499: loss=0.5772120412717149\n",
      "GD iter. 123/499: loss=0.5770111715087225\n",
      "GD iter. 124/499: loss=0.5768418051456228\n",
      "GD iter. 125/499: loss=0.5766378977547585\n",
      "GD iter. 126/499: loss=0.57645551788035\n",
      "GD iter. 127/499: loss=0.5762643960089155\n",
      "GD iter. 128/499: loss=0.5760804030572264\n",
      "GD iter. 129/499: loss=0.5758884011808745\n",
      "GD iter. 130/499: loss=0.5757289191523339\n",
      "GD iter. 131/499: loss=0.5755267800498725\n",
      "GD iter. 132/499: loss=0.5753429010137241\n",
      "GD iter. 133/499: loss=0.5751650159888644\n",
      "GD iter. 134/499: loss=0.5749710200751124\n",
      "GD iter. 135/499: loss=0.5748066845238968\n",
      "GD iter. 136/499: loss=0.5746234260908782\n",
      "GD iter. 137/499: loss=0.5744393543998774\n",
      "GD iter. 138/499: loss=0.5743055575506462\n",
      "GD iter. 139/499: loss=0.5740997938608949\n",
      "GD iter. 140/499: loss=0.5739285420087454\n",
      "GD iter. 141/499: loss=0.5737664886386773\n",
      "GD iter. 142/499: loss=0.5735914694789769\n",
      "GD iter. 143/499: loss=0.5734275835568762\n",
      "GD iter. 144/499: loss=0.5732448756525854\n",
      "GD iter. 145/499: loss=0.5730812020471593\n",
      "GD iter. 146/499: loss=0.5729093034966264\n",
      "GD iter. 147/499: loss=0.5727431616528621\n",
      "GD iter. 148/499: loss=0.5726082024045535\n",
      "GD iter. 149/499: loss=0.5724114309429207\n",
      "GD iter. 150/499: loss=0.5722686706539117\n",
      "GD iter. 151/499: loss=0.5721026731985035\n",
      "GD iter. 152/499: loss=0.5719345886527359\n",
      "GD iter. 153/499: loss=0.5717865303737681\n",
      "GD iter. 154/499: loss=0.5716152460249119\n",
      "GD iter. 155/499: loss=0.5714811209346868\n",
      "GD iter. 156/499: loss=0.571320618925139\n",
      "GD iter. 157/499: loss=0.5711530337656997\n",
      "GD iter. 158/499: loss=0.571017840944657\n",
      "GD iter. 159/499: loss=0.5708673845555304\n",
      "GD iter. 160/499: loss=0.5707163880565342\n",
      "GD iter. 161/499: loss=0.5705757306924137\n",
      "GD iter. 162/499: loss=0.5704530810454742\n",
      "GD iter. 163/499: loss=0.5702899310527156\n",
      "GD iter. 164/499: loss=0.5701761001972809\n",
      "GD iter. 165/499: loss=0.5700396525553655\n",
      "GD iter. 166/499: loss=0.5698855840453966\n",
      "GD iter. 167/499: loss=0.5697576354435242\n",
      "GD iter. 168/499: loss=0.569661527012242\n",
      "GD iter. 169/499: loss=0.5695038382483786\n",
      "GD iter. 170/499: loss=0.5693823305528275\n",
      "GD iter. 171/499: loss=0.5692755828254613\n",
      "GD iter. 172/499: loss=0.5691365070880361\n",
      "GD iter. 173/499: loss=0.5690459822598689\n",
      "GD iter. 174/499: loss=0.5689140352873622\n",
      "GD iter. 175/499: loss=0.5688231497374867\n",
      "GD iter. 176/499: loss=0.5687032564354827\n",
      "GD iter. 177/499: loss=0.5685835645526516\n",
      "GD iter. 178/499: loss=0.5684697187844894\n",
      "GD iter. 179/499: loss=0.5683785553405372\n",
      "GD iter. 180/499: loss=0.5682520723494281\n",
      "GD iter. 181/499: loss=0.5681660448767761\n",
      "GD iter. 182/499: loss=0.5680461283916937\n",
      "GD iter. 183/499: loss=0.5679309969216412\n",
      "GD iter. 184/499: loss=0.5678468447594915\n",
      "GD iter. 185/499: loss=0.5677646357796131\n",
      "GD iter. 186/499: loss=0.5676425848625946\n",
      "GD iter. 187/499: loss=0.5675406817159555\n",
      "GD iter. 188/499: loss=0.567471276293161\n",
      "GD iter. 189/499: loss=0.5673912071266972\n",
      "GD iter. 190/499: loss=0.5672773146321343\n",
      "GD iter. 191/499: loss=0.5671786937428426\n",
      "GD iter. 192/499: loss=0.5671205785805571\n",
      "GD iter. 193/499: loss=0.5670103093010732\n",
      "GD iter. 194/499: loss=0.566917002969694\n",
      "GD iter. 195/499: loss=0.5668347519401165\n",
      "GD iter. 196/499: loss=0.5667620914219001\n",
      "GD iter. 197/499: loss=0.5666900932879707\n",
      "GD iter. 198/499: loss=0.5665846918470628\n",
      "GD iter. 199/499: loss=0.5664729910560294\n",
      "GD iter. 200/499: loss=0.5663947871763824\n",
      "GD iter. 201/499: loss=0.5663135424603829\n",
      "GD iter. 202/499: loss=0.5662305538877972\n",
      "GD iter. 203/499: loss=0.5661494173076916\n",
      "GD iter. 204/499: loss=0.5660655244058378\n",
      "GD iter. 205/499: loss=0.5659900522960896\n",
      "GD iter. 206/499: loss=0.56589388806998\n",
      "GD iter. 207/499: loss=0.5658026457064992\n",
      "GD iter. 208/499: loss=0.5657170349491693\n",
      "GD iter. 209/499: loss=0.5656675308565119\n",
      "GD iter. 210/499: loss=0.5655812311192633\n",
      "GD iter. 211/499: loss=0.5655189913089048\n",
      "GD iter. 212/499: loss=0.5654335979056667\n",
      "GD iter. 213/499: loss=0.5653473340678036\n",
      "GD iter. 214/499: loss=0.5652672039713349\n",
      "GD iter. 215/499: loss=0.5651945983555224\n",
      "GD iter. 216/499: loss=0.5651080081866559\n",
      "GD iter. 217/499: loss=0.5650375734809714\n",
      "GD iter. 218/499: loss=0.5649716520461953\n",
      "GD iter. 219/499: loss=0.5648868662002137\n",
      "GD iter. 220/499: loss=0.5648159771362208\n",
      "GD iter. 221/499: loss=0.5647764674213879\n",
      "GD iter. 222/499: loss=0.5647318397278596\n",
      "GD iter. 223/499: loss=0.5645996264142894\n",
      "GD iter. 224/499: loss=0.5645202733825444\n",
      "GD iter. 225/499: loss=0.5644543876676231\n",
      "GD iter. 226/499: loss=0.5643860742012553\n",
      "GD iter. 227/499: loss=0.5642998414405108\n",
      "GD iter. 228/499: loss=0.5642165721865574\n",
      "GD iter. 229/499: loss=0.5641897193518195\n",
      "GD iter. 230/499: loss=0.5640795196671062\n",
      "GD iter. 231/499: loss=0.5640051279862596\n",
      "GD iter. 232/499: loss=0.5639302829810136\n",
      "GD iter. 233/499: loss=0.5638931931688109\n",
      "GD iter. 234/499: loss=0.5638199264010424\n",
      "GD iter. 235/499: loss=0.5637418644647009\n",
      "GD iter. 236/499: loss=0.5636573366669129\n",
      "GD iter. 237/499: loss=0.5635782993646047\n",
      "GD iter. 238/499: loss=0.563530211343517\n",
      "GD iter. 239/499: loss=0.5634588743516301\n",
      "GD iter. 240/499: loss=0.5634175833972552\n",
      "GD iter. 241/499: loss=0.5633061286211656\n",
      "GD iter. 242/499: loss=0.5632379392373266\n",
      "GD iter. 243/499: loss=0.5631802288677161\n",
      "GD iter. 244/499: loss=0.563098098681722\n",
      "GD iter. 245/499: loss=0.5630300036807603\n",
      "GD iter. 246/499: loss=0.5629608479606951\n",
      "GD iter. 247/499: loss=0.5629096677256252\n",
      "GD iter. 248/499: loss=0.5628337181791637\n",
      "GD iter. 249/499: loss=0.562765489054501\n",
      "GD iter. 250/499: loss=0.5627195245994188\n",
      "GD iter. 251/499: loss=0.5626653003084657\n",
      "GD iter. 252/499: loss=0.5625621726095786\n",
      "GD iter. 253/499: loss=0.5625272707966916\n",
      "GD iter. 254/499: loss=0.5624435800652126\n",
      "GD iter. 255/499: loss=0.5623813080315065\n",
      "GD iter. 256/499: loss=0.5623171548207023\n",
      "GD iter. 257/499: loss=0.562242122236472\n",
      "GD iter. 258/499: loss=0.5621773132635355\n",
      "GD iter. 259/499: loss=0.5621329408026033\n",
      "GD iter. 260/499: loss=0.5620762261170295\n",
      "GD iter. 261/499: loss=0.5619995963767387\n",
      "GD iter. 262/499: loss=0.561971393638799\n",
      "GD iter. 263/499: loss=0.5619032281200894\n",
      "GD iter. 264/499: loss=0.5618260902655832\n",
      "GD iter. 265/499: loss=0.5617908261193669\n",
      "GD iter. 266/499: loss=0.5617365700243241\n",
      "GD iter. 267/499: loss=0.5616833623710679\n",
      "GD iter. 268/499: loss=0.5615721477307217\n",
      "GD iter. 269/499: loss=0.5615235372904274\n",
      "GD iter. 270/499: loss=0.561496526357654\n",
      "GD iter. 271/499: loss=0.5614126431409947\n",
      "GD iter. 272/499: loss=0.5613559288559012\n",
      "GD iter. 273/499: loss=0.5612955112900256\n",
      "GD iter. 274/499: loss=0.561262184313253\n",
      "GD iter. 275/499: loss=0.5612058933574211\n",
      "GD iter. 276/499: loss=0.5611204366064237\n",
      "GD iter. 277/499: loss=0.5610805850226189\n",
      "GD iter. 278/499: loss=0.5610325269641623\n",
      "GD iter. 279/499: loss=0.5609640677200983\n",
      "GD iter. 280/499: loss=0.5609342273050065\n",
      "GD iter. 281/499: loss=0.5608464852925106\n",
      "GD iter. 282/499: loss=0.5608043981056173\n",
      "GD iter. 283/499: loss=0.5607743024587859\n",
      "GD iter. 284/499: loss=0.5606998639197442\n",
      "GD iter. 285/499: loss=0.5606361726961613\n",
      "GD iter. 286/499: loss=0.5605587308598585\n",
      "GD iter. 287/499: loss=0.5605240676373547\n",
      "GD iter. 288/499: loss=0.5604735927569797\n",
      "GD iter. 289/499: loss=0.5604025505763773\n",
      "GD iter. 290/499: loss=0.5603726100098204\n",
      "GD iter. 291/499: loss=0.5602905531734221\n",
      "GD iter. 292/499: loss=0.5602583609421051\n",
      "GD iter. 293/499: loss=0.5602221240493818\n",
      "GD iter. 294/499: loss=0.5601440827262626\n",
      "GD iter. 295/499: loss=0.5600863366980484\n",
      "GD iter. 296/499: loss=0.560030993665447\n",
      "GD iter. 297/499: loss=0.5600060303037482\n",
      "GD iter. 298/499: loss=0.559947503195462\n",
      "GD iter. 299/499: loss=0.5598643045340218\n",
      "GD iter. 300/499: loss=0.5598220524600913\n",
      "GD iter. 301/499: loss=0.5597878054218202\n",
      "GD iter. 302/499: loss=0.5597251896007167\n",
      "GD iter. 303/499: loss=0.5596618041969263\n",
      "GD iter. 304/499: loss=0.5596041353633415\n",
      "GD iter. 305/499: loss=0.5595596820237705\n",
      "GD iter. 306/499: loss=0.5595683286041233\n",
      "GD iter. 307/499: loss=0.5594760147308688\n",
      "GD iter. 308/499: loss=0.5594009739167454\n",
      "GD iter. 309/499: loss=0.5593900849990405\n",
      "GD iter. 310/499: loss=0.5593217174987819\n",
      "GD iter. 311/499: loss=0.5592435472724776\n",
      "GD iter. 312/499: loss=0.5592143497582006\n",
      "GD iter. 313/499: loss=0.5591608925328088\n",
      "GD iter. 314/499: loss=0.5591091506349752\n",
      "GD iter. 315/499: loss=0.5590727727703512\n",
      "GD iter. 316/499: loss=0.5590400101296603\n",
      "GD iter. 317/499: loss=0.558976957734115\n",
      "GD iter. 318/499: loss=0.5589363109071341\n",
      "GD iter. 319/499: loss=0.5588916429314188\n",
      "GD iter. 320/499: loss=0.55887728278888\n",
      "GD iter. 321/499: loss=0.5588030351742959\n",
      "GD iter. 322/499: loss=0.5587360493945773\n",
      "GD iter. 323/499: loss=0.5586806268434037\n",
      "GD iter. 324/499: loss=0.5586409542333868\n",
      "GD iter. 325/499: loss=0.5586037940261724\n",
      "GD iter. 326/499: loss=0.558528371788799\n",
      "GD iter. 327/499: loss=0.5584937368797517\n",
      "GD iter. 328/499: loss=0.5584522553519449\n",
      "GD iter. 329/499: loss=0.558414280575219\n",
      "GD iter. 330/499: loss=0.5583794470212203\n",
      "GD iter. 331/499: loss=0.5583225267042264\n",
      "GD iter. 332/499: loss=0.5583248353805734\n",
      "GD iter. 333/499: loss=0.5582295822380458\n",
      "GD iter. 334/499: loss=0.5581830144886527\n",
      "GD iter. 335/499: loss=0.55812311424858\n",
      "GD iter. 336/499: loss=0.5581292582845124\n",
      "GD iter. 337/499: loss=0.5580571128729687\n",
      "GD iter. 338/499: loss=0.5580154755492573\n",
      "GD iter. 339/499: loss=0.5579505408882472\n",
      "GD iter. 340/499: loss=0.5579035991653393\n",
      "GD iter. 341/499: loss=0.5578910220092284\n",
      "GD iter. 342/499: loss=0.5578398138633929\n",
      "GD iter. 343/499: loss=0.5577904209118884\n",
      "GD iter. 344/499: loss=0.5577427167066118\n",
      "GD iter. 345/499: loss=0.5576779877615766\n",
      "GD iter. 346/499: loss=0.5576465267035527\n",
      "GD iter. 347/499: loss=0.5576070233367411\n",
      "GD iter. 348/499: loss=0.5575745131486063\n",
      "GD iter. 349/499: loss=0.5575284405352288\n",
      "GD iter. 350/499: loss=0.5574754029003048\n",
      "GD iter. 351/499: loss=0.5574556069915899\n",
      "GD iter. 352/499: loss=0.557383643736779\n",
      "GD iter. 353/499: loss=0.5573395172252229\n",
      "GD iter. 354/499: loss=0.5573295537496876\n",
      "GD iter. 355/499: loss=0.5572602590923147\n",
      "GD iter. 356/499: loss=0.557228247958621\n",
      "GD iter. 357/499: loss=0.557187925656606\n",
      "GD iter. 358/499: loss=0.5571562804708499\n",
      "GD iter. 359/499: loss=0.5571161233454045\n",
      "GD iter. 360/499: loss=0.5570732565798795\n",
      "GD iter. 361/499: loss=0.5570306159388776\n",
      "GD iter. 362/499: loss=0.5569764088199366\n",
      "GD iter. 363/499: loss=0.55693100328035\n",
      "GD iter. 364/499: loss=0.5569180578155608\n",
      "GD iter. 365/499: loss=0.5568868461431105\n",
      "GD iter. 366/499: loss=0.5567956223707965\n",
      "GD iter. 367/499: loss=0.5567995436672364\n",
      "GD iter. 368/499: loss=0.5567780436641224\n",
      "GD iter. 369/499: loss=0.5567046665790899\n",
      "GD iter. 370/499: loss=0.556635125505843\n",
      "GD iter. 371/499: loss=0.5566116736593114\n",
      "GD iter. 372/499: loss=0.5565869836476027\n",
      "GD iter. 373/499: loss=0.5565360606944082\n",
      "GD iter. 374/499: loss=0.5565374179119055\n",
      "GD iter. 375/499: loss=0.5564620471097341\n",
      "GD iter. 376/499: loss=0.5564118220925465\n",
      "GD iter. 377/499: loss=0.556382422261418\n",
      "GD iter. 378/499: loss=0.556409454420112\n",
      "GD iter. 379/499: loss=0.5563064423012166\n",
      "GD iter. 380/499: loss=0.5562611235681099\n",
      "GD iter. 381/499: loss=0.5562115967311821\n",
      "GD iter. 382/499: loss=0.5561738032171373\n",
      "GD iter. 383/499: loss=0.5561621533852625\n",
      "GD iter. 384/499: loss=0.5561010501402406\n",
      "GD iter. 385/499: loss=0.5560696906100665\n",
      "GD iter. 386/499: loss=0.556016968924747\n",
      "GD iter. 387/499: loss=0.5559952736639242\n",
      "GD iter. 388/499: loss=0.5559675609698126\n",
      "GD iter. 389/499: loss=0.5559325441620828\n",
      "GD iter. 390/499: loss=0.5558729291253278\n",
      "GD iter. 391/499: loss=0.5558308463229845\n",
      "GD iter. 392/499: loss=0.5558321301698906\n",
      "GD iter. 393/499: loss=0.5557690714130182\n",
      "GD iter. 394/499: loss=0.555732222725182\n",
      "GD iter. 395/499: loss=0.5557040020515684\n",
      "GD iter. 396/499: loss=0.5556752988808972\n",
      "GD iter. 397/499: loss=0.5556176248405372\n",
      "GD iter. 398/499: loss=0.5556040480298549\n",
      "GD iter. 399/499: loss=0.5555940464002561\n",
      "GD iter. 400/499: loss=0.5555167452401868\n",
      "GD iter. 401/499: loss=0.5554838843881242\n",
      "GD iter. 402/499: loss=0.5555049931588534\n",
      "GD iter. 403/499: loss=0.5554268325453229\n",
      "GD iter. 404/499: loss=0.5554164279640887\n",
      "GD iter. 405/499: loss=0.5553906898120671\n",
      "GD iter. 406/499: loss=0.5553360979199017\n",
      "GD iter. 407/499: loss=0.5552690862213993\n",
      "GD iter. 408/499: loss=0.5552486574261469\n",
      "GD iter. 409/499: loss=0.555235061311095\n",
      "GD iter. 410/499: loss=0.5551944400315271\n",
      "GD iter. 411/499: loss=0.5551410091108971\n",
      "GD iter. 412/499: loss=0.5551470706347413\n",
      "GD iter. 413/499: loss=0.5551316420324217\n",
      "GD iter. 414/499: loss=0.5550538203922809\n",
      "GD iter. 415/499: loss=0.5550159257327232\n",
      "GD iter. 416/499: loss=0.5549672448566044\n",
      "GD iter. 417/499: loss=0.5549469513179883\n",
      "GD iter. 418/499: loss=0.5549213796904772\n",
      "GD iter. 419/499: loss=0.5548949683441844\n",
      "GD iter. 420/499: loss=0.5548736259759788\n",
      "GD iter. 421/499: loss=0.5548350016482523\n",
      "GD iter. 422/499: loss=0.5547996991989073\n",
      "GD iter. 423/499: loss=0.5547714520573694\n",
      "GD iter. 424/499: loss=0.5547435136083947\n",
      "GD iter. 425/499: loss=0.554709138235118\n",
      "GD iter. 426/499: loss=0.5546750831454744\n",
      "GD iter. 427/499: loss=0.5546562155736199\n",
      "GD iter. 428/499: loss=0.5546431326127137\n",
      "GD iter. 429/499: loss=0.5546118420483122\n",
      "GD iter. 430/499: loss=0.554579680335911\n",
      "GD iter. 431/499: loss=0.5545791036776648\n",
      "GD iter. 432/499: loss=0.554509299819052\n",
      "GD iter. 433/499: loss=0.5544968281895324\n",
      "GD iter. 434/499: loss=0.5545155482243244\n",
      "GD iter. 435/499: loss=0.5544531034989383\n",
      "GD iter. 436/499: loss=0.5543916464014325\n",
      "GD iter. 437/499: loss=0.5543511645925093\n",
      "GD iter. 438/499: loss=0.5543836050342956\n",
      "GD iter. 439/499: loss=0.5543458064274347\n",
      "GD iter. 440/499: loss=0.5542836983334578\n",
      "GD iter. 441/499: loss=0.5542659323926766\n",
      "GD iter. 442/499: loss=0.5542634823246978\n",
      "GD iter. 443/499: loss=0.5542266706194775\n",
      "GD iter. 444/499: loss=0.5542048641057074\n",
      "GD iter. 445/499: loss=0.5541882349615813\n",
      "GD iter. 446/499: loss=0.5541134823015488\n",
      "GD iter. 447/499: loss=0.554106749245214\n",
      "GD iter. 448/499: loss=0.5541004163263604\n",
      "GD iter. 449/499: loss=0.5540637157946985\n",
      "GD iter. 450/499: loss=0.5540595967349967\n",
      "GD iter. 451/499: loss=0.5540045685758701\n",
      "GD iter. 452/499: loss=0.5539820958216516\n",
      "GD iter. 453/499: loss=0.5539790707678783\n",
      "GD iter. 454/499: loss=0.5539206937671902\n",
      "GD iter. 455/499: loss=0.5539104853956273\n",
      "GD iter. 456/499: loss=0.5538979926782663\n",
      "GD iter. 457/499: loss=0.5538809143284993\n",
      "GD iter. 458/499: loss=0.5538428225453327\n",
      "GD iter. 459/499: loss=0.553841152145382\n",
      "GD iter. 460/499: loss=0.5537732609329272\n",
      "GD iter. 461/499: loss=0.5537379143425192\n",
      "GD iter. 462/499: loss=0.5537238645924992\n",
      "GD iter. 463/499: loss=0.5537023921394097\n",
      "GD iter. 464/499: loss=0.5536610050584487\n",
      "GD iter. 465/499: loss=0.5536979752175825\n",
      "GD iter. 466/499: loss=0.5536358651670099\n",
      "GD iter. 467/499: loss=0.5536169697116012\n",
      "GD iter. 468/499: loss=0.5536009160927304\n",
      "GD iter. 469/499: loss=0.5535723325300903\n",
      "GD iter. 470/499: loss=0.5535197704761279\n",
      "GD iter. 471/499: loss=0.5534955860657732\n",
      "GD iter. 472/499: loss=0.5535162963217168\n",
      "GD iter. 473/499: loss=0.5534568121483471\n",
      "GD iter. 474/499: loss=0.553453571004032\n",
      "GD iter. 475/499: loss=0.5534362958756606\n",
      "GD iter. 476/499: loss=0.5533982020867982\n",
      "GD iter. 477/499: loss=0.5533747215129962\n",
      "GD iter. 478/499: loss=0.5534084874655784\n",
      "GD iter. 479/499: loss=0.5533927429777752\n",
      "GD iter. 480/499: loss=0.5533372845663989\n",
      "GD iter. 481/499: loss=0.5532879913650587\n",
      "GD iter. 482/499: loss=0.5532851540417654\n",
      "GD iter. 483/499: loss=0.5532556846344525\n",
      "GD iter. 484/499: loss=0.5532771188421707\n",
      "GD iter. 485/499: loss=0.5532489466338217\n",
      "GD iter. 486/499: loss=0.5532263561994859\n",
      "GD iter. 487/499: loss=0.5532043212659301\n",
      "GD iter. 488/499: loss=0.5531646572136023\n",
      "GD iter. 489/499: loss=0.5531394418803601\n",
      "GD iter. 490/499: loss=0.5531283715534101\n",
      "GD iter. 491/499: loss=0.5531370990150538\n",
      "GD iter. 492/499: loss=0.5531162853491558\n",
      "GD iter. 493/499: loss=0.5531116625283077\n",
      "GD iter. 494/499: loss=0.553047136088194\n",
      "GD iter. 495/499: loss=0.5530376591395064\n",
      "GD iter. 496/499: loss=0.5530196900577024\n",
      "GD iter. 497/499: loss=0.5530111334278226\n",
      "GD iter. 498/499: loss=0.5529823012394092\n",
      "GD iter. 499/499: loss=0.5529498657453054\n",
      "The Accuracy is: 0.7082\n",
      "The F1 score is: 0.3688\n",
      "The precision is: 0.2291\n",
      "The recall is: 0.9455\n",
      "GD iter. 0/499: loss=1.0250022197902449\n",
      "GD iter. 1/499: loss=0.950828332710389\n",
      "GD iter. 2/499: loss=0.8768768133062926\n",
      "GD iter. 3/499: loss=0.8047147755943955\n",
      "GD iter. 4/499: loss=0.7431774539296943\n",
      "GD iter. 5/499: loss=0.7039267154618282\n",
      "GD iter. 6/499: loss=0.6822488798896689\n",
      "GD iter. 7/499: loss=0.6690379313532899\n",
      "GD iter. 8/499: loss=0.6591424627221274\n",
      "GD iter. 9/499: loss=0.6512933773487146\n",
      "GD iter. 10/499: loss=0.6446841714434361\n",
      "GD iter. 11/499: loss=0.6389641784332398\n",
      "GD iter. 12/499: loss=0.6342825792170643\n",
      "GD iter. 13/499: loss=0.630485661442262\n",
      "GD iter. 14/499: loss=0.6271739471595225\n",
      "GD iter. 15/499: loss=0.6243090096253736\n",
      "GD iter. 16/499: loss=0.6216809037783041\n",
      "GD iter. 17/499: loss=0.6193348765119764\n",
      "GD iter. 18/499: loss=0.617239528882121\n",
      "GD iter. 19/499: loss=0.6153897703190702\n",
      "GD iter. 20/499: loss=0.6136236672482255\n",
      "GD iter. 21/499: loss=0.6119351100458265\n",
      "GD iter. 22/499: loss=0.6103725647004905\n",
      "GD iter. 23/499: loss=0.6088805960660789\n",
      "GD iter. 24/499: loss=0.6075305717218495\n",
      "GD iter. 25/499: loss=0.6062370538679647\n",
      "GD iter. 26/499: loss=0.605052280353481\n",
      "GD iter. 27/499: loss=0.6038915915227505\n",
      "GD iter. 28/499: loss=0.6027360767659022\n",
      "GD iter. 29/499: loss=0.6015902456284462\n",
      "GD iter. 30/499: loss=0.6004651303365988\n",
      "GD iter. 31/499: loss=0.5993592576609459\n",
      "GD iter. 32/499: loss=0.5983116053868364\n",
      "GD iter. 33/499: loss=0.5973213864482818\n",
      "GD iter. 34/499: loss=0.5963575221922052\n",
      "GD iter. 35/499: loss=0.5954023835055136\n",
      "GD iter. 36/499: loss=0.594510213867636\n",
      "GD iter. 37/499: loss=0.5936654914310361\n",
      "GD iter. 38/499: loss=0.5928677100864486\n",
      "GD iter. 39/499: loss=0.592144671991071\n",
      "GD iter. 40/499: loss=0.5914407293697734\n",
      "GD iter. 41/499: loss=0.5907478548843125\n",
      "GD iter. 42/499: loss=0.5900826671000345\n",
      "GD iter. 43/499: loss=0.5894208582502379\n",
      "GD iter. 44/499: loss=0.5887664428257529\n",
      "GD iter. 45/499: loss=0.5881494491783986\n",
      "GD iter. 46/499: loss=0.5875441914744534\n",
      "GD iter. 47/499: loss=0.586945129794639\n",
      "GD iter. 48/499: loss=0.5863536781359595\n",
      "GD iter. 49/499: loss=0.5857784542615747\n",
      "GD iter. 50/499: loss=0.5852038855672071\n",
      "GD iter. 51/499: loss=0.5846303914528579\n",
      "GD iter. 52/499: loss=0.5840591434914026\n",
      "GD iter. 53/499: loss=0.5835059776887288\n",
      "GD iter. 54/499: loss=0.5829533361290088\n",
      "GD iter. 55/499: loss=0.5824259976575037\n",
      "GD iter. 56/499: loss=0.5819359934384132\n",
      "GD iter. 57/499: loss=0.5814609673625877\n",
      "GD iter. 58/499: loss=0.5810053551918192\n",
      "GD iter. 59/499: loss=0.5805588816394627\n",
      "GD iter. 60/499: loss=0.5801211460355115\n",
      "GD iter. 61/499: loss=0.5796900500952935\n",
      "GD iter. 62/499: loss=0.5792541398504715\n",
      "GD iter. 63/499: loss=0.5788299902543835\n",
      "GD iter. 64/499: loss=0.5784197887141153\n",
      "GD iter. 65/499: loss=0.5780137150955692\n",
      "GD iter. 66/499: loss=0.5776079021445742\n",
      "GD iter. 67/499: loss=0.5772047798115691\n",
      "GD iter. 68/499: loss=0.5768034352927405\n",
      "GD iter. 69/499: loss=0.5764128884954217\n",
      "GD iter. 70/499: loss=0.5760381424543096\n",
      "GD iter. 71/499: loss=0.5756725720962967\n",
      "GD iter. 72/499: loss=0.5753237725951431\n",
      "GD iter. 73/499: loss=0.5750000478953027\n",
      "GD iter. 74/499: loss=0.5746898899040109\n",
      "GD iter. 75/499: loss=0.5743914866652796\n",
      "GD iter. 76/499: loss=0.57409604344804\n",
      "GD iter. 77/499: loss=0.5738383139686815\n",
      "GD iter. 78/499: loss=0.573576206653642\n",
      "GD iter. 79/499: loss=0.5733168636959673\n",
      "GD iter. 80/499: loss=0.5730639536511717\n",
      "GD iter. 81/499: loss=0.5728052509166671\n",
      "GD iter. 82/499: loss=0.572563294004213\n",
      "GD iter. 83/499: loss=0.5723162647988749\n",
      "GD iter. 84/499: loss=0.5720753538780008\n",
      "GD iter. 85/499: loss=0.5718268408208744\n",
      "GD iter. 86/499: loss=0.5715992298843107\n",
      "GD iter. 87/499: loss=0.5713740266809542\n",
      "GD iter. 88/499: loss=0.5711224711039552\n",
      "GD iter. 89/499: loss=0.5708982417044369\n",
      "GD iter. 90/499: loss=0.5706756080066483\n",
      "GD iter. 91/499: loss=0.5704535156051487\n",
      "GD iter. 92/499: loss=0.570234918130365\n",
      "GD iter. 93/499: loss=0.570012755755183\n",
      "GD iter. 94/499: loss=0.5698121561879215\n",
      "GD iter. 95/499: loss=0.5696114560437782\n",
      "GD iter. 96/499: loss=0.5694117324068078\n",
      "GD iter. 97/499: loss=0.5692249602878259\n",
      "GD iter. 98/499: loss=0.5690212425709436\n",
      "GD iter. 99/499: loss=0.5688335695064884\n",
      "GD iter. 100/499: loss=0.5686447839028791\n",
      "GD iter. 101/499: loss=0.568448313265328\n",
      "GD iter. 102/499: loss=0.5682704325453575\n",
      "GD iter. 103/499: loss=0.5680798918034075\n",
      "GD iter. 104/499: loss=0.5679069934004091\n",
      "GD iter. 105/499: loss=0.567728748547455\n",
      "GD iter. 106/499: loss=0.567542499737018\n",
      "GD iter. 107/499: loss=0.5673513329563667\n",
      "GD iter. 108/499: loss=0.5671771315663787\n",
      "GD iter. 109/499: loss=0.5670010954499461\n",
      "GD iter. 110/499: loss=0.566819328696512\n",
      "GD iter. 111/499: loss=0.5666423182758846\n",
      "GD iter. 112/499: loss=0.566465650406841\n",
      "GD iter. 113/499: loss=0.5662899845091748\n",
      "GD iter. 114/499: loss=0.5661328753948717\n",
      "GD iter. 115/499: loss=0.5659614738658039\n",
      "GD iter. 116/499: loss=0.5658048095436699\n",
      "GD iter. 117/499: loss=0.5656469871636819\n",
      "GD iter. 118/499: loss=0.565494928105274\n",
      "GD iter. 119/499: loss=0.5653437075199262\n",
      "GD iter. 120/499: loss=0.5651826445758945\n",
      "GD iter. 121/499: loss=0.5650114670828477\n",
      "GD iter. 122/499: loss=0.564859274382929\n",
      "GD iter. 123/499: loss=0.5647198718103129\n",
      "GD iter. 124/499: loss=0.5645584936899541\n",
      "GD iter. 125/499: loss=0.5643982809975867\n",
      "GD iter. 126/499: loss=0.5642448228111844\n",
      "GD iter. 127/499: loss=0.5640948743780466\n",
      "GD iter. 128/499: loss=0.5639482290204548\n",
      "GD iter. 129/499: loss=0.5637998064038887\n",
      "GD iter. 130/499: loss=0.5636546869135023\n",
      "GD iter. 131/499: loss=0.5635097110470935\n",
      "GD iter. 132/499: loss=0.5633560305908984\n",
      "GD iter. 133/499: loss=0.5632096858343294\n",
      "GD iter. 134/499: loss=0.5630707206096293\n",
      "GD iter. 135/499: loss=0.5629185862008147\n",
      "GD iter. 136/499: loss=0.562783419603037\n",
      "GD iter. 137/499: loss=0.5626379642354012\n",
      "GD iter. 138/499: loss=0.5624951368101387\n",
      "GD iter. 139/499: loss=0.5623528719280211\n",
      "GD iter. 140/499: loss=0.5622208891910452\n",
      "GD iter. 141/499: loss=0.5620806397789838\n",
      "GD iter. 142/499: loss=0.5619378516277609\n",
      "GD iter. 143/499: loss=0.5617895415761811\n",
      "GD iter. 144/499: loss=0.5616629314152005\n",
      "GD iter. 145/499: loss=0.5615414700515186\n",
      "GD iter. 146/499: loss=0.561404513863339\n",
      "GD iter. 147/499: loss=0.561260264720537\n",
      "GD iter. 148/499: loss=0.5611446465821459\n",
      "GD iter. 149/499: loss=0.5610045083220211\n",
      "GD iter. 150/499: loss=0.5608786487830324\n",
      "GD iter. 151/499: loss=0.5607434460749685\n",
      "GD iter. 152/499: loss=0.5606139057157028\n",
      "GD iter. 153/499: loss=0.5604877710468275\n",
      "GD iter. 154/499: loss=0.5603693323031683\n",
      "GD iter. 155/499: loss=0.5602425778958575\n",
      "GD iter. 156/499: loss=0.5601253434749257\n",
      "GD iter. 157/499: loss=0.5600000815804315\n",
      "GD iter. 158/499: loss=0.5598813187675934\n",
      "GD iter. 159/499: loss=0.5597555020555796\n",
      "GD iter. 160/499: loss=0.5596230470489993\n",
      "GD iter. 161/499: loss=0.5595167118421337\n",
      "GD iter. 162/499: loss=0.5594003225685554\n",
      "GD iter. 163/499: loss=0.5592824208863416\n",
      "GD iter. 164/499: loss=0.5591688739006871\n",
      "GD iter. 165/499: loss=0.5590666017469355\n",
      "GD iter. 166/499: loss=0.5589469534707913\n",
      "GD iter. 167/499: loss=0.558837470242667\n",
      "GD iter. 168/499: loss=0.5587528920200392\n",
      "GD iter. 169/499: loss=0.5586210850731442\n",
      "GD iter. 170/499: loss=0.558510026719406\n",
      "GD iter. 171/499: loss=0.5584140243169331\n",
      "GD iter. 172/499: loss=0.5583146739104293\n",
      "GD iter. 173/499: loss=0.5581963450998644\n",
      "GD iter. 174/499: loss=0.5580920476518257\n",
      "GD iter. 175/499: loss=0.5580048751004194\n",
      "GD iter. 176/499: loss=0.5578997438157154\n",
      "GD iter. 177/499: loss=0.5577848819865534\n",
      "GD iter. 178/499: loss=0.5576772434955432\n",
      "GD iter. 179/499: loss=0.5575786950817567\n",
      "GD iter. 180/499: loss=0.5574663919088131\n",
      "GD iter. 181/499: loss=0.5573853556271782\n",
      "GD iter. 182/499: loss=0.5572751440716752\n",
      "GD iter. 183/499: loss=0.5571801885500622\n",
      "GD iter. 184/499: loss=0.55708597762603\n",
      "GD iter. 185/499: loss=0.5569864798957798\n",
      "GD iter. 186/499: loss=0.5569005352634541\n",
      "GD iter. 187/499: loss=0.5568000681156596\n",
      "GD iter. 188/499: loss=0.5567109336784604\n",
      "GD iter. 189/499: loss=0.5566247148137017\n",
      "GD iter. 190/499: loss=0.5565396124515245\n",
      "GD iter. 191/499: loss=0.5564463718617695\n",
      "GD iter. 192/499: loss=0.5563624437610821\n",
      "GD iter. 193/499: loss=0.5562668568589075\n",
      "GD iter. 194/499: loss=0.5561873383872403\n",
      "GD iter. 195/499: loss=0.5560998108796951\n",
      "GD iter. 196/499: loss=0.5560430256179207\n",
      "GD iter. 197/499: loss=0.5559359628791212\n",
      "GD iter. 198/499: loss=0.5558517162088644\n",
      "GD iter. 199/499: loss=0.5557841011505605\n",
      "GD iter. 200/499: loss=0.5557027584446013\n",
      "GD iter. 201/499: loss=0.5556153289264094\n",
      "GD iter. 202/499: loss=0.5555324176341753\n",
      "GD iter. 203/499: loss=0.5554507738404834\n",
      "GD iter. 204/499: loss=0.555382011658402\n",
      "GD iter. 205/499: loss=0.5553054603299279\n",
      "GD iter. 206/499: loss=0.5552296392008076\n",
      "GD iter. 207/499: loss=0.555140824258599\n",
      "GD iter. 208/499: loss=0.555071298329467\n",
      "GD iter. 209/499: loss=0.5550277802565369\n",
      "GD iter. 210/499: loss=0.5549225871397896\n",
      "GD iter. 211/499: loss=0.5548571247201832\n",
      "GD iter. 212/499: loss=0.5547806895129678\n",
      "GD iter. 213/499: loss=0.55471862314129\n",
      "GD iter. 214/499: loss=0.5546490486067073\n",
      "GD iter. 215/499: loss=0.5545837455457322\n",
      "GD iter. 216/499: loss=0.5544860859116019\n",
      "GD iter. 217/499: loss=0.5544187780096768\n",
      "GD iter. 218/499: loss=0.5543510545704884\n",
      "GD iter. 219/499: loss=0.5542800091303053\n",
      "GD iter. 220/499: loss=0.554221919594552\n",
      "GD iter. 221/499: loss=0.5541399273153458\n",
      "GD iter. 222/499: loss=0.5540685406549549\n",
      "GD iter. 223/499: loss=0.55401361318061\n",
      "GD iter. 224/499: loss=0.5539208974752605\n",
      "GD iter. 225/499: loss=0.5538680833336926\n",
      "GD iter. 226/499: loss=0.5538236352182417\n",
      "GD iter. 227/499: loss=0.5537539061556773\n",
      "GD iter. 228/499: loss=0.553656944988548\n",
      "GD iter. 229/499: loss=0.5536020299447887\n",
      "GD iter. 230/499: loss=0.5535324114218828\n",
      "GD iter. 231/499: loss=0.5534917071914984\n",
      "GD iter. 232/499: loss=0.5534236774638529\n",
      "GD iter. 233/499: loss=0.5533497039741146\n",
      "GD iter. 234/499: loss=0.5533037193102042\n",
      "GD iter. 235/499: loss=0.5532331867723399\n",
      "GD iter. 236/499: loss=0.5531959265526838\n",
      "GD iter. 237/499: loss=0.5531217507410933\n",
      "GD iter. 238/499: loss=0.5530773331693928\n",
      "GD iter. 239/499: loss=0.5530369921284484\n",
      "GD iter. 240/499: loss=0.5529516666804533\n",
      "GD iter. 241/499: loss=0.5529005003689449\n",
      "GD iter. 242/499: loss=0.5528541389953179\n",
      "GD iter. 243/499: loss=0.552796740933554\n",
      "GD iter. 244/499: loss=0.5527647082299632\n",
      "GD iter. 245/499: loss=0.5527199517327707\n",
      "GD iter. 246/499: loss=0.5526559325317096\n",
      "GD iter. 247/499: loss=0.5525988585981513\n",
      "GD iter. 248/499: loss=0.5525669562812202\n",
      "GD iter. 249/499: loss=0.5525201530418253\n",
      "GD iter. 250/499: loss=0.5524630240829491\n",
      "GD iter. 251/499: loss=0.5524129878128284\n",
      "GD iter. 252/499: loss=0.5523675361666878\n",
      "GD iter. 253/499: loss=0.5523331841480638\n",
      "GD iter. 254/499: loss=0.5522861815785463\n",
      "GD iter. 255/499: loss=0.5522261981247193\n",
      "GD iter. 256/499: loss=0.5522007400837536\n",
      "GD iter. 257/499: loss=0.5521296306480399\n",
      "GD iter. 258/499: loss=0.5520831893101782\n",
      "GD iter. 259/499: loss=0.5520307490493478\n",
      "GD iter. 260/499: loss=0.5520081633611326\n",
      "GD iter. 261/499: loss=0.5519505033421022\n",
      "GD iter. 262/499: loss=0.551910530110569\n",
      "GD iter. 263/499: loss=0.5518505126491877\n",
      "GD iter. 264/499: loss=0.5518162795159874\n",
      "GD iter. 265/499: loss=0.5517989721602373\n",
      "GD iter. 266/499: loss=0.5517258679757366\n",
      "GD iter. 267/499: loss=0.5517123906307687\n",
      "GD iter. 268/499: loss=0.5516583842094389\n",
      "GD iter. 269/499: loss=0.5516090827893105\n",
      "GD iter. 270/499: loss=0.5515733248940325\n",
      "GD iter. 271/499: loss=0.5515274857537654\n",
      "GD iter. 272/499: loss=0.5514877167309804\n",
      "GD iter. 273/499: loss=0.5514557731317018\n",
      "GD iter. 274/499: loss=0.5513868855601498\n",
      "GD iter. 275/499: loss=0.5513643180818932\n",
      "GD iter. 276/499: loss=0.5513490731813848\n",
      "GD iter. 277/499: loss=0.5512767127838708\n",
      "GD iter. 278/499: loss=0.5512269986981106\n",
      "GD iter. 279/499: loss=0.5511972525100655\n",
      "GD iter. 280/499: loss=0.551167338145865\n",
      "GD iter. 281/499: loss=0.5510943305089256\n",
      "GD iter. 282/499: loss=0.5510658683693431\n",
      "GD iter. 283/499: loss=0.5510334686092591\n",
      "GD iter. 284/499: loss=0.55102208522834\n",
      "GD iter. 285/499: loss=0.5509587438383223\n",
      "GD iter. 286/499: loss=0.5509096032576319\n",
      "GD iter. 287/499: loss=0.5508579595637411\n",
      "GD iter. 288/499: loss=0.550840588591838\n",
      "GD iter. 289/499: loss=0.5508226367654093\n",
      "GD iter. 290/499: loss=0.5507682087292425\n",
      "GD iter. 291/499: loss=0.5507185986030828\n",
      "GD iter. 292/499: loss=0.5506807240273838\n",
      "GD iter. 293/499: loss=0.5506594403169663\n",
      "GD iter. 294/499: loss=0.5506232165962087\n",
      "GD iter. 295/499: loss=0.550569360884178\n",
      "GD iter. 296/499: loss=0.5505584922428823\n",
      "GD iter. 297/499: loss=0.5505028765856368\n",
      "GD iter. 298/499: loss=0.55045712523347\n",
      "GD iter. 299/499: loss=0.5504299137706493\n",
      "GD iter. 300/499: loss=0.5504106375470921\n",
      "GD iter. 301/499: loss=0.5503602271665751\n",
      "GD iter. 302/499: loss=0.5503557794422351\n",
      "GD iter. 303/499: loss=0.5502864541664737\n",
      "GD iter. 304/499: loss=0.5502757298804529\n",
      "GD iter. 305/499: loss=0.5502179876242927\n",
      "GD iter. 306/499: loss=0.5502134884357069\n",
      "GD iter. 307/499: loss=0.5501798344639638\n",
      "GD iter. 308/499: loss=0.5501190834763229\n",
      "GD iter. 309/499: loss=0.5501125476918379\n",
      "GD iter. 310/499: loss=0.5500693746134596\n",
      "GD iter. 311/499: loss=0.5500300930017927\n",
      "GD iter. 312/499: loss=0.5499859957491964\n",
      "GD iter. 313/499: loss=0.549967144126464\n",
      "GD iter. 314/499: loss=0.5499746759144707\n",
      "GD iter. 315/499: loss=0.5498957254657986\n",
      "GD iter. 316/499: loss=0.5498801133070951\n",
      "GD iter. 317/499: loss=0.5498694035926909\n",
      "GD iter. 318/499: loss=0.549841346627002\n",
      "GD iter. 319/499: loss=0.5498209869142764\n",
      "GD iter. 320/499: loss=0.549786249211233\n",
      "GD iter. 321/499: loss=0.5497211255809099\n",
      "GD iter. 322/499: loss=0.5497101721975389\n",
      "GD iter. 323/499: loss=0.5496733219063669\n",
      "GD iter. 324/499: loss=0.5496393542397522\n",
      "GD iter. 325/499: loss=0.5496178652847357\n",
      "GD iter. 326/499: loss=0.549607156316607\n",
      "GD iter. 327/499: loss=0.5495461490941733\n",
      "GD iter. 328/499: loss=0.5495298104725835\n",
      "GD iter. 329/499: loss=0.5494868387408824\n",
      "GD iter. 330/499: loss=0.5494698422373717\n",
      "GD iter. 331/499: loss=0.5494507222699123\n",
      "GD iter. 332/499: loss=0.549405520543978\n",
      "GD iter. 333/499: loss=0.5493745614884422\n",
      "GD iter. 334/499: loss=0.5493432183913702\n",
      "GD iter. 335/499: loss=0.5493346660978355\n",
      "GD iter. 336/499: loss=0.5493129438183695\n",
      "GD iter. 337/499: loss=0.5492793734484303\n",
      "GD iter. 338/499: loss=0.5492269574613018\n",
      "GD iter. 339/499: loss=0.5492114220165393\n",
      "GD iter. 340/499: loss=0.5491708663211953\n",
      "GD iter. 341/499: loss=0.549157614564688\n",
      "GD iter. 342/499: loss=0.5491413940650499\n",
      "GD iter. 343/499: loss=0.5490860082483414\n",
      "GD iter. 344/499: loss=0.5490520827785069\n",
      "GD iter. 345/499: loss=0.5490560147123953\n",
      "GD iter. 346/499: loss=0.5490086037761404\n",
      "GD iter. 347/499: loss=0.5489966610672207\n",
      "GD iter. 348/499: loss=0.5489605337610722\n",
      "GD iter. 349/499: loss=0.548942302994157\n",
      "GD iter. 350/499: loss=0.5489008503177519\n",
      "GD iter. 351/499: loss=0.5488737926862092\n",
      "GD iter. 352/499: loss=0.5488653064627593\n",
      "GD iter. 353/499: loss=0.5488310396484684\n",
      "GD iter. 354/499: loss=0.5487963763150332\n",
      "GD iter. 355/499: loss=0.5487695213648279\n",
      "GD iter. 356/499: loss=0.5487478650511918\n",
      "GD iter. 357/499: loss=0.5487195022053338\n",
      "GD iter. 358/499: loss=0.5487219417762497\n",
      "GD iter. 359/499: loss=0.5486818664134807\n",
      "GD iter. 360/499: loss=0.5486379356701301\n",
      "GD iter. 361/499: loss=0.5486343327233986\n",
      "GD iter. 362/499: loss=0.5485958463339479\n",
      "GD iter. 363/499: loss=0.5485807380185311\n",
      "GD iter. 364/499: loss=0.5485521392149054\n",
      "GD iter. 365/499: loss=0.5485280913968598\n",
      "GD iter. 366/499: loss=0.5484991364202584\n",
      "GD iter. 367/499: loss=0.5484986306579863\n",
      "GD iter. 368/499: loss=0.5484581014093239\n",
      "GD iter. 369/499: loss=0.5484542277491454\n",
      "GD iter. 370/499: loss=0.5484162813113317\n",
      "GD iter. 371/499: loss=0.5484062077164056\n",
      "GD iter. 372/499: loss=0.5483950588083438\n",
      "GD iter. 373/499: loss=0.5483373068464877\n",
      "GD iter. 374/499: loss=0.5483200499419469\n",
      "GD iter. 375/499: loss=0.5483097903469077\n",
      "GD iter. 376/499: loss=0.5482767687816762\n",
      "GD iter. 377/499: loss=0.5482355426463917\n",
      "GD iter. 378/499: loss=0.5482483903635917\n",
      "GD iter. 379/499: loss=0.5482135785480702\n",
      "GD iter. 380/499: loss=0.5481881700013084\n",
      "GD iter. 381/499: loss=0.5481611456506299\n",
      "GD iter. 382/499: loss=0.5481534064340705\n",
      "GD iter. 383/499: loss=0.5481311000835386\n",
      "GD iter. 384/499: loss=0.5481015534059065\n",
      "GD iter. 385/499: loss=0.5480685893660607\n",
      "GD iter. 386/499: loss=0.5480440847770668\n",
      "GD iter. 387/499: loss=0.5480352679670601\n",
      "GD iter. 388/499: loss=0.5480173361358307\n",
      "GD iter. 389/499: loss=0.547988694281304\n",
      "GD iter. 390/499: loss=0.5479627997581124\n",
      "GD iter. 391/499: loss=0.5479381978009016\n",
      "GD iter. 392/499: loss=0.5479486261999202\n",
      "GD iter. 393/499: loss=0.5479105883493433\n",
      "GD iter. 394/499: loss=0.5478774779389836\n",
      "GD iter. 395/499: loss=0.5478680964993975\n",
      "GD iter. 396/499: loss=0.5478503505228969\n",
      "GD iter. 397/499: loss=0.5478469340718517\n",
      "GD iter. 398/499: loss=0.547818500342001\n",
      "GD iter. 399/499: loss=0.5477721531907545\n",
      "GD iter. 400/499: loss=0.54776944985182\n",
      "GD iter. 401/499: loss=0.5477344492737536\n",
      "GD iter. 402/499: loss=0.547719833039844\n",
      "GD iter. 403/499: loss=0.5476985890669072\n",
      "GD iter. 404/499: loss=0.5476771685986599\n",
      "GD iter. 405/499: loss=0.5476680926519032\n",
      "GD iter. 406/499: loss=0.5476366568989287\n",
      "GD iter. 407/499: loss=0.5476028160347141\n",
      "GD iter. 408/499: loss=0.5475960442183467\n",
      "GD iter. 409/499: loss=0.5475586562705171\n",
      "GD iter. 410/499: loss=0.5475431155479514\n",
      "GD iter. 411/499: loss=0.547532751492461\n",
      "GD iter. 412/499: loss=0.5475189871923618\n",
      "GD iter. 413/499: loss=0.5475079306098897\n",
      "GD iter. 414/499: loss=0.5474984706499447\n",
      "GD iter. 415/499: loss=0.547474793256037\n",
      "GD iter. 416/499: loss=0.547465589682348\n",
      "GD iter. 417/499: loss=0.5474068160156758\n",
      "GD iter. 418/499: loss=0.5473936630605718\n",
      "GD iter. 419/499: loss=0.5473653624739809\n",
      "GD iter. 420/499: loss=0.5473885792791473\n",
      "GD iter. 421/499: loss=0.5473386354506118\n",
      "GD iter. 422/499: loss=0.5473142054188966\n",
      "GD iter. 423/499: loss=0.5472993491775382\n",
      "GD iter. 424/499: loss=0.5472748105193236\n",
      "GD iter. 425/499: loss=0.5472606594145766\n",
      "GD iter. 426/499: loss=0.5472624293407451\n",
      "GD iter. 427/499: loss=0.5472311817607046\n",
      "GD iter. 428/499: loss=0.5472066587061775\n",
      "GD iter. 429/499: loss=0.5471813079511222\n",
      "GD iter. 430/499: loss=0.5471708176210909\n",
      "GD iter. 431/499: loss=0.5471514668203531\n",
      "GD iter. 432/499: loss=0.547127310489362\n",
      "GD iter. 433/499: loss=0.5471042314784885\n",
      "GD iter. 434/499: loss=0.5470863806175243\n",
      "GD iter. 435/499: loss=0.5470911176289208\n",
      "GD iter. 436/499: loss=0.5470878819345498\n",
      "GD iter. 437/499: loss=0.5470923830040691\n",
      "GD iter. 438/499: loss=0.5470367738562665\n",
      "GD iter. 439/499: loss=0.5470097804858357\n",
      "GD iter. 440/499: loss=0.5469993484586952\n",
      "GD iter. 441/499: loss=0.546967488481754\n",
      "GD iter. 442/499: loss=0.546953351439788\n",
      "GD iter. 443/499: loss=0.5469700409496656\n",
      "GD iter. 444/499: loss=0.5469632713829868\n",
      "GD iter. 445/499: loss=0.5469276944131947\n",
      "GD iter. 446/499: loss=0.5469220396864386\n",
      "GD iter. 447/499: loss=0.5468854303683328\n",
      "GD iter. 448/499: loss=0.5468691079224489\n",
      "GD iter. 449/499: loss=0.5468518350279987\n",
      "GD iter. 450/499: loss=0.5468560165507153\n",
      "GD iter. 451/499: loss=0.5468251968728897\n",
      "GD iter. 452/499: loss=0.5468163130370103\n",
      "GD iter. 453/499: loss=0.5467958737769034\n",
      "GD iter. 454/499: loss=0.5468027625197768\n",
      "GD iter. 455/499: loss=0.5467528606024757\n",
      "GD iter. 456/499: loss=0.5467789838766538\n",
      "GD iter. 457/499: loss=0.5467491888780065\n",
      "GD iter. 458/499: loss=0.5467278131990563\n",
      "GD iter. 459/499: loss=0.5466988806563574\n",
      "GD iter. 460/499: loss=0.5467042361500799\n",
      "GD iter. 461/499: loss=0.5466794843552187\n",
      "GD iter. 462/499: loss=0.5466696539844724\n",
      "GD iter. 463/499: loss=0.5466396945443717\n",
      "GD iter. 464/499: loss=0.5466094859643225\n",
      "GD iter. 465/499: loss=0.5466052346743027\n",
      "GD iter. 466/499: loss=0.54662888828794\n",
      "GD iter. 467/499: loss=0.546578041275508\n",
      "GD iter. 468/499: loss=0.5465893988205839\n",
      "GD iter. 469/499: loss=0.5465789780954511\n",
      "GD iter. 470/499: loss=0.5465512536384087\n",
      "GD iter. 471/499: loss=0.5465309585168802\n",
      "GD iter. 472/499: loss=0.5465497046802367\n",
      "GD iter. 473/499: loss=0.5465536407076955\n",
      "GD iter. 474/499: loss=0.5465420850994397\n",
      "GD iter. 475/499: loss=0.546469338542606\n",
      "GD iter. 476/499: loss=0.5464647856507321\n",
      "GD iter. 477/499: loss=0.5464260017121072\n",
      "GD iter. 478/499: loss=0.5464350461522407\n",
      "GD iter. 479/499: loss=0.546459538816993\n",
      "GD iter. 480/499: loss=0.5464215466870015\n",
      "GD iter. 481/499: loss=0.546412820724259\n",
      "GD iter. 482/499: loss=0.5464119426531151\n",
      "GD iter. 483/499: loss=0.5463682648553279\n",
      "GD iter. 484/499: loss=0.5463636119507169\n",
      "GD iter. 485/499: loss=0.5463344769278979\n",
      "GD iter. 486/499: loss=0.5463403504327867\n",
      "GD iter. 487/499: loss=0.5463184165869754\n",
      "GD iter. 488/499: loss=0.5463187219817845\n",
      "GD iter. 489/499: loss=0.5462945230623256\n",
      "GD iter. 490/499: loss=0.5462732482714158\n",
      "GD iter. 491/499: loss=0.546263083084783\n",
      "GD iter. 492/499: loss=0.5462682368598724\n",
      "GD iter. 493/499: loss=0.5462310391755368\n",
      "GD iter. 494/499: loss=0.5462368795283188\n",
      "GD iter. 495/499: loss=0.5462358753530273\n",
      "GD iter. 496/499: loss=0.5461946377730535\n",
      "GD iter. 497/499: loss=0.5461809545209428\n",
      "GD iter. 498/499: loss=0.546180197988293\n",
      "GD iter. 499/499: loss=0.5461787681341751\n",
      "The Accuracy is: 0.6934\n",
      "The F1 score is: 0.3297\n",
      "The precision is: 0.2035\n",
      "The recall is: 0.8679\n",
      "GD iter. 0/499: loss=0.9519326110398533\n",
      "GD iter. 1/499: loss=0.8777351629878462\n",
      "GD iter. 2/499: loss=0.807552584322248\n",
      "GD iter. 3/499: loss=0.7531582252601929\n",
      "GD iter. 4/499: loss=0.719716637035127\n",
      "GD iter. 5/499: loss=0.6996276135593891\n",
      "GD iter. 6/499: loss=0.6839137040942194\n",
      "GD iter. 7/499: loss=0.6720414050347568\n",
      "GD iter. 8/499: loss=0.6626020493473057\n",
      "GD iter. 9/499: loss=0.6550743518102877\n",
      "GD iter. 10/499: loss=0.6489188413988634\n",
      "GD iter. 11/499: loss=0.6437974981949192\n",
      "GD iter. 12/499: loss=0.6394441866657036\n",
      "GD iter. 13/499: loss=0.6357028303421942\n",
      "GD iter. 14/499: loss=0.6322726404622748\n",
      "GD iter. 15/499: loss=0.6293615120508699\n",
      "GD iter. 16/499: loss=0.6267641725585718\n",
      "GD iter. 17/499: loss=0.6244134051125295\n",
      "GD iter. 18/499: loss=0.6222443656071908\n",
      "GD iter. 19/499: loss=0.6203226099289824\n",
      "GD iter. 20/499: loss=0.6186318838145517\n",
      "GD iter. 21/499: loss=0.6170198495860423\n",
      "GD iter. 22/499: loss=0.6154385071570703\n",
      "GD iter. 23/499: loss=0.6138864529175402\n",
      "GD iter. 24/499: loss=0.6124202578453317\n",
      "GD iter. 25/499: loss=0.61102340996606\n",
      "GD iter. 26/499: loss=0.6096821036391399\n",
      "GD iter. 27/499: loss=0.6084009201595135\n",
      "GD iter. 28/499: loss=0.6071585246638558\n",
      "GD iter. 29/499: loss=0.6059341972028885\n",
      "GD iter. 30/499: loss=0.6047825041965285\n",
      "GD iter. 31/499: loss=0.603640087644763\n",
      "GD iter. 32/499: loss=0.6025451065360529\n",
      "GD iter. 33/499: loss=0.6015117384857691\n",
      "GD iter. 34/499: loss=0.6005072232347246\n",
      "GD iter. 35/499: loss=0.5995472828154238\n",
      "GD iter. 36/499: loss=0.5986048521085034\n",
      "GD iter. 37/499: loss=0.5977065393097521\n",
      "GD iter. 38/499: loss=0.5968192858311598\n",
      "GD iter. 39/499: loss=0.5959647590714993\n",
      "GD iter. 40/499: loss=0.5951640117244091\n",
      "GD iter. 41/499: loss=0.5944406984150226\n",
      "GD iter. 42/499: loss=0.5937370241066132\n",
      "GD iter. 43/499: loss=0.5930755493712464\n",
      "GD iter. 44/499: loss=0.5924284373708567\n",
      "GD iter. 45/499: loss=0.5917840446103594\n",
      "GD iter. 46/499: loss=0.5911586660017476\n",
      "GD iter. 47/499: loss=0.5905748165745055\n",
      "GD iter. 48/499: loss=0.5899864577684789\n",
      "GD iter. 49/499: loss=0.5894152496970633\n",
      "GD iter. 50/499: loss=0.5888666883826533\n",
      "GD iter. 51/499: loss=0.5883332249798742\n",
      "GD iter. 52/499: loss=0.5878074124105744\n",
      "GD iter. 53/499: loss=0.5872894820138385\n",
      "GD iter. 54/499: loss=0.5867835849833547\n",
      "GD iter. 55/499: loss=0.5862847568915488\n",
      "GD iter. 56/499: loss=0.5857865122173956\n",
      "GD iter. 57/499: loss=0.5852802094662238\n",
      "GD iter. 58/499: loss=0.5847868681938116\n",
      "GD iter. 59/499: loss=0.5842901239555405\n",
      "GD iter. 60/499: loss=0.5838002136093553\n",
      "GD iter. 61/499: loss=0.5833227164700525\n",
      "GD iter. 62/499: loss=0.5828534859427715\n",
      "GD iter. 63/499: loss=0.5823820389727875\n",
      "GD iter. 64/499: loss=0.5819171264913674\n",
      "GD iter. 65/499: loss=0.5814559565097495\n",
      "GD iter. 66/499: loss=0.5809997001030162\n",
      "GD iter. 67/499: loss=0.5805628954440082\n",
      "GD iter. 68/499: loss=0.5801261031331325\n",
      "GD iter. 69/499: loss=0.5797294467216173\n",
      "GD iter. 70/499: loss=0.5793198069770206\n",
      "GD iter. 71/499: loss=0.5789257844977864\n",
      "GD iter. 72/499: loss=0.5785991788506146\n",
      "GD iter. 73/499: loss=0.5782557567630927\n",
      "GD iter. 74/499: loss=0.5779000219756114\n",
      "GD iter. 75/499: loss=0.5775573091612055\n",
      "GD iter. 76/499: loss=0.5772501660977467\n",
      "GD iter. 77/499: loss=0.576928073685959\n",
      "GD iter. 78/499: loss=0.576614469482764\n",
      "GD iter. 79/499: loss=0.5763131489629701\n",
      "GD iter. 80/499: loss=0.5760134895193416\n",
      "GD iter. 81/499: loss=0.5757126792989223\n",
      "GD iter. 82/499: loss=0.5754213291956425\n",
      "GD iter. 83/499: loss=0.5751447808788888\n",
      "GD iter. 84/499: loss=0.5748728141463073\n",
      "GD iter. 85/499: loss=0.5745810890891143\n",
      "GD iter. 86/499: loss=0.5743165066690349\n",
      "GD iter. 87/499: loss=0.5740527774411366\n",
      "GD iter. 88/499: loss=0.5737914447561357\n",
      "GD iter. 89/499: loss=0.573559829524499\n",
      "GD iter. 90/499: loss=0.5733083064246497\n",
      "GD iter. 91/499: loss=0.5730476729720355\n",
      "GD iter. 92/499: loss=0.572802638903887\n",
      "GD iter. 93/499: loss=0.572572500071468\n",
      "GD iter. 94/499: loss=0.5723281047505193\n",
      "GD iter. 95/499: loss=0.5720960832882416\n",
      "GD iter. 96/499: loss=0.5718801954234153\n",
      "GD iter. 97/499: loss=0.5716656680889524\n",
      "GD iter. 98/499: loss=0.5714276357043875\n",
      "GD iter. 99/499: loss=0.5712046640562162\n",
      "GD iter. 100/499: loss=0.5709844485819469\n",
      "GD iter. 101/499: loss=0.5707653626487285\n",
      "GD iter. 102/499: loss=0.5705595437292376\n",
      "GD iter. 103/499: loss=0.5703520264295334\n",
      "GD iter. 104/499: loss=0.5701459121377973\n",
      "GD iter. 105/499: loss=0.5699695166031793\n",
      "GD iter. 106/499: loss=0.569754247489879\n",
      "GD iter. 107/499: loss=0.5695382894795068\n",
      "GD iter. 108/499: loss=0.5693315158094198\n",
      "GD iter. 109/499: loss=0.5691401641616444\n",
      "GD iter. 110/499: loss=0.5689461942289459\n",
      "GD iter. 111/499: loss=0.5687628841172688\n",
      "GD iter. 112/499: loss=0.5685697855483898\n",
      "GD iter. 113/499: loss=0.5683794992237863\n",
      "GD iter. 114/499: loss=0.5682081599274809\n",
      "GD iter. 115/499: loss=0.5680385582170255\n",
      "GD iter. 116/499: loss=0.5678500239572365\n",
      "GD iter. 117/499: loss=0.5676750523657722\n",
      "GD iter. 118/499: loss=0.567504899182134\n",
      "GD iter. 119/499: loss=0.5673216501342508\n",
      "GD iter. 120/499: loss=0.5671742983061321\n",
      "GD iter. 121/499: loss=0.5669909103600663\n",
      "GD iter. 122/499: loss=0.5668399174757983\n",
      "GD iter. 123/499: loss=0.56666351057069\n",
      "GD iter. 124/499: loss=0.5665029039017422\n",
      "GD iter. 125/499: loss=0.566339560983628\n",
      "GD iter. 126/499: loss=0.5661677683298052\n",
      "GD iter. 127/499: loss=0.5660114307650388\n",
      "GD iter. 128/499: loss=0.5658591823469022\n",
      "GD iter. 129/499: loss=0.5657037330076689\n",
      "GD iter. 130/499: loss=0.5655511905837471\n",
      "GD iter. 131/499: loss=0.5653901172649127\n",
      "GD iter. 132/499: loss=0.5652405359197338\n",
      "GD iter. 133/499: loss=0.5650633902669305\n",
      "GD iter. 134/499: loss=0.5649080521941326\n",
      "GD iter. 135/499: loss=0.5647706877957541\n",
      "GD iter. 136/499: loss=0.5646331056127007\n",
      "GD iter. 137/499: loss=0.5644574917639357\n",
      "GD iter. 138/499: loss=0.5643087513694123\n",
      "GD iter. 139/499: loss=0.5641650986479539\n",
      "GD iter. 140/499: loss=0.5640198983494553\n",
      "GD iter. 141/499: loss=0.5638850158636572\n",
      "GD iter. 142/499: loss=0.5637268177083922\n",
      "GD iter. 143/499: loss=0.5635910476919078\n",
      "GD iter. 144/499: loss=0.5634306713085997\n",
      "GD iter. 145/499: loss=0.5632997439906076\n",
      "GD iter. 146/499: loss=0.5631722218376681\n",
      "GD iter. 147/499: loss=0.5630490554171548\n",
      "GD iter. 148/499: loss=0.5628901112397149\n",
      "GD iter. 149/499: loss=0.5627559433944014\n",
      "GD iter. 150/499: loss=0.562629149065635\n",
      "GD iter. 151/499: loss=0.5624917063244108\n",
      "GD iter. 152/499: loss=0.5623721501255843\n",
      "GD iter. 153/499: loss=0.5622581320785973\n",
      "GD iter. 154/499: loss=0.5621086965685514\n",
      "GD iter. 155/499: loss=0.5619938869195205\n",
      "GD iter. 156/499: loss=0.5618705039604954\n",
      "GD iter. 157/499: loss=0.561744790443559\n",
      "GD iter. 158/499: loss=0.5615974039800004\n",
      "GD iter. 159/499: loss=0.5614734536028488\n",
      "GD iter. 160/499: loss=0.5613612641887818\n",
      "GD iter. 161/499: loss=0.5612389734980731\n",
      "GD iter. 162/499: loss=0.5611092369545996\n",
      "GD iter. 163/499: loss=0.5609950499967544\n",
      "GD iter. 164/499: loss=0.5608756474521518\n",
      "GD iter. 165/499: loss=0.5607489609402466\n",
      "GD iter. 166/499: loss=0.5606124646972511\n",
      "GD iter. 167/499: loss=0.5605017539063324\n",
      "GD iter. 168/499: loss=0.5604125605404088\n",
      "GD iter. 169/499: loss=0.5602613789504001\n",
      "GD iter. 170/499: loss=0.5601332723466917\n",
      "GD iter. 171/499: loss=0.5600265957817703\n",
      "GD iter. 172/499: loss=0.5599190663175305\n",
      "GD iter. 173/499: loss=0.5597902425939835\n",
      "GD iter. 174/499: loss=0.559700489931144\n",
      "GD iter. 175/499: loss=0.5596110957873434\n",
      "GD iter. 176/499: loss=0.5594667230977617\n",
      "GD iter. 177/499: loss=0.5593383743629681\n",
      "GD iter. 178/499: loss=0.5592542748056301\n",
      "GD iter. 179/499: loss=0.5591319369177289\n",
      "GD iter. 180/499: loss=0.5590170352437466\n",
      "GD iter. 181/499: loss=0.5589104633446019\n",
      "GD iter. 182/499: loss=0.5587842918269652\n",
      "GD iter. 183/499: loss=0.5587128549560977\n",
      "GD iter. 184/499: loss=0.5585956489450701\n",
      "GD iter. 185/499: loss=0.5584730622631651\n",
      "GD iter. 186/499: loss=0.5583472867679328\n",
      "GD iter. 187/499: loss=0.5582563470305398\n",
      "GD iter. 188/499: loss=0.5581462527811755\n",
      "GD iter. 189/499: loss=0.5580388827234558\n",
      "GD iter. 190/499: loss=0.5579339418885124\n",
      "GD iter. 191/499: loss=0.5578379777590576\n",
      "GD iter. 192/499: loss=0.5577154268831476\n",
      "GD iter. 193/499: loss=0.5576052845181354\n",
      "GD iter. 194/499: loss=0.5575227714376693\n",
      "GD iter. 195/499: loss=0.5574046082794271\n",
      "GD iter. 196/499: loss=0.557290755946407\n",
      "GD iter. 197/499: loss=0.5571805231100709\n",
      "GD iter. 198/499: loss=0.5571012030712721\n",
      "GD iter. 199/499: loss=0.5570030364147462\n",
      "GD iter. 200/499: loss=0.5568846205868252\n",
      "GD iter. 201/499: loss=0.5567687596206505\n",
      "GD iter. 202/499: loss=0.5566701146757375\n",
      "GD iter. 203/499: loss=0.5566026947545227\n",
      "GD iter. 204/499: loss=0.5564842046228456\n",
      "GD iter. 205/499: loss=0.5563883096967164\n",
      "GD iter. 206/499: loss=0.5563154272527071\n",
      "GD iter. 207/499: loss=0.5562028678919392\n",
      "GD iter. 208/499: loss=0.5560851082849753\n",
      "GD iter. 209/499: loss=0.5560000690092028\n",
      "GD iter. 210/499: loss=0.5559158857960249\n",
      "GD iter. 211/499: loss=0.5558100525139348\n",
      "GD iter. 212/499: loss=0.5557081071767854\n",
      "GD iter. 213/499: loss=0.5556178256599607\n",
      "GD iter. 214/499: loss=0.5555355429469047\n",
      "GD iter. 215/499: loss=0.5554399460709084\n",
      "GD iter. 216/499: loss=0.5553327506630261\n",
      "GD iter. 217/499: loss=0.5552371272234154\n",
      "GD iter. 218/499: loss=0.5551876443320065\n",
      "GD iter. 219/499: loss=0.5550587799067749\n",
      "GD iter. 220/499: loss=0.5549554173787454\n",
      "GD iter. 221/499: loss=0.5548789758041028\n",
      "GD iter. 222/499: loss=0.5547928021962545\n",
      "GD iter. 223/499: loss=0.5546842390915248\n",
      "GD iter. 224/499: loss=0.554588605934654\n",
      "GD iter. 225/499: loss=0.5545052661302398\n",
      "GD iter. 226/499: loss=0.5544091158214385\n",
      "GD iter. 227/499: loss=0.5543137128391349\n",
      "GD iter. 228/499: loss=0.5542461976572045\n",
      "GD iter. 229/499: loss=0.5541474232010333\n",
      "GD iter. 230/499: loss=0.554048236696314\n",
      "GD iter. 231/499: loss=0.5539655965875256\n",
      "GD iter. 232/499: loss=0.5538830240977887\n",
      "GD iter. 233/499: loss=0.5538321659275427\n",
      "GD iter. 234/499: loss=0.5537450473908165\n",
      "GD iter. 235/499: loss=0.553640821352843\n",
      "GD iter. 236/499: loss=0.5535733891953436\n",
      "GD iter. 237/499: loss=0.5535121042108174\n",
      "GD iter. 238/499: loss=0.5534121905239378\n",
      "GD iter. 239/499: loss=0.5533326042942917\n",
      "GD iter. 240/499: loss=0.5532618112184627\n",
      "GD iter. 241/499: loss=0.5531888512510817\n",
      "GD iter. 242/499: loss=0.5531069043629441\n",
      "GD iter. 243/499: loss=0.5530292687934609\n",
      "GD iter. 244/499: loss=0.552966935686012\n",
      "GD iter. 245/499: loss=0.5528807315658166\n",
      "GD iter. 246/499: loss=0.5528137508298758\n",
      "GD iter. 247/499: loss=0.5527357803032785\n",
      "GD iter. 248/499: loss=0.5526546640224598\n",
      "GD iter. 249/499: loss=0.552589024334149\n",
      "GD iter. 250/499: loss=0.552509720212347\n",
      "GD iter. 251/499: loss=0.5524757251324854\n",
      "GD iter. 252/499: loss=0.5523759107213652\n",
      "GD iter. 253/499: loss=0.5523057432702185\n",
      "GD iter. 254/499: loss=0.552252914373215\n",
      "GD iter. 255/499: loss=0.5521803062896051\n",
      "GD iter. 256/499: loss=0.5521269380404604\n",
      "GD iter. 257/499: loss=0.5520362689139862\n",
      "GD iter. 258/499: loss=0.5519834580741508\n",
      "GD iter. 259/499: loss=0.5519129291577102\n",
      "GD iter. 260/499: loss=0.5518638246687079\n",
      "GD iter. 261/499: loss=0.5517786241914989\n",
      "GD iter. 262/499: loss=0.5517398105511129\n",
      "GD iter. 263/499: loss=0.5516608047818407\n",
      "GD iter. 264/499: loss=0.5515915045123673\n",
      "GD iter. 265/499: loss=0.551504467025529\n",
      "GD iter. 266/499: loss=0.5514582629362761\n",
      "GD iter. 267/499: loss=0.5513969574459638\n",
      "GD iter. 268/499: loss=0.5513426356449748\n",
      "GD iter. 269/499: loss=0.5512840025790516\n",
      "GD iter. 270/499: loss=0.5512224981726426\n",
      "GD iter. 271/499: loss=0.5511585227625699\n",
      "GD iter. 272/499: loss=0.5511049152698081\n",
      "GD iter. 273/499: loss=0.5510259125508132\n",
      "GD iter. 274/499: loss=0.550976913527653\n",
      "GD iter. 275/499: loss=0.5509239121686271\n",
      "GD iter. 276/499: loss=0.55084613798307\n",
      "GD iter. 277/499: loss=0.5507972425562585\n",
      "GD iter. 278/499: loss=0.5507513327662023\n",
      "GD iter. 279/499: loss=0.5506756014236918\n",
      "GD iter. 280/499: loss=0.5506163131172985\n",
      "GD iter. 281/499: loss=0.5505484689042104\n",
      "GD iter. 282/499: loss=0.5504964581616759\n",
      "GD iter. 283/499: loss=0.5504259160287501\n",
      "GD iter. 284/499: loss=0.5503803070326445\n",
      "GD iter. 285/499: loss=0.5503358229628378\n",
      "GD iter. 286/499: loss=0.5502649920511132\n",
      "GD iter. 287/499: loss=0.5502186347522262\n",
      "GD iter. 288/499: loss=0.5501419367255928\n",
      "GD iter. 289/499: loss=0.5500889482862046\n",
      "GD iter. 290/499: loss=0.5500612205223376\n",
      "GD iter. 291/499: loss=0.5499984955818764\n",
      "GD iter. 292/499: loss=0.5499282846504656\n",
      "GD iter. 293/499: loss=0.5498867503980641\n",
      "GD iter. 294/499: loss=0.549864031933481\n",
      "GD iter. 295/499: loss=0.5497993804788259\n",
      "GD iter. 296/499: loss=0.5497460543486142\n",
      "GD iter. 297/499: loss=0.5497242430047089\n",
      "GD iter. 298/499: loss=0.5496501409800354\n",
      "GD iter. 299/499: loss=0.5496306607175695\n",
      "GD iter. 300/499: loss=0.5495616091112622\n",
      "GD iter. 301/499: loss=0.5495205606936839\n",
      "GD iter. 302/499: loss=0.5494701471414961\n",
      "GD iter. 303/499: loss=0.5494632687412054\n",
      "GD iter. 304/499: loss=0.5493975939050472\n",
      "GD iter. 305/499: loss=0.5493521695170713\n",
      "GD iter. 306/499: loss=0.5492926814317314\n",
      "GD iter. 307/499: loss=0.5492647291337645\n",
      "GD iter. 308/499: loss=0.5492242848486603\n",
      "GD iter. 309/499: loss=0.5491720859864122\n",
      "GD iter. 310/499: loss=0.5491244179013054\n",
      "GD iter. 311/499: loss=0.5491167954782983\n",
      "GD iter. 312/499: loss=0.5490688886965404\n",
      "GD iter. 313/499: loss=0.5490266306905897\n",
      "GD iter. 314/499: loss=0.5489559583619634\n",
      "GD iter. 315/499: loss=0.5489268112465505\n",
      "GD iter. 316/499: loss=0.5488992250418253\n",
      "GD iter. 317/499: loss=0.5488725800102339\n",
      "GD iter. 318/499: loss=0.5487783224282786\n",
      "GD iter. 319/499: loss=0.5487619254276077\n",
      "GD iter. 320/499: loss=0.5487163457476748\n",
      "GD iter. 321/499: loss=0.5486976945373446\n",
      "GD iter. 322/499: loss=0.5486175208875642\n",
      "GD iter. 323/499: loss=0.5485994699410583\n",
      "GD iter. 324/499: loss=0.5485539807314779\n",
      "GD iter. 325/499: loss=0.54852547199657\n",
      "GD iter. 326/499: loss=0.5484795182404946\n",
      "GD iter. 327/499: loss=0.548465148723638\n",
      "GD iter. 328/499: loss=0.5484163066049198\n",
      "GD iter. 329/499: loss=0.5484015291294376\n",
      "GD iter. 330/499: loss=0.548360482844228\n",
      "GD iter. 331/499: loss=0.5483242501391308\n",
      "GD iter. 332/499: loss=0.5482549145576717\n",
      "GD iter. 333/499: loss=0.548222912155141\n",
      "GD iter. 334/499: loss=0.5481906083176015\n",
      "GD iter. 335/499: loss=0.5481671039726466\n",
      "GD iter. 336/499: loss=0.548153138644579\n",
      "GD iter. 337/499: loss=0.5481159253900248\n",
      "GD iter. 338/499: loss=0.5480849534633443\n",
      "GD iter. 339/499: loss=0.5480364975288472\n",
      "GD iter. 340/499: loss=0.5479872797474251\n",
      "GD iter. 341/499: loss=0.5479599135376624\n",
      "GD iter. 342/499: loss=0.5479153275842341\n",
      "GD iter. 343/499: loss=0.5479032691827348\n",
      "GD iter. 344/499: loss=0.5478836281512562\n",
      "GD iter. 345/499: loss=0.547853656766915\n",
      "GD iter. 346/499: loss=0.547819686177181\n",
      "GD iter. 347/499: loss=0.5477963770703108\n",
      "GD iter. 348/499: loss=0.5477663497235198\n",
      "GD iter. 349/499: loss=0.5477394899059198\n",
      "GD iter. 350/499: loss=0.5477107222457465\n",
      "GD iter. 351/499: loss=0.5476656072149518\n",
      "GD iter. 352/499: loss=0.5476329649937655\n",
      "GD iter. 353/499: loss=0.5475879990211313\n",
      "GD iter. 354/499: loss=0.5475542251212088\n",
      "GD iter. 355/499: loss=0.5475556529399163\n",
      "GD iter. 356/499: loss=0.5475304102214644\n",
      "GD iter. 357/499: loss=0.5474820441529826\n",
      "GD iter. 358/499: loss=0.5474353341061217\n",
      "GD iter. 359/499: loss=0.5474227038253746\n",
      "GD iter. 360/499: loss=0.5474382141346592\n",
      "GD iter. 361/499: loss=0.5473772792577157\n",
      "GD iter. 362/499: loss=0.547339103144788\n",
      "GD iter. 363/499: loss=0.5473204209944758\n",
      "GD iter. 364/499: loss=0.5472602153705236\n",
      "GD iter. 365/499: loss=0.5472339675842247\n",
      "GD iter. 366/499: loss=0.5471980136082056\n",
      "GD iter. 367/499: loss=0.5471790555939784\n",
      "GD iter. 368/499: loss=0.5471515209501107\n",
      "GD iter. 369/499: loss=0.5471399352017472\n",
      "GD iter. 370/499: loss=0.5471044242333981\n",
      "GD iter. 371/499: loss=0.5471118928740409\n",
      "GD iter. 372/499: loss=0.5470297038223533\n",
      "GD iter. 373/499: loss=0.5470081789640817\n",
      "GD iter. 374/499: loss=0.5469792972314399\n",
      "GD iter. 375/499: loss=0.5469694008404145\n",
      "GD iter. 376/499: loss=0.5469732144490964\n",
      "GD iter. 377/499: loss=0.5469098577804925\n",
      "GD iter. 378/499: loss=0.5469121173699031\n",
      "GD iter. 379/499: loss=0.5468454423904486\n",
      "GD iter. 380/499: loss=0.5468101622485828\n",
      "GD iter. 381/499: loss=0.5467983744850249\n",
      "GD iter. 382/499: loss=0.5468058504331018\n",
      "GD iter. 383/499: loss=0.546777666862706\n",
      "GD iter. 384/499: loss=0.5467244504023401\n",
      "GD iter. 385/499: loss=0.546696630925228\n",
      "GD iter. 386/499: loss=0.5467283486749649\n",
      "GD iter. 387/499: loss=0.5466974347253856\n",
      "GD iter. 388/499: loss=0.5466331885425381\n",
      "GD iter. 389/499: loss=0.5465836107620222\n",
      "GD iter. 390/499: loss=0.5465628618066751\n",
      "GD iter. 391/499: loss=0.5465223027206867\n",
      "GD iter. 392/499: loss=0.5465098074694997\n",
      "GD iter. 393/499: loss=0.5465130987877107\n",
      "GD iter. 394/499: loss=0.5464710171985423\n",
      "GD iter. 395/499: loss=0.5464497397800323\n",
      "GD iter. 396/499: loss=0.5464173438134583\n",
      "GD iter. 397/499: loss=0.5463995247020961\n",
      "GD iter. 398/499: loss=0.5463769966232161\n",
      "GD iter. 399/499: loss=0.5463721969890776\n",
      "GD iter. 400/499: loss=0.5463225637913038\n",
      "GD iter. 401/499: loss=0.546284801300868\n",
      "GD iter. 402/499: loss=0.5462722092734698\n",
      "GD iter. 403/499: loss=0.546251813933402\n",
      "GD iter. 404/499: loss=0.5462219424006951\n",
      "GD iter. 405/499: loss=0.5462142918745092\n",
      "GD iter. 406/499: loss=0.5461882520420828\n",
      "GD iter. 407/499: loss=0.5461888585304164\n",
      "GD iter. 408/499: loss=0.5461410702974347\n",
      "GD iter. 409/499: loss=0.5461031328602391\n",
      "GD iter. 410/499: loss=0.546080757501912\n",
      "GD iter. 411/499: loss=0.54607059025198\n",
      "GD iter. 412/499: loss=0.5460438591344922\n",
      "GD iter. 413/499: loss=0.5460209933562156\n",
      "GD iter. 414/499: loss=0.5460014103103185\n",
      "GD iter. 415/499: loss=0.5460082756236555\n",
      "GD iter. 416/499: loss=0.5459610987947605\n",
      "GD iter. 417/499: loss=0.5459397683615427\n",
      "GD iter. 418/499: loss=0.5459081238763893\n",
      "GD iter. 419/499: loss=0.5459111739308816\n",
      "GD iter. 420/499: loss=0.5458623483503955\n",
      "GD iter. 421/499: loss=0.5458221183834632\n",
      "GD iter. 422/499: loss=0.5458130192506151\n",
      "GD iter. 423/499: loss=0.5458241946756437\n",
      "GD iter. 424/499: loss=0.5457883033234155\n",
      "GD iter. 425/499: loss=0.5457978214516094\n",
      "GD iter. 426/499: loss=0.5457342740089459\n",
      "GD iter. 427/499: loss=0.5457239604047917\n",
      "GD iter. 428/499: loss=0.5457130104720519\n",
      "GD iter. 429/499: loss=0.5457136582064942\n",
      "GD iter. 430/499: loss=0.5456465512624167\n",
      "GD iter. 431/499: loss=0.5456395494026617\n",
      "GD iter. 432/499: loss=0.545611049659731\n",
      "GD iter. 433/499: loss=0.5455828539868428\n",
      "GD iter. 434/499: loss=0.5455495534516122\n",
      "GD iter. 435/499: loss=0.5455309971857614\n",
      "GD iter. 436/499: loss=0.545516003264574\n",
      "GD iter. 437/499: loss=0.5455138854996392\n",
      "GD iter. 438/499: loss=0.5454855725132892\n",
      "GD iter. 439/499: loss=0.5454900677660641\n",
      "GD iter. 440/499: loss=0.5454363257527401\n",
      "GD iter. 441/499: loss=0.5454124643573122\n",
      "GD iter. 442/499: loss=0.5453759059517975\n",
      "GD iter. 443/499: loss=0.5453544088010325\n",
      "GD iter. 444/499: loss=0.545351874811322\n",
      "GD iter. 445/499: loss=0.5453483894339807\n",
      "GD iter. 446/499: loss=0.5453102036847124\n",
      "GD iter. 447/499: loss=0.5452822735792439\n",
      "GD iter. 448/499: loss=0.5452644315584927\n",
      "GD iter. 449/499: loss=0.5452448523724276\n",
      "GD iter. 450/499: loss=0.5452104131181198\n",
      "GD iter. 451/499: loss=0.5452186694034374\n",
      "GD iter. 452/499: loss=0.5451924011146029\n",
      "GD iter. 453/499: loss=0.5451943464056692\n",
      "GD iter. 454/499: loss=0.545145889096698\n",
      "GD iter. 455/499: loss=0.5451323738936529\n",
      "GD iter. 456/499: loss=0.5451102535838761\n",
      "GD iter. 457/499: loss=0.5450918682716865\n",
      "GD iter. 458/499: loss=0.5450790695247221\n",
      "GD iter. 459/499: loss=0.5450628983279798\n",
      "GD iter. 460/499: loss=0.5450355232718099\n",
      "GD iter. 461/499: loss=0.5449972593004535\n",
      "GD iter. 462/499: loss=0.5449761656435307\n",
      "GD iter. 463/499: loss=0.5450149297917757\n",
      "GD iter. 464/499: loss=0.5449421767562453\n",
      "GD iter. 465/499: loss=0.5449106400067921\n",
      "GD iter. 466/499: loss=0.5449420391324212\n",
      "GD iter. 467/499: loss=0.5449432693613129\n",
      "GD iter. 468/499: loss=0.5448645512843603\n",
      "GD iter. 469/499: loss=0.5448782452939398\n",
      "GD iter. 470/499: loss=0.5448327277571848\n",
      "GD iter. 471/499: loss=0.5448283048775033\n",
      "GD iter. 472/499: loss=0.544797943346138\n",
      "GD iter. 473/499: loss=0.5448020849250808\n",
      "GD iter. 474/499: loss=0.5447663985257735\n",
      "GD iter. 475/499: loss=0.5447447068654989\n",
      "GD iter. 476/499: loss=0.5447374568534481\n",
      "GD iter. 477/499: loss=0.5447316126582405\n",
      "GD iter. 478/499: loss=0.5446995138240761\n",
      "GD iter. 479/499: loss=0.5446762423898679\n",
      "GD iter. 480/499: loss=0.5446531398229044\n",
      "GD iter. 481/499: loss=0.5446945726321245\n",
      "GD iter. 482/499: loss=0.5446705496687879\n",
      "GD iter. 483/499: loss=0.5446594449279579\n",
      "GD iter. 484/499: loss=0.5445980443526371\n",
      "GD iter. 485/499: loss=0.5445895264247768\n",
      "GD iter. 486/499: loss=0.5445526386012888\n",
      "GD iter. 487/499: loss=0.5445538609304432\n",
      "GD iter. 488/499: loss=0.5445123314900902\n",
      "GD iter. 489/499: loss=0.5444846068896179\n",
      "GD iter. 490/499: loss=0.5445005393402507\n",
      "GD iter. 491/499: loss=0.5445173799974634\n",
      "GD iter. 492/499: loss=0.5444509802583304\n",
      "GD iter. 493/499: loss=0.5444572864562117\n",
      "GD iter. 494/499: loss=0.5444394601707652\n",
      "GD iter. 495/499: loss=0.5444477381211801\n",
      "GD iter. 496/499: loss=0.5444358734423574\n",
      "GD iter. 497/499: loss=0.5444356173519597\n",
      "GD iter. 498/499: loss=0.5443612167835613\n",
      "GD iter. 499/499: loss=0.5443370103725041\n",
      "The Accuracy is: 0.6721\n",
      "The F1 score is: 0.3151\n",
      "The precision is: 0.1966\n",
      "The recall is: 0.7931\n",
      "GD iter. 0/499: loss=0.9630024810254585\n",
      "GD iter. 1/499: loss=0.8927967690763514\n",
      "GD iter. 2/499: loss=0.8245075184940753\n",
      "GD iter. 3/499: loss=0.7660518558106914\n",
      "GD iter. 4/499: loss=0.7275486169750475\n",
      "GD iter. 5/499: loss=0.7035053416239176\n",
      "GD iter. 6/499: loss=0.6869130619089849\n",
      "GD iter. 7/499: loss=0.6747360258396048\n",
      "GD iter. 8/499: loss=0.6658924663102052\n",
      "GD iter. 9/499: loss=0.6588210489008551\n",
      "GD iter. 10/499: loss=0.6534035470720656\n",
      "GD iter. 11/499: loss=0.6486488924570325\n",
      "GD iter. 12/499: loss=0.6446172053433095\n",
      "GD iter. 13/499: loss=0.6410603282822297\n",
      "GD iter. 14/499: loss=0.6379781600723061\n",
      "GD iter. 15/499: loss=0.6353053823942832\n",
      "GD iter. 16/499: loss=0.6328181257770913\n",
      "GD iter. 17/499: loss=0.6304874811926371\n",
      "GD iter. 18/499: loss=0.6283620868483981\n",
      "GD iter. 19/499: loss=0.6263775422724462\n",
      "GD iter. 20/499: loss=0.6245620043688862\n",
      "GD iter. 21/499: loss=0.6229170411526557\n",
      "GD iter. 22/499: loss=0.6213313850253812\n",
      "GD iter. 23/499: loss=0.6198272489512858\n",
      "GD iter. 24/499: loss=0.6183334416546132\n",
      "GD iter. 25/499: loss=0.6168988766698651\n",
      "GD iter. 26/499: loss=0.6155243839110207\n",
      "GD iter. 27/499: loss=0.6142018712888849\n",
      "GD iter. 28/499: loss=0.6129257756843962\n",
      "GD iter. 29/499: loss=0.6116626400363041\n",
      "GD iter. 30/499: loss=0.61043646176386\n",
      "GD iter. 31/499: loss=0.6092419249391511\n",
      "GD iter. 32/499: loss=0.608070661968814\n",
      "GD iter. 33/499: loss=0.6069451728822487\n",
      "GD iter. 34/499: loss=0.605859133179818\n",
      "GD iter. 35/499: loss=0.6048515460455773\n",
      "GD iter. 36/499: loss=0.6038863217792781\n",
      "GD iter. 37/499: loss=0.6029633334697938\n",
      "GD iter. 38/499: loss=0.6020933324379956\n",
      "GD iter. 39/499: loss=0.6012677194351241\n",
      "GD iter. 40/499: loss=0.60048179323851\n",
      "GD iter. 41/499: loss=0.5996985503524966\n",
      "GD iter. 42/499: loss=0.5989248717191882\n",
      "GD iter. 43/499: loss=0.5981665472295907\n",
      "GD iter. 44/499: loss=0.5974382388341984\n",
      "GD iter. 45/499: loss=0.5967453566700015\n",
      "GD iter. 46/499: loss=0.5960729350961383\n",
      "GD iter. 47/499: loss=0.5954197129791344\n",
      "GD iter. 48/499: loss=0.5947950539210095\n",
      "GD iter. 49/499: loss=0.5941869527976515\n",
      "GD iter. 50/499: loss=0.5935865827314908\n",
      "GD iter. 51/499: loss=0.5929954637077122\n",
      "GD iter. 52/499: loss=0.5924150219892675\n",
      "GD iter. 53/499: loss=0.5918295419382492\n",
      "GD iter. 54/499: loss=0.5912662720784556\n",
      "GD iter. 55/499: loss=0.590724349330175\n",
      "GD iter. 56/499: loss=0.5902130884268865\n",
      "GD iter. 57/499: loss=0.5897310699906018\n",
      "GD iter. 58/499: loss=0.5892703194875072\n",
      "GD iter. 59/499: loss=0.5888100831501687\n",
      "GD iter. 60/499: loss=0.5883542950937591\n",
      "GD iter. 61/499: loss=0.5878948044543296\n",
      "GD iter. 62/499: loss=0.5874690971829982\n",
      "GD iter. 63/499: loss=0.5870673678704165\n",
      "GD iter. 64/499: loss=0.5866642980434249\n",
      "GD iter. 65/499: loss=0.5862638900796149\n",
      "GD iter. 66/499: loss=0.5858706235991751\n",
      "GD iter. 67/499: loss=0.5854808255411186\n",
      "GD iter. 68/499: loss=0.5850905457406935\n",
      "GD iter. 69/499: loss=0.5847149501540185\n",
      "GD iter. 70/499: loss=0.5843501103035866\n",
      "GD iter. 71/499: loss=0.583998013341526\n",
      "GD iter. 72/499: loss=0.5836596977647157\n",
      "GD iter. 73/499: loss=0.5833256613733566\n",
      "GD iter. 74/499: loss=0.583015593488095\n",
      "GD iter. 75/499: loss=0.5827040000468151\n",
      "GD iter. 76/499: loss=0.5824067461788456\n",
      "GD iter. 77/499: loss=0.582106253121706\n",
      "GD iter. 78/499: loss=0.5818078640463837\n",
      "GD iter. 79/499: loss=0.581501662157418\n",
      "GD iter. 80/499: loss=0.58121350078861\n",
      "GD iter. 81/499: loss=0.5809257264324332\n",
      "GD iter. 82/499: loss=0.5806407530225158\n",
      "GD iter. 83/499: loss=0.5803524904268409\n",
      "GD iter. 84/499: loss=0.5800721275792282\n",
      "GD iter. 85/499: loss=0.579802928588537\n",
      "GD iter. 86/499: loss=0.5795256677550621\n",
      "GD iter. 87/499: loss=0.5792523095263303\n",
      "GD iter. 88/499: loss=0.5789951628197686\n",
      "GD iter. 89/499: loss=0.578750750094629\n",
      "GD iter. 90/499: loss=0.5784956438698601\n",
      "GD iter. 91/499: loss=0.5782460083218494\n",
      "GD iter. 92/499: loss=0.5780068486463037\n",
      "GD iter. 93/499: loss=0.5777654169092095\n",
      "GD iter. 94/499: loss=0.5775213336112034\n",
      "GD iter. 95/499: loss=0.5772802136750838\n",
      "GD iter. 96/499: loss=0.5770559329376859\n",
      "GD iter. 97/499: loss=0.5768187792597252\n",
      "GD iter. 98/499: loss=0.5765890054204261\n",
      "GD iter. 99/499: loss=0.5763559071322383\n",
      "GD iter. 100/499: loss=0.5761336075341382\n",
      "GD iter. 101/499: loss=0.5759023186986878\n",
      "GD iter. 102/499: loss=0.5756814020796356\n",
      "GD iter. 103/499: loss=0.5754562774632516\n",
      "GD iter. 104/499: loss=0.5752330621171733\n",
      "GD iter. 105/499: loss=0.5750132825557829\n",
      "GD iter. 106/499: loss=0.5747865862457516\n",
      "GD iter. 107/499: loss=0.5745782436747254\n",
      "GD iter. 108/499: loss=0.574348865483433\n",
      "GD iter. 109/499: loss=0.5741348121473396\n",
      "GD iter. 110/499: loss=0.5739130560714903\n",
      "GD iter. 111/499: loss=0.5737006547645768\n",
      "GD iter. 112/499: loss=0.5734836657979814\n",
      "GD iter. 113/499: loss=0.5732659723850658\n",
      "GD iter. 114/499: loss=0.5730550119669268\n",
      "GD iter. 115/499: loss=0.5728647153518175\n",
      "GD iter. 116/499: loss=0.5726753110430438\n",
      "GD iter. 117/499: loss=0.5724941441645043\n",
      "GD iter. 118/499: loss=0.5723054626792516\n",
      "GD iter. 119/499: loss=0.5721245421823817\n",
      "GD iter. 120/499: loss=0.5719432738471067\n",
      "GD iter. 121/499: loss=0.5717697444145491\n",
      "GD iter. 122/499: loss=0.5715880292338512\n",
      "GD iter. 123/499: loss=0.5714218163718463\n",
      "GD iter. 124/499: loss=0.5712575318254592\n",
      "GD iter. 125/499: loss=0.571075100510492\n",
      "GD iter. 126/499: loss=0.5709061782022362\n",
      "GD iter. 127/499: loss=0.5707339395062931\n",
      "GD iter. 128/499: loss=0.5705724012539172\n",
      "GD iter. 129/499: loss=0.5704124799838101\n",
      "GD iter. 130/499: loss=0.5702612206873506\n",
      "GD iter. 131/499: loss=0.5701160366926609\n",
      "GD iter. 132/499: loss=0.5699820408330052\n",
      "GD iter. 133/499: loss=0.5698282370792853\n",
      "GD iter. 134/499: loss=0.5696856566765446\n",
      "GD iter. 135/499: loss=0.5695583622455893\n",
      "GD iter. 136/499: loss=0.5694216656601874\n",
      "GD iter. 137/499: loss=0.5692782374332601\n",
      "GD iter. 138/499: loss=0.5691414150874032\n",
      "GD iter. 139/499: loss=0.5690065252249761\n",
      "GD iter. 140/499: loss=0.568878328518787\n",
      "GD iter. 141/499: loss=0.5687597621822067\n",
      "GD iter. 142/499: loss=0.5686140446229685\n",
      "GD iter. 143/499: loss=0.5684815524614582\n",
      "GD iter. 144/499: loss=0.5683630776077161\n",
      "GD iter. 145/499: loss=0.5682257176879016\n",
      "GD iter. 146/499: loss=0.5680955553313504\n",
      "GD iter. 147/499: loss=0.5679674152578028\n",
      "GD iter. 148/499: loss=0.5678434136289686\n",
      "GD iter. 149/499: loss=0.5677204815050142\n",
      "GD iter. 150/499: loss=0.5675919667345896\n",
      "GD iter. 151/499: loss=0.5674731938164244\n",
      "GD iter. 152/499: loss=0.5673548813472971\n",
      "GD iter. 153/499: loss=0.5672427782125878\n",
      "GD iter. 154/499: loss=0.5671173277032531\n",
      "GD iter. 155/499: loss=0.5670039838683665\n",
      "GD iter. 156/499: loss=0.5668958036942884\n",
      "GD iter. 157/499: loss=0.5667774195989305\n",
      "GD iter. 158/499: loss=0.5666565233505555\n",
      "GD iter. 159/499: loss=0.5665477697388204\n",
      "GD iter. 160/499: loss=0.5664376239651224\n",
      "GD iter. 161/499: loss=0.5663249180682096\n",
      "GD iter. 162/499: loss=0.5662178492183888\n",
      "GD iter. 163/499: loss=0.5661082000904836\n",
      "GD iter. 164/499: loss=0.5660045837896439\n",
      "GD iter. 165/499: loss=0.5658946583845511\n",
      "GD iter. 166/499: loss=0.5657822060537949\n",
      "GD iter. 167/499: loss=0.5656851693543008\n",
      "GD iter. 168/499: loss=0.5655856323859835\n",
      "GD iter. 169/499: loss=0.5654841333633475\n",
      "GD iter. 170/499: loss=0.5653735704705382\n",
      "GD iter. 171/499: loss=0.5652803964824189\n",
      "GD iter. 172/499: loss=0.5651717751537465\n",
      "GD iter. 173/499: loss=0.5650988406583305\n",
      "GD iter. 174/499: loss=0.5650027035699662\n",
      "GD iter. 175/499: loss=0.5648924452889795\n",
      "GD iter. 176/499: loss=0.5648047650816961\n",
      "GD iter. 177/499: loss=0.5647159780014832\n",
      "GD iter. 178/499: loss=0.564635896778377\n",
      "GD iter. 179/499: loss=0.5645424403980572\n",
      "GD iter. 180/499: loss=0.56445039526205\n",
      "GD iter. 181/499: loss=0.5643601182686835\n",
      "GD iter. 182/499: loss=0.5642788914968656\n",
      "GD iter. 183/499: loss=0.5642010830198578\n",
      "GD iter. 184/499: loss=0.5641250462908919\n",
      "GD iter. 185/499: loss=0.5640181159859571\n",
      "GD iter. 186/499: loss=0.5639384992489013\n",
      "GD iter. 187/499: loss=0.5638602874082737\n",
      "GD iter. 188/499: loss=0.5637769325804498\n",
      "GD iter. 189/499: loss=0.5636948209753462\n",
      "GD iter. 190/499: loss=0.5636217850470051\n",
      "GD iter. 191/499: loss=0.5635425085904411\n",
      "GD iter. 192/499: loss=0.5634602720159853\n",
      "GD iter. 193/499: loss=0.5633847616715532\n",
      "GD iter. 194/499: loss=0.5632965470968441\n",
      "GD iter. 195/499: loss=0.5632157833438068\n",
      "GD iter. 196/499: loss=0.5631413705379723\n",
      "GD iter. 197/499: loss=0.5630717057447884\n",
      "GD iter. 198/499: loss=0.5629823186633497\n",
      "GD iter. 199/499: loss=0.5629080779582604\n",
      "GD iter. 200/499: loss=0.5628230960610133\n",
      "GD iter. 201/499: loss=0.5627456956941003\n",
      "GD iter. 202/499: loss=0.5626714177450384\n",
      "GD iter. 203/499: loss=0.562590183699995\n",
      "GD iter. 204/499: loss=0.5625241249390914\n",
      "GD iter. 205/499: loss=0.5624476815112609\n",
      "GD iter. 206/499: loss=0.5623647429462354\n",
      "GD iter. 207/499: loss=0.5622967650345035\n",
      "GD iter. 208/499: loss=0.5622230214558205\n",
      "GD iter. 209/499: loss=0.5621425627834489\n",
      "GD iter. 210/499: loss=0.5620686479316445\n",
      "GD iter. 211/499: loss=0.5619961460053937\n",
      "GD iter. 212/499: loss=0.5619362551949831\n",
      "GD iter. 213/499: loss=0.5618555533128482\n",
      "GD iter. 214/499: loss=0.5617831494299629\n",
      "GD iter. 215/499: loss=0.5617028880994616\n",
      "GD iter. 216/499: loss=0.5616307707024856\n",
      "GD iter. 217/499: loss=0.5615685933520025\n",
      "GD iter. 218/499: loss=0.5614973026275164\n",
      "GD iter. 219/499: loss=0.561413677493531\n",
      "GD iter. 220/499: loss=0.5613459459589991\n",
      "GD iter. 221/499: loss=0.5612728523469843\n",
      "GD iter. 222/499: loss=0.5612055237921362\n",
      "GD iter. 223/499: loss=0.5611542410036576\n",
      "GD iter. 224/499: loss=0.5610681932236303\n",
      "GD iter. 225/499: loss=0.5609955753692049\n",
      "GD iter. 226/499: loss=0.5609264075857695\n",
      "GD iter. 227/499: loss=0.5608626187922499\n",
      "GD iter. 228/499: loss=0.5607954588791367\n",
      "GD iter. 229/499: loss=0.5607422009801459\n",
      "GD iter. 230/499: loss=0.5606680681152693\n",
      "GD iter. 231/499: loss=0.5605861423959001\n",
      "GD iter. 232/499: loss=0.5605220069964851\n",
      "GD iter. 233/499: loss=0.5604565639756478\n",
      "GD iter. 234/499: loss=0.5604131074001574\n",
      "GD iter. 235/499: loss=0.5603341111850256\n",
      "GD iter. 236/499: loss=0.5602593853807114\n",
      "GD iter. 237/499: loss=0.5602014505081916\n",
      "GD iter. 238/499: loss=0.560133209056959\n",
      "GD iter. 239/499: loss=0.5600648652199524\n",
      "GD iter. 240/499: loss=0.5600043265048212\n",
      "GD iter. 241/499: loss=0.5599300289127505\n",
      "GD iter. 242/499: loss=0.559878015490182\n",
      "GD iter. 243/499: loss=0.5598065743999171\n",
      "GD iter. 244/499: loss=0.5597380549892358\n",
      "GD iter. 245/499: loss=0.5596922336148196\n",
      "GD iter. 246/499: loss=0.5596183820131382\n",
      "GD iter. 247/499: loss=0.5595486238656155\n",
      "GD iter. 248/499: loss=0.5594897406085778\n",
      "GD iter. 249/499: loss=0.5594188074147729\n",
      "GD iter. 250/499: loss=0.5593549784990327\n",
      "GD iter. 251/499: loss=0.5592902785574362\n",
      "GD iter. 252/499: loss=0.5592520658205309\n",
      "GD iter. 253/499: loss=0.5591845282081372\n",
      "GD iter. 254/499: loss=0.559145195246262\n",
      "GD iter. 255/499: loss=0.559074689524262\n",
      "GD iter. 256/499: loss=0.5590209835841012\n",
      "GD iter. 257/499: loss=0.5589635695534947\n",
      "GD iter. 258/499: loss=0.558928512228598\n",
      "GD iter. 259/499: loss=0.558861413386797\n",
      "GD iter. 260/499: loss=0.5588074984433407\n",
      "GD iter. 261/499: loss=0.5587627130712781\n",
      "GD iter. 262/499: loss=0.5587039331620282\n",
      "GD iter. 263/499: loss=0.5586648282051203\n",
      "GD iter. 264/499: loss=0.5586201978372543\n",
      "GD iter. 265/499: loss=0.55855759657937\n",
      "GD iter. 266/499: loss=0.5585058137502651\n",
      "GD iter. 267/499: loss=0.5584634176738769\n",
      "GD iter. 268/499: loss=0.5584198773366881\n",
      "GD iter. 269/499: loss=0.5583783710267476\n",
      "GD iter. 270/499: loss=0.5583170016676366\n",
      "GD iter. 271/499: loss=0.5582763835778435\n",
      "GD iter. 272/499: loss=0.5582376740385817\n",
      "GD iter. 273/499: loss=0.5581866439176273\n",
      "GD iter. 274/499: loss=0.5581314063296324\n",
      "GD iter. 275/499: loss=0.5580738250140379\n",
      "GD iter. 276/499: loss=0.5580394264164913\n",
      "GD iter. 277/499: loss=0.5579907446737885\n",
      "GD iter. 278/499: loss=0.5579483228160981\n",
      "GD iter. 279/499: loss=0.5579070132801541\n",
      "GD iter. 280/499: loss=0.5578470933022075\n",
      "GD iter. 281/499: loss=0.5578123908385783\n",
      "GD iter. 282/499: loss=0.5577579032984197\n",
      "GD iter. 283/499: loss=0.5577118891945921\n",
      "GD iter. 284/499: loss=0.5576739608818362\n",
      "GD iter. 285/499: loss=0.5576239415386722\n",
      "GD iter. 286/499: loss=0.5575735959350653\n",
      "GD iter. 287/499: loss=0.5575355513067778\n",
      "GD iter. 288/499: loss=0.5574733977134793\n",
      "GD iter. 289/499: loss=0.5574373002235303\n",
      "GD iter. 290/499: loss=0.5574111138102327\n",
      "GD iter. 291/499: loss=0.5573561095202713\n",
      "GD iter. 292/499: loss=0.5573027849719826\n",
      "GD iter. 293/499: loss=0.5572647627247498\n",
      "GD iter. 294/499: loss=0.5572072229926042\n",
      "GD iter. 295/499: loss=0.5571610736478677\n",
      "GD iter. 296/499: loss=0.5571312536549401\n",
      "GD iter. 297/499: loss=0.5570813117938268\n",
      "GD iter. 298/499: loss=0.5570452209252829\n",
      "GD iter. 299/499: loss=0.5569930972583412\n",
      "GD iter. 300/499: loss=0.5569505882176358\n",
      "GD iter. 301/499: loss=0.5569050751150256\n",
      "GD iter. 302/499: loss=0.556858989107474\n",
      "GD iter. 303/499: loss=0.5568304555896747\n",
      "GD iter. 304/499: loss=0.5567799167041443\n",
      "GD iter. 305/499: loss=0.5567556085526326\n",
      "GD iter. 306/499: loss=0.5567029408580845\n",
      "GD iter. 307/499: loss=0.5566409499333524\n",
      "GD iter. 308/499: loss=0.5566068001685021\n",
      "GD iter. 309/499: loss=0.5565557275320272\n",
      "GD iter. 310/499: loss=0.5565087002834748\n",
      "GD iter. 311/499: loss=0.5564742592875812\n",
      "GD iter. 312/499: loss=0.5564328675616339\n",
      "GD iter. 313/499: loss=0.5563941567104104\n",
      "GD iter. 314/499: loss=0.5563608861271497\n",
      "GD iter. 315/499: loss=0.5563087989958098\n",
      "GD iter. 316/499: loss=0.5562719440271774\n",
      "GD iter. 317/499: loss=0.5562279783728474\n",
      "GD iter. 318/499: loss=0.5561843419164254\n",
      "GD iter. 319/499: loss=0.5561315764907168\n",
      "GD iter. 320/499: loss=0.5560966632936498\n",
      "GD iter. 321/499: loss=0.5560596376289483\n",
      "GD iter. 322/499: loss=0.5560097694672905\n",
      "GD iter. 323/499: loss=0.5559826455900782\n",
      "GD iter. 324/499: loss=0.5559629655717907\n",
      "GD iter. 325/499: loss=0.5559070692094475\n",
      "GD iter. 326/499: loss=0.5558539885156487\n",
      "GD iter. 327/499: loss=0.5558074261104077\n",
      "GD iter. 328/499: loss=0.5557834829078381\n",
      "GD iter. 329/499: loss=0.5557390445422229\n",
      "GD iter. 330/499: loss=0.5556951630375357\n",
      "GD iter. 331/499: loss=0.5556521172164676\n",
      "GD iter. 332/499: loss=0.5556211358427365\n",
      "GD iter. 333/499: loss=0.5555749867417497\n",
      "GD iter. 334/499: loss=0.5555346329585323\n",
      "GD iter. 335/499: loss=0.5554954302425033\n",
      "GD iter. 336/499: loss=0.5554488176746772\n",
      "GD iter. 337/499: loss=0.5554265125536771\n",
      "GD iter. 338/499: loss=0.5554033711073865\n",
      "GD iter. 339/499: loss=0.5553560643849175\n",
      "GD iter. 340/499: loss=0.555300446847148\n",
      "GD iter. 341/499: loss=0.5552605227288792\n",
      "GD iter. 342/499: loss=0.5552245406008656\n",
      "GD iter. 343/499: loss=0.5552098510977713\n",
      "GD iter. 344/499: loss=0.5551638283826306\n",
      "GD iter. 345/499: loss=0.5551270111312528\n",
      "GD iter. 346/499: loss=0.5550944734993912\n",
      "GD iter. 347/499: loss=0.5550443068737498\n",
      "GD iter. 348/499: loss=0.5550157793185589\n",
      "GD iter. 349/499: loss=0.5549770044988703\n",
      "GD iter. 350/499: loss=0.554942899132534\n",
      "GD iter. 351/499: loss=0.5549185270094423\n",
      "GD iter. 352/499: loss=0.5548660919319119\n",
      "GD iter. 353/499: loss=0.5548232676747058\n",
      "GD iter. 354/499: loss=0.5547899933431997\n",
      "GD iter. 355/499: loss=0.5547567057764565\n",
      "GD iter. 356/499: loss=0.5547286006164486\n",
      "GD iter. 357/499: loss=0.5546914237164327\n",
      "GD iter. 358/499: loss=0.5546538145325248\n",
      "GD iter. 359/499: loss=0.5546284036114145\n",
      "GD iter. 360/499: loss=0.554588359489449\n",
      "GD iter. 361/499: loss=0.554563358205302\n",
      "GD iter. 362/499: loss=0.5545195052013225\n",
      "GD iter. 363/499: loss=0.5544886023459458\n",
      "GD iter. 364/499: loss=0.5544589138265797\n",
      "GD iter. 365/499: loss=0.5544577100391945\n",
      "GD iter. 366/499: loss=0.554397053758636\n",
      "GD iter. 367/499: loss=0.5543611767571978\n",
      "GD iter. 368/499: loss=0.5543186165846529\n",
      "GD iter. 369/499: loss=0.5542868959139192\n",
      "GD iter. 370/499: loss=0.5542578066062116\n",
      "GD iter. 371/499: loss=0.5542349456878326\n",
      "GD iter. 372/499: loss=0.5541993555964071\n",
      "GD iter. 373/499: loss=0.5541495663520003\n",
      "GD iter. 374/499: loss=0.5541322826214723\n",
      "GD iter. 375/499: loss=0.5540958270874756\n",
      "GD iter. 376/499: loss=0.5540627911732242\n",
      "GD iter. 377/499: loss=0.5540318060707716\n",
      "GD iter. 378/499: loss=0.5540115464847324\n",
      "GD iter. 379/499: loss=0.5539824638242372\n",
      "GD iter. 380/499: loss=0.5539425740100813\n",
      "GD iter. 381/499: loss=0.5539101714476073\n",
      "GD iter. 382/499: loss=0.5538744814222144\n",
      "GD iter. 383/499: loss=0.5538488466089161\n",
      "GD iter. 384/499: loss=0.5538212016161528\n",
      "GD iter. 385/499: loss=0.5537881070056855\n",
      "GD iter. 386/499: loss=0.55375270440964\n",
      "GD iter. 387/499: loss=0.5537246605672066\n",
      "GD iter. 388/499: loss=0.5537014856422731\n",
      "GD iter. 389/499: loss=0.5536613048580884\n",
      "GD iter. 390/499: loss=0.5536271301186223\n",
      "GD iter. 391/499: loss=0.5536000155436269\n",
      "GD iter. 392/499: loss=0.5535712548814896\n",
      "GD iter. 393/499: loss=0.5535350644719\n",
      "GD iter. 394/499: loss=0.553525707433709\n",
      "GD iter. 395/499: loss=0.5534828663605337\n",
      "GD iter. 396/499: loss=0.5534616573832375\n",
      "GD iter. 397/499: loss=0.5534262782682745\n",
      "GD iter. 398/499: loss=0.5533924527123283\n",
      "GD iter. 399/499: loss=0.5533772878873827\n",
      "GD iter. 400/499: loss=0.5533527544600418\n",
      "GD iter. 401/499: loss=0.5533255671355777\n",
      "GD iter. 402/499: loss=0.5532813650197581\n",
      "GD iter. 403/499: loss=0.5532434236027876\n",
      "GD iter. 404/499: loss=0.5532386049054795\n",
      "GD iter. 405/499: loss=0.5532143269195893\n",
      "GD iter. 406/499: loss=0.5531618675687364\n",
      "GD iter. 407/499: loss=0.5531416679390735\n",
      "GD iter. 408/499: loss=0.5531420268347818\n",
      "GD iter. 409/499: loss=0.5530933607561739\n",
      "GD iter. 410/499: loss=0.553070296608024\n",
      "GD iter. 411/499: loss=0.5530277145284037\n",
      "GD iter. 412/499: loss=0.5530059756556642\n",
      "GD iter. 413/499: loss=0.5530086627805002\n",
      "GD iter. 414/499: loss=0.5529516418414122\n",
      "GD iter. 415/499: loss=0.552931493183653\n",
      "GD iter. 416/499: loss=0.552897482054278\n",
      "GD iter. 417/499: loss=0.5528684180166278\n",
      "GD iter. 418/499: loss=0.5528665254085088\n",
      "GD iter. 419/499: loss=0.552830624240616\n",
      "GD iter. 420/499: loss=0.5527986359861796\n",
      "GD iter. 421/499: loss=0.5527759052450316\n",
      "GD iter. 422/499: loss=0.5527552333686664\n",
      "GD iter. 423/499: loss=0.5527332935584507\n",
      "GD iter. 424/499: loss=0.5526879376144407\n",
      "GD iter. 425/499: loss=0.5526703939661737\n",
      "GD iter. 426/499: loss=0.5526490859309289\n",
      "GD iter. 427/499: loss=0.5526270478427837\n",
      "GD iter. 428/499: loss=0.5526000849396985\n",
      "GD iter. 429/499: loss=0.5525715103919072\n",
      "GD iter. 430/499: loss=0.5525496240627077\n",
      "GD iter. 431/499: loss=0.5525171979482305\n",
      "GD iter. 432/499: loss=0.5524876282309277\n",
      "GD iter. 433/499: loss=0.5524826959086758\n",
      "GD iter. 434/499: loss=0.5524492688560898\n",
      "GD iter. 435/499: loss=0.5524325363247375\n",
      "GD iter. 436/499: loss=0.5523998889531184\n",
      "GD iter. 437/499: loss=0.5523856671514831\n",
      "GD iter. 438/499: loss=0.5523535351126307\n",
      "GD iter. 439/499: loss=0.5523371451209368\n",
      "GD iter. 440/499: loss=0.5523168317228944\n",
      "GD iter. 441/499: loss=0.5522855504800931\n",
      "GD iter. 442/499: loss=0.5522578066413752\n",
      "GD iter. 443/499: loss=0.552236157541421\n",
      "GD iter. 444/499: loss=0.5522258749310199\n",
      "GD iter. 445/499: loss=0.5521914035468053\n",
      "GD iter. 446/499: loss=0.5521702695798748\n",
      "GD iter. 447/499: loss=0.5521364822140842\n",
      "GD iter. 448/499: loss=0.5521340908867988\n",
      "GD iter. 449/499: loss=0.5520975043216636\n",
      "GD iter. 450/499: loss=0.5520927851638976\n",
      "GD iter. 451/499: loss=0.5520540890078689\n",
      "GD iter. 452/499: loss=0.5520131264360225\n",
      "GD iter. 453/499: loss=0.551999690384383\n",
      "GD iter. 454/499: loss=0.5520045787521156\n",
      "GD iter. 455/499: loss=0.5519882085700866\n",
      "GD iter. 456/499: loss=0.5519461806592351\n",
      "GD iter. 457/499: loss=0.5519154251528644\n",
      "GD iter. 458/499: loss=0.5518898674402454\n",
      "GD iter. 459/499: loss=0.5518748161418132\n",
      "GD iter. 460/499: loss=0.5518908117544367\n",
      "GD iter. 461/499: loss=0.551824817627693\n",
      "GD iter. 462/499: loss=0.5518186823600485\n",
      "GD iter. 463/499: loss=0.5517818739020015\n",
      "GD iter. 464/499: loss=0.5517603540103206\n",
      "GD iter. 465/499: loss=0.5517480500015306\n",
      "GD iter. 466/499: loss=0.5517193494748288\n",
      "GD iter. 467/499: loss=0.5517051735239384\n",
      "GD iter. 468/499: loss=0.5516858225878868\n",
      "GD iter. 469/499: loss=0.5516908566682539\n",
      "GD iter. 470/499: loss=0.5516572313463044\n",
      "GD iter. 471/499: loss=0.5516299284044285\n",
      "GD iter. 472/499: loss=0.5516041346607943\n",
      "GD iter. 473/499: loss=0.5515902624666356\n",
      "GD iter. 474/499: loss=0.551569441692566\n",
      "GD iter. 475/499: loss=0.5515510934931727\n",
      "GD iter. 476/499: loss=0.5515407541160046\n",
      "GD iter. 477/499: loss=0.5515138601163642\n",
      "GD iter. 478/499: loss=0.5514855196254881\n",
      "GD iter. 479/499: loss=0.5514599408459504\n",
      "GD iter. 480/499: loss=0.5514479427803457\n",
      "GD iter. 481/499: loss=0.5514394946765729\n",
      "GD iter. 482/499: loss=0.5513977046354938\n",
      "GD iter. 483/499: loss=0.5513943293684563\n",
      "GD iter. 484/499: loss=0.5513823340465631\n",
      "GD iter. 485/499: loss=0.5513610984947183\n",
      "GD iter. 486/499: loss=0.5513269045295378\n",
      "GD iter. 487/499: loss=0.5512973144177183\n",
      "GD iter. 488/499: loss=0.5512727279360257\n",
      "GD iter. 489/499: loss=0.5512655635468794\n",
      "GD iter. 490/499: loss=0.5512488631872535\n",
      "GD iter. 491/499: loss=0.5512350875538662\n",
      "GD iter. 492/499: loss=0.5512077521289809\n",
      "GD iter. 493/499: loss=0.5511886024032077\n",
      "GD iter. 494/499: loss=0.5511710480396773\n",
      "GD iter. 495/499: loss=0.5511542582780175\n",
      "GD iter. 496/499: loss=0.5511386344610795\n",
      "GD iter. 497/499: loss=0.5511132044452789\n",
      "GD iter. 498/499: loss=0.5511170403289233\n",
      "GD iter. 499/499: loss=0.5510822873856553\n",
      "The Accuracy is: 0.6721\n",
      "The F1 score is: 0.3151\n",
      "The precision is: 0.1917\n",
      "The recall is: 0.8846\n",
      "GD iter. 0/499: loss=0.9895103268718892\n",
      "GD iter. 1/499: loss=0.9141671944486324\n",
      "GD iter. 2/499: loss=0.8391997289402592\n",
      "GD iter. 3/499: loss=0.7708160531423474\n",
      "GD iter. 4/499: loss=0.7228543070773253\n",
      "GD iter. 5/499: loss=0.6933610097410313\n",
      "GD iter. 6/499: loss=0.674715694957917\n",
      "GD iter. 7/499: loss=0.6619838409096377\n",
      "GD iter. 8/499: loss=0.6520900213939526\n",
      "GD iter. 9/499: loss=0.6445941346476687\n",
      "GD iter. 10/499: loss=0.638877851102676\n",
      "GD iter. 11/499: loss=0.6342864040944012\n",
      "GD iter. 12/499: loss=0.6302952905383911\n",
      "GD iter. 13/499: loss=0.6267802887298192\n",
      "GD iter. 14/499: loss=0.6237577553365564\n",
      "GD iter. 15/499: loss=0.6211531646223305\n",
      "GD iter. 16/499: loss=0.6187400581969054\n",
      "GD iter. 17/499: loss=0.6165560819973251\n",
      "GD iter. 18/499: loss=0.6145918799839419\n",
      "GD iter. 19/499: loss=0.6127659534551397\n",
      "GD iter. 20/499: loss=0.6110906074910283\n",
      "GD iter. 21/499: loss=0.6094957301936953\n",
      "GD iter. 22/499: loss=0.6080131638531533\n",
      "GD iter. 23/499: loss=0.6065816386508719\n",
      "GD iter. 24/499: loss=0.6052079911571911\n",
      "GD iter. 25/499: loss=0.6038671783495269\n",
      "GD iter. 26/499: loss=0.6025740908821723\n",
      "GD iter. 27/499: loss=0.6013490242139392\n",
      "GD iter. 28/499: loss=0.6001689085626545\n",
      "GD iter. 29/499: loss=0.5990157846715033\n",
      "GD iter. 30/499: loss=0.5979189635505394\n",
      "GD iter. 31/499: loss=0.5968541176267661\n",
      "GD iter. 32/499: loss=0.5958289135669813\n",
      "GD iter. 33/499: loss=0.5948510943856027\n",
      "GD iter. 34/499: loss=0.5938984688838411\n",
      "GD iter. 35/499: loss=0.5929775866782258\n",
      "GD iter. 36/499: loss=0.5921334938446793\n",
      "GD iter. 37/499: loss=0.5913155634107145\n",
      "GD iter. 38/499: loss=0.590530985492417\n",
      "GD iter. 39/499: loss=0.5897985005761924\n",
      "GD iter. 40/499: loss=0.5890801474440021\n",
      "GD iter. 41/499: loss=0.5883520150856192\n",
      "GD iter. 42/499: loss=0.587637707846076\n",
      "GD iter. 43/499: loss=0.5869429851926087\n",
      "GD iter. 44/499: loss=0.5862483458185607\n",
      "GD iter. 45/499: loss=0.5855697131565111\n",
      "GD iter. 46/499: loss=0.584956325506397\n",
      "GD iter. 47/499: loss=0.5843585548482109\n",
      "GD iter. 48/499: loss=0.5837713534578292\n",
      "GD iter. 49/499: loss=0.5832181178900997\n",
      "GD iter. 50/499: loss=0.5826889046646504\n",
      "GD iter. 51/499: loss=0.5821782748962974\n",
      "GD iter. 52/499: loss=0.5816767035120937\n",
      "GD iter. 53/499: loss=0.5811953589760017\n",
      "GD iter. 54/499: loss=0.5807390607754103\n",
      "GD iter. 55/499: loss=0.5803140178836603\n",
      "GD iter. 56/499: loss=0.579906985545831\n",
      "GD iter. 57/499: loss=0.5795015185834066\n",
      "GD iter. 58/499: loss=0.5791074500530645\n",
      "GD iter. 59/499: loss=0.578715709457996\n",
      "GD iter. 60/499: loss=0.5783372445290528\n",
      "GD iter. 61/499: loss=0.5779687136353064\n",
      "GD iter. 62/499: loss=0.5776124500079891\n",
      "GD iter. 63/499: loss=0.5772734390252551\n",
      "GD iter. 64/499: loss=0.5769251411331578\n",
      "GD iter. 65/499: loss=0.5765806051446423\n",
      "GD iter. 66/499: loss=0.5762447044679817\n",
      "GD iter. 67/499: loss=0.575924179047217\n",
      "GD iter. 68/499: loss=0.5756057315160639\n",
      "GD iter. 69/499: loss=0.5752868600916491\n",
      "GD iter. 70/499: loss=0.5749751453343883\n",
      "GD iter. 71/499: loss=0.5746660760535626\n",
      "GD iter. 72/499: loss=0.5743531231565635\n",
      "GD iter. 73/499: loss=0.5740535076333249\n",
      "GD iter. 74/499: loss=0.5737737729609751\n",
      "GD iter. 75/499: loss=0.5734880846509907\n",
      "GD iter. 76/499: loss=0.5732108045344255\n",
      "GD iter. 77/499: loss=0.5729434571589821\n",
      "GD iter. 78/499: loss=0.5726841487894595\n",
      "GD iter. 79/499: loss=0.5724301399398076\n",
      "GD iter. 80/499: loss=0.5721771367048112\n",
      "GD iter. 81/499: loss=0.5719393807784605\n",
      "GD iter. 82/499: loss=0.5717033502010991\n",
      "GD iter. 83/499: loss=0.5714705632958257\n",
      "GD iter. 84/499: loss=0.5712437973671632\n",
      "GD iter. 85/499: loss=0.5710225018016337\n",
      "GD iter. 86/499: loss=0.5708026532464678\n",
      "GD iter. 87/499: loss=0.5705878296339689\n",
      "GD iter. 88/499: loss=0.5703691956787575\n",
      "GD iter. 89/499: loss=0.5701599347338149\n",
      "GD iter. 90/499: loss=0.5699621215019981\n",
      "GD iter. 91/499: loss=0.5697631346904354\n",
      "GD iter. 92/499: loss=0.5695709455629819\n",
      "GD iter. 93/499: loss=0.5693670034569238\n",
      "GD iter. 94/499: loss=0.5691687702202084\n",
      "GD iter. 95/499: loss=0.5689773058978924\n",
      "GD iter. 96/499: loss=0.5687893043778469\n",
      "GD iter. 97/499: loss=0.5685991394319166\n",
      "GD iter. 98/499: loss=0.568421881863858\n",
      "GD iter. 99/499: loss=0.5682312505299624\n",
      "GD iter. 100/499: loss=0.5680454916808414\n",
      "GD iter. 101/499: loss=0.5678654055457749\n",
      "GD iter. 102/499: loss=0.5676799269822239\n",
      "GD iter. 103/499: loss=0.5675097283324262\n",
      "GD iter. 104/499: loss=0.5673177245162339\n",
      "GD iter. 105/499: loss=0.5671425515900632\n",
      "GD iter. 106/499: loss=0.5669857311983889\n",
      "GD iter. 107/499: loss=0.5668239101926388\n",
      "GD iter. 108/499: loss=0.5666719067174926\n",
      "GD iter. 109/499: loss=0.5665100985883894\n",
      "GD iter. 110/499: loss=0.5663488579195538\n",
      "GD iter. 111/499: loss=0.5662079003252823\n",
      "GD iter. 112/499: loss=0.5660583322556745\n",
      "GD iter. 113/499: loss=0.5659069434104463\n",
      "GD iter. 114/499: loss=0.5657635604047018\n",
      "GD iter. 115/499: loss=0.5656224661098905\n",
      "GD iter. 116/499: loss=0.5654717758948455\n",
      "GD iter. 117/499: loss=0.5653322066729353\n",
      "GD iter. 118/499: loss=0.5651894101948458\n",
      "GD iter. 119/499: loss=0.5650443848381449\n",
      "GD iter. 120/499: loss=0.5649062823563481\n",
      "GD iter. 121/499: loss=0.5647665614247823\n",
      "GD iter. 122/499: loss=0.5646374281995887\n",
      "GD iter. 123/499: loss=0.564496445484994\n",
      "GD iter. 124/499: loss=0.5643591818150547\n",
      "GD iter. 125/499: loss=0.5642322494125676\n",
      "GD iter. 126/499: loss=0.5640972481105491\n",
      "GD iter. 127/499: loss=0.5639770066356932\n",
      "GD iter. 128/499: loss=0.5638466723200839\n",
      "GD iter. 129/499: loss=0.5637270395594375\n",
      "GD iter. 130/499: loss=0.5635971504335063\n",
      "GD iter. 131/499: loss=0.5634718693736552\n",
      "GD iter. 132/499: loss=0.5633476743771056\n",
      "GD iter. 133/499: loss=0.563226765668344\n",
      "GD iter. 134/499: loss=0.5631203203807218\n",
      "GD iter. 135/499: loss=0.5630002332376681\n",
      "GD iter. 136/499: loss=0.5628770176835914\n",
      "GD iter. 137/499: loss=0.5627641535685527\n",
      "GD iter. 138/499: loss=0.5626531222014074\n",
      "GD iter. 139/499: loss=0.562547324046688\n",
      "GD iter. 140/499: loss=0.5624217488122198\n",
      "GD iter. 141/499: loss=0.5623155740933262\n",
      "GD iter. 142/499: loss=0.5622056571352192\n",
      "GD iter. 143/499: loss=0.5620957236551386\n",
      "GD iter. 144/499: loss=0.5619887171869563\n",
      "GD iter. 145/499: loss=0.5618832045334302\n",
      "GD iter. 146/499: loss=0.5617684627896085\n",
      "GD iter. 147/499: loss=0.5616560622789849\n",
      "GD iter. 148/499: loss=0.5615468509867693\n",
      "GD iter. 149/499: loss=0.5614314365018457\n",
      "GD iter. 150/499: loss=0.5613268083059842\n",
      "GD iter. 151/499: loss=0.5612135111771359\n",
      "GD iter. 152/499: loss=0.5611102735005655\n",
      "GD iter. 153/499: loss=0.5610146110283721\n",
      "GD iter. 154/499: loss=0.5609031362933935\n",
      "GD iter. 155/499: loss=0.5607962841396078\n",
      "GD iter. 156/499: loss=0.5606879923604408\n",
      "GD iter. 157/499: loss=0.5605799955667377\n",
      "GD iter. 158/499: loss=0.5604945841046947\n",
      "GD iter. 159/499: loss=0.5603703351497321\n",
      "GD iter. 160/499: loss=0.5602647219311625\n",
      "GD iter. 161/499: loss=0.5601617353918174\n",
      "GD iter. 162/499: loss=0.5600729153025378\n",
      "GD iter. 163/499: loss=0.5599658956555461\n",
      "GD iter. 164/499: loss=0.5598508346226304\n",
      "GD iter. 165/499: loss=0.5597560471188742\n",
      "GD iter. 166/499: loss=0.5596438134273848\n",
      "GD iter. 167/499: loss=0.5595434096015626\n",
      "GD iter. 168/499: loss=0.5594691903667479\n",
      "GD iter. 169/499: loss=0.55934828971043\n",
      "GD iter. 170/499: loss=0.5592487630175346\n",
      "GD iter. 171/499: loss=0.5591487218895183\n",
      "GD iter. 172/499: loss=0.5590512702513659\n",
      "GD iter. 173/499: loss=0.5589555066167075\n",
      "GD iter. 174/499: loss=0.558845702588116\n",
      "GD iter. 175/499: loss=0.5587413756026579\n",
      "GD iter. 176/499: loss=0.5586540311194638\n",
      "GD iter. 177/499: loss=0.5585565830188947\n",
      "GD iter. 178/499: loss=0.5584612209710579\n",
      "GD iter. 179/499: loss=0.5583671208921677\n",
      "GD iter. 180/499: loss=0.5582851937684786\n",
      "GD iter. 181/499: loss=0.5581900732552246\n",
      "GD iter. 182/499: loss=0.5581040552781891\n",
      "GD iter. 183/499: loss=0.5580097812167291\n",
      "GD iter. 184/499: loss=0.5579196935470335\n",
      "GD iter. 185/499: loss=0.5578337718401005\n",
      "GD iter. 186/499: loss=0.5577613914946672\n",
      "GD iter. 187/499: loss=0.5576648820310804\n",
      "GD iter. 188/499: loss=0.557563583222528\n",
      "GD iter. 189/499: loss=0.5574822429640941\n",
      "GD iter. 190/499: loss=0.557384527957624\n",
      "GD iter. 191/499: loss=0.5572939665417573\n",
      "GD iter. 192/499: loss=0.5572238757159372\n",
      "GD iter. 193/499: loss=0.557129521363577\n",
      "GD iter. 194/499: loss=0.5570425122847742\n",
      "GD iter. 195/499: loss=0.5569501552368523\n",
      "GD iter. 196/499: loss=0.5568660520458746\n",
      "GD iter. 197/499: loss=0.5568006009635696\n",
      "GD iter. 198/499: loss=0.5567015118546155\n",
      "GD iter. 199/499: loss=0.5566242048350707\n",
      "GD iter. 200/499: loss=0.5565509417446743\n",
      "GD iter. 201/499: loss=0.5564674573566174\n",
      "GD iter. 202/499: loss=0.5563861183408483\n",
      "GD iter. 203/499: loss=0.5563116371482874\n",
      "GD iter. 204/499: loss=0.5562366430933147\n",
      "GD iter. 205/499: loss=0.5561589602823754\n",
      "GD iter. 206/499: loss=0.5560759674782276\n",
      "GD iter. 207/499: loss=0.5559909340213358\n",
      "GD iter. 208/499: loss=0.555913947488986\n",
      "GD iter. 209/499: loss=0.5558430752674082\n",
      "GD iter. 210/499: loss=0.5557766972200934\n",
      "GD iter. 211/499: loss=0.5557126465453816\n",
      "GD iter. 212/499: loss=0.5556374864018961\n",
      "GD iter. 213/499: loss=0.5555517588793731\n",
      "GD iter. 214/499: loss=0.5554771580958582\n",
      "GD iter. 215/499: loss=0.5553993180265413\n",
      "GD iter. 216/499: loss=0.5553392766137485\n",
      "GD iter. 217/499: loss=0.5552772965632032\n",
      "GD iter. 218/499: loss=0.5551929198510875\n",
      "GD iter. 219/499: loss=0.5551147312166841\n",
      "GD iter. 220/499: loss=0.5550461968004095\n",
      "GD iter. 221/499: loss=0.5549748403832547\n",
      "GD iter. 222/499: loss=0.5549177387033684\n",
      "GD iter. 223/499: loss=0.554851771790049\n",
      "GD iter. 224/499: loss=0.5547777494479608\n",
      "GD iter. 225/499: loss=0.5546944412495769\n",
      "GD iter. 226/499: loss=0.5546227762690688\n",
      "GD iter. 227/499: loss=0.5545499570943213\n",
      "GD iter. 228/499: loss=0.554471690123265\n",
      "GD iter. 229/499: loss=0.5544107222110827\n",
      "GD iter. 230/499: loss=0.5543553792657966\n",
      "GD iter. 231/499: loss=0.5542869944974116\n",
      "GD iter. 232/499: loss=0.5542245967893562\n",
      "GD iter. 233/499: loss=0.5541545719673484\n",
      "GD iter. 234/499: loss=0.554100415531656\n",
      "GD iter. 235/499: loss=0.5540386270313019\n",
      "GD iter. 236/499: loss=0.5539900096938373\n",
      "GD iter. 237/499: loss=0.5539348532677805\n",
      "GD iter. 238/499: loss=0.5538705359763032\n",
      "GD iter. 239/499: loss=0.5538187490492102\n",
      "GD iter. 240/499: loss=0.553768524615307\n",
      "GD iter. 241/499: loss=0.5537174805240794\n",
      "GD iter. 242/499: loss=0.5536542459664862\n",
      "GD iter. 243/499: loss=0.5536145452376752\n",
      "GD iter. 244/499: loss=0.5535390856157653\n",
      "GD iter. 245/499: loss=0.5534991683859622\n",
      "GD iter. 246/499: loss=0.5534422196825444\n",
      "GD iter. 247/499: loss=0.5533949653466489\n",
      "GD iter. 248/499: loss=0.5533324319659705\n",
      "GD iter. 249/499: loss=0.5532866884417523\n",
      "GD iter. 250/499: loss=0.5532429626459509\n",
      "GD iter. 251/499: loss=0.553176845017964\n",
      "GD iter. 252/499: loss=0.5531275334718372\n",
      "GD iter. 253/499: loss=0.5530595680003758\n",
      "GD iter. 254/499: loss=0.5530258055060853\n",
      "GD iter. 255/499: loss=0.5529705697702074\n",
      "GD iter. 256/499: loss=0.5529147592244332\n",
      "GD iter. 257/499: loss=0.5528686048928377\n",
      "GD iter. 258/499: loss=0.5528157459420532\n",
      "GD iter. 259/499: loss=0.5527686311824472\n",
      "GD iter. 260/499: loss=0.5527062966584793\n",
      "GD iter. 261/499: loss=0.5526646455188201\n",
      "GD iter. 262/499: loss=0.5526027164356676\n",
      "GD iter. 263/499: loss=0.5525669079883474\n",
      "GD iter. 264/499: loss=0.5525313135288643\n",
      "GD iter. 265/499: loss=0.5524694243066767\n",
      "GD iter. 266/499: loss=0.5524191109883252\n",
      "GD iter. 267/499: loss=0.5523639486247943\n",
      "GD iter. 268/499: loss=0.5523188496398007\n",
      "GD iter. 269/499: loss=0.5522865959916704\n",
      "GD iter. 270/499: loss=0.5522142381328216\n",
      "GD iter. 271/499: loss=0.5521843767835872\n",
      "GD iter. 272/499: loss=0.5521212913259302\n",
      "GD iter. 273/499: loss=0.5520715399585469\n",
      "GD iter. 274/499: loss=0.5520300328028993\n",
      "GD iter. 275/499: loss=0.5519808937305877\n",
      "GD iter. 276/499: loss=0.5519355509128493\n",
      "GD iter. 277/499: loss=0.5518824855947745\n",
      "GD iter. 278/499: loss=0.5518472417534412\n",
      "GD iter. 279/499: loss=0.5517936407228652\n",
      "GD iter. 280/499: loss=0.5517486586692204\n",
      "GD iter. 281/499: loss=0.5516956103474064\n",
      "GD iter. 282/499: loss=0.5516528937459122\n",
      "GD iter. 283/499: loss=0.5516040036127199\n",
      "GD iter. 284/499: loss=0.551571424906357\n",
      "GD iter. 285/499: loss=0.5515340122148943\n",
      "GD iter. 286/499: loss=0.5514674464321926\n",
      "GD iter. 287/499: loss=0.5514295146741819\n",
      "GD iter. 288/499: loss=0.5513800146280972\n",
      "GD iter. 289/499: loss=0.551333644199298\n",
      "GD iter. 290/499: loss=0.5513048477180985\n",
      "GD iter. 291/499: loss=0.5512399476688552\n",
      "GD iter. 292/499: loss=0.5512047310984559\n",
      "GD iter. 293/499: loss=0.5511448062560315\n",
      "GD iter. 294/499: loss=0.551105191136796\n",
      "GD iter. 295/499: loss=0.5510655795812782\n",
      "GD iter. 296/499: loss=0.5510422124034201\n",
      "GD iter. 297/499: loss=0.5509724474694041\n",
      "GD iter. 298/499: loss=0.5509375919555355\n",
      "GD iter. 299/499: loss=0.5508939602372062\n",
      "GD iter. 300/499: loss=0.5508591765017161\n",
      "GD iter. 301/499: loss=0.5508178045082195\n",
      "GD iter. 302/499: loss=0.55077022983483\n",
      "GD iter. 303/499: loss=0.5507244340487639\n",
      "GD iter. 304/499: loss=0.550685347424584\n",
      "GD iter. 305/499: loss=0.5506540379018723\n",
      "GD iter. 306/499: loss=0.5506384351509023\n",
      "GD iter. 307/499: loss=0.5505611201005163\n",
      "GD iter. 308/499: loss=0.550527419850481\n",
      "GD iter. 309/499: loss=0.5505056311562707\n",
      "GD iter. 310/499: loss=0.5504437361439593\n",
      "GD iter. 311/499: loss=0.5504062227302161\n",
      "GD iter. 312/499: loss=0.5503788620164213\n",
      "GD iter. 313/499: loss=0.550331227123148\n",
      "GD iter. 314/499: loss=0.5503330890489264\n",
      "GD iter. 315/499: loss=0.5502522348261624\n",
      "GD iter. 316/499: loss=0.5502163355547242\n",
      "GD iter. 317/499: loss=0.5501797585620921\n",
      "GD iter. 318/499: loss=0.5501266579321664\n",
      "GD iter. 319/499: loss=0.5501129275399319\n",
      "GD iter. 320/499: loss=0.5500505850815499\n",
      "GD iter. 321/499: loss=0.5500275420914285\n",
      "GD iter. 322/499: loss=0.54999627010777\n",
      "GD iter. 323/499: loss=0.5499468731154549\n",
      "GD iter. 324/499: loss=0.5499119125972809\n",
      "GD iter. 325/499: loss=0.549877212272981\n",
      "GD iter. 326/499: loss=0.5498471513827657\n",
      "GD iter. 327/499: loss=0.5498088680383079\n",
      "GD iter. 328/499: loss=0.5497756426654782\n",
      "GD iter. 329/499: loss=0.5497618182056088\n",
      "GD iter. 330/499: loss=0.5497051674261656\n",
      "GD iter. 331/499: loss=0.5496882237000145\n",
      "GD iter. 332/499: loss=0.5496356554445535\n",
      "GD iter. 333/499: loss=0.5496154191512146\n",
      "GD iter. 334/499: loss=0.5495788278725311\n",
      "GD iter. 335/499: loss=0.5495517906625922\n",
      "GD iter. 336/499: loss=0.5494991204064942\n",
      "GD iter. 337/499: loss=0.5494882272477248\n",
      "GD iter. 338/499: loss=0.5494453315734412\n",
      "GD iter. 339/499: loss=0.5494074980875299\n",
      "GD iter. 340/499: loss=0.5493867822172329\n",
      "GD iter. 341/499: loss=0.5493615660122766\n",
      "GD iter. 342/499: loss=0.5493179659114134\n",
      "GD iter. 343/499: loss=0.5492970461520474\n",
      "GD iter. 344/499: loss=0.5492592477741609\n",
      "GD iter. 345/499: loss=0.5492305237328601\n",
      "GD iter. 346/499: loss=0.5492242980719859\n",
      "GD iter. 347/499: loss=0.54919130198628\n",
      "GD iter. 348/499: loss=0.5491492261215065\n",
      "GD iter. 349/499: loss=0.549108465919363\n",
      "GD iter. 350/499: loss=0.549076778097985\n",
      "GD iter. 351/499: loss=0.5490589350641836\n",
      "GD iter. 352/499: loss=0.5490372159535566\n",
      "GD iter. 353/499: loss=0.548982645287002\n",
      "GD iter. 354/499: loss=0.5489647982935486\n",
      "GD iter. 355/499: loss=0.5489560253796902\n",
      "GD iter. 356/499: loss=0.5489472453503751\n",
      "GD iter. 357/499: loss=0.5488840501253224\n",
      "GD iter. 358/499: loss=0.5488553951063216\n",
      "GD iter. 359/499: loss=0.5488259504609307\n",
      "GD iter. 360/499: loss=0.5488077904402169\n",
      "GD iter. 361/499: loss=0.5487654198954862\n",
      "GD iter. 362/499: loss=0.5487510873942021\n",
      "GD iter. 363/499: loss=0.54871875111633\n",
      "GD iter. 364/499: loss=0.5486858907193227\n",
      "GD iter. 365/499: loss=0.548654238919158\n",
      "GD iter. 366/499: loss=0.5486470811217276\n",
      "GD iter. 367/499: loss=0.5485962181132576\n",
      "GD iter. 368/499: loss=0.548572111901221\n",
      "GD iter. 369/499: loss=0.5485429835497935\n",
      "GD iter. 370/499: loss=0.5485425340249925\n",
      "GD iter. 371/499: loss=0.5484920620562737\n",
      "GD iter. 372/499: loss=0.5484890896828597\n",
      "GD iter. 373/499: loss=0.5484619012301094\n",
      "GD iter. 374/499: loss=0.5484397053439055\n",
      "GD iter. 375/499: loss=0.5483848116028429\n",
      "GD iter. 376/499: loss=0.5483742376486096\n",
      "GD iter. 377/499: loss=0.5483412483179679\n",
      "GD iter. 378/499: loss=0.5483300706122245\n",
      "GD iter. 379/499: loss=0.5482806123780355\n",
      "GD iter. 380/499: loss=0.5482539120986456\n",
      "GD iter. 381/499: loss=0.5482280311042688\n",
      "GD iter. 382/499: loss=0.5482146806502581\n",
      "GD iter. 383/499: loss=0.5481924657957394\n",
      "GD iter. 384/499: loss=0.5481675385970937\n",
      "GD iter. 385/499: loss=0.5481276478559155\n",
      "GD iter. 386/499: loss=0.54811119821967\n",
      "GD iter. 387/499: loss=0.5480953807654186\n",
      "GD iter. 388/499: loss=0.5480605652101221\n",
      "GD iter. 389/499: loss=0.54803880007974\n",
      "GD iter. 390/499: loss=0.5480040961585348\n",
      "GD iter. 391/499: loss=0.5479818592446817\n",
      "GD iter. 392/499: loss=0.5479716214749405\n",
      "GD iter. 393/499: loss=0.5479620449877147\n",
      "GD iter. 394/499: loss=0.547909995223205\n",
      "GD iter. 395/499: loss=0.5478790955312223\n",
      "GD iter. 396/499: loss=0.5478543107699547\n",
      "GD iter. 397/499: loss=0.5478479489012935\n",
      "GD iter. 398/499: loss=0.5478106586380362\n",
      "GD iter. 399/499: loss=0.5477861458802427\n",
      "GD iter. 400/499: loss=0.5477951098216512\n",
      "GD iter. 401/499: loss=0.5477488680461103\n",
      "GD iter. 402/499: loss=0.5477040290827693\n",
      "GD iter. 403/499: loss=0.5476931198640691\n",
      "GD iter. 404/499: loss=0.5476893102517371\n",
      "GD iter. 405/499: loss=0.547637965883721\n",
      "GD iter. 406/499: loss=0.54761687535278\n",
      "GD iter. 407/499: loss=0.547591016241901\n",
      "GD iter. 408/499: loss=0.54757302620201\n",
      "GD iter. 409/499: loss=0.5475442392629198\n",
      "GD iter. 410/499: loss=0.547541726198024\n",
      "GD iter. 411/499: loss=0.5475052568373513\n",
      "GD iter. 412/499: loss=0.5474650522321072\n",
      "GD iter. 413/499: loss=0.5474809818197655\n",
      "GD iter. 414/499: loss=0.5474371326816075\n",
      "GD iter. 415/499: loss=0.5474131459238816\n",
      "GD iter. 416/499: loss=0.5473867147794397\n",
      "GD iter. 417/499: loss=0.5473528281403528\n",
      "GD iter. 418/499: loss=0.5473294452324066\n",
      "GD iter. 419/499: loss=0.5473123259456049\n",
      "GD iter. 420/499: loss=0.5472856445627946\n",
      "GD iter. 421/499: loss=0.5472669255696945\n",
      "GD iter. 422/499: loss=0.5472398556837935\n",
      "GD iter. 423/499: loss=0.5472288266749367\n",
      "GD iter. 424/499: loss=0.5471993435252821\n",
      "GD iter. 425/499: loss=0.5471968349590999\n",
      "GD iter. 426/499: loss=0.5471478861843574\n",
      "GD iter. 427/499: loss=0.5471291019237449\n",
      "GD iter. 428/499: loss=0.5471016070169584\n",
      "GD iter. 429/499: loss=0.5470861396509802\n",
      "GD iter. 430/499: loss=0.5470641165625969\n",
      "GD iter. 431/499: loss=0.5470620565546702\n",
      "GD iter. 432/499: loss=0.5470154703000155\n",
      "GD iter. 433/499: loss=0.5470050724633558\n",
      "GD iter. 434/499: loss=0.5469648268069605\n",
      "GD iter. 435/499: loss=0.5469655865532091\n",
      "GD iter. 436/499: loss=0.5469517136065452\n",
      "GD iter. 437/499: loss=0.5469177184936497\n",
      "GD iter. 438/499: loss=0.5468831928245605\n",
      "GD iter. 439/499: loss=0.5468453617207203\n",
      "GD iter. 440/499: loss=0.546834814906066\n",
      "GD iter. 441/499: loss=0.546813831294781\n",
      "GD iter. 442/499: loss=0.5467917611788637\n",
      "GD iter. 443/499: loss=0.546760777574558\n",
      "GD iter. 444/499: loss=0.546776200550223\n",
      "GD iter. 445/499: loss=0.5467401674670587\n",
      "GD iter. 446/499: loss=0.5467129066741245\n",
      "GD iter. 447/499: loss=0.5466874010704952\n",
      "GD iter. 448/499: loss=0.5466696689619337\n",
      "GD iter. 449/499: loss=0.5466632239542288\n",
      "GD iter. 450/499: loss=0.5466261820365903\n",
      "GD iter. 451/499: loss=0.5466122952972975\n",
      "GD iter. 452/499: loss=0.5465710987869876\n",
      "GD iter. 453/499: loss=0.5465813554186274\n",
      "GD iter. 454/499: loss=0.5465635736555176\n",
      "GD iter. 455/499: loss=0.5465426852463845\n",
      "GD iter. 456/499: loss=0.5465129765989769\n",
      "GD iter. 457/499: loss=0.546488572141385\n",
      "GD iter. 458/499: loss=0.5464758134182701\n",
      "GD iter. 459/499: loss=0.5464461665729725\n",
      "GD iter. 460/499: loss=0.5464328306926539\n",
      "GD iter. 461/499: loss=0.5464012814994993\n",
      "GD iter. 462/499: loss=0.5463956282486386\n",
      "GD iter. 463/499: loss=0.5463592287630535\n",
      "GD iter. 464/499: loss=0.5463336348158502\n",
      "GD iter. 465/499: loss=0.5463157796525456\n",
      "GD iter. 466/499: loss=0.5463134166445208\n",
      "GD iter. 467/499: loss=0.5462938772510898\n",
      "GD iter. 468/499: loss=0.5462882083799833\n",
      "GD iter. 469/499: loss=0.5462546403202125\n",
      "GD iter. 470/499: loss=0.546217541091858\n",
      "GD iter. 471/499: loss=0.546202879142033\n",
      "GD iter. 472/499: loss=0.546206168483301\n",
      "GD iter. 473/499: loss=0.5461851017974502\n",
      "GD iter. 474/499: loss=0.5461570175881522\n",
      "GD iter. 475/499: loss=0.5461211799297524\n",
      "GD iter. 476/499: loss=0.5461174398775722\n",
      "GD iter. 477/499: loss=0.5461155352290139\n",
      "GD iter. 478/499: loss=0.5460860658707399\n",
      "GD iter. 479/499: loss=0.5460547148673988\n",
      "GD iter. 480/499: loss=0.5460403864391699\n",
      "GD iter. 481/499: loss=0.5460355706825142\n",
      "GD iter. 482/499: loss=0.5460110281988153\n",
      "GD iter. 483/499: loss=0.5459794031134215\n",
      "GD iter. 484/499: loss=0.5459924726588207\n",
      "GD iter. 485/499: loss=0.5459726316895145\n",
      "GD iter. 486/499: loss=0.5459349083648138\n",
      "GD iter. 487/499: loss=0.5458948341881814\n",
      "GD iter. 488/499: loss=0.5458907695326667\n",
      "GD iter. 489/499: loss=0.5458769300041335\n",
      "GD iter. 490/499: loss=0.5458517031329077\n",
      "GD iter. 491/499: loss=0.5458305368153206\n",
      "GD iter. 492/499: loss=0.5458373226015439\n",
      "GD iter. 493/499: loss=0.5458219445987909\n",
      "GD iter. 494/499: loss=0.5457851410557061\n",
      "GD iter. 495/499: loss=0.5457601441202341\n",
      "GD iter. 496/499: loss=0.5457452074265443\n",
      "GD iter. 497/499: loss=0.545762382772265\n",
      "GD iter. 498/499: loss=0.5457357476181868\n",
      "GD iter. 499/499: loss=0.5456997641168269\n",
      "The Accuracy is: 0.6492\n",
      "The F1 score is: 0.2357\n",
      "The precision is: 0.1381\n",
      "The recall is: 0.8049\n",
      "Final accuracy score is:  0.6788524590163935\n",
      "Final f1 score is:  0.31404260428315733\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "f1 = []\n",
    "for i in range(10):\n",
    "    x_t, y_t, x_v, y_v = split_data(x_train_processed, y_train_processed, 0.9)\n",
    "    x_t, y_t = data_augmentation(x_t, y_t)\n",
    "    initial_w = np.random.randn(x_t.shape[1]) * 0.01\n",
    "    w, loss = hinge_regression(y_t, x_t, initial_w, lambda_=0.1, max_iters=500, gamma=0.01)\n",
    "    y_pred = ((x_v @ w) > 0.5).astype(int)\n",
    "    accs.append(predict_acc_pure(y_pred, y_v))\n",
    "    f1.append(predict_f1_pure(y_pred, y_v))\n",
    "print(\"Final accuracy score is: \", np.mean(accs))\n",
    "print(\"Final f1 score is: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/ivonne/ML_proj/project1/data_glance.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ivonne/ML_proj/project1/data_glance.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msvm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msvm\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ivonne/ML_proj/project1/data_glance.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC(C\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ivonne/ML_proj/project1/data_glance.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m x_t, y_t, x_v, y_v \u001b[39m=\u001b[39m split_data(x_train_processed_hinge, y_train_processed_hinge, \u001b[39m0.9\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sklearn.svm as svm\n",
    "cls = svm.SVC(C=50, kernel='rbf')\n",
    "x_t, y_t, x_v, y_v = split_data(x_train_processed_hinge, y_train_processed_hinge, 0.9)\n",
    "cls.fit(x_t, y_t)\n",
    "y_pred = cls.predict(x_v)\n",
    "predict_acc_pure(y_pred, y_v)\n",
    "predict_f1_pure(y_pred, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/499: loss=(0.0635121239387749+0j)\n",
      "GD iter. 10/499: loss=(0.03499360164250566+0j)\n",
      "GD iter. 20/499: loss=(0.032219675441975+0j)\n",
      "GD iter. 30/499: loss=(0.03140766729669545+0j)\n",
      "GD iter. 40/499: loss=(0.031123605529602+0j)\n",
      "GD iter. 50/499: loss=(0.031015348713709905+0j)\n",
      "GD iter. 60/499: loss=(0.030971639066752436+0j)\n",
      "GD iter. 70/499: loss=(0.030953165467271105+0j)\n",
      "GD iter. 80/499: loss=(0.030945049333066486+0j)\n",
      "GD iter. 90/499: loss=(0.03094136228476214+0j)\n",
      "GD iter. 100/499: loss=(0.03093963843538125+0j)\n",
      "GD iter. 110/499: loss=(0.030938812584707584+0j)\n",
      "GD iter. 120/499: loss=(0.03093840882467128+0j)\n",
      "GD iter. 130/499: loss=(0.03093820810333348+0j)\n",
      "GD iter. 140/499: loss=(0.030938106954342837+0j)\n",
      "GD iter. 150/499: loss=(0.030938055419327343+0j)\n",
      "GD iter. 160/499: loss=(0.030938028928111847+0j)\n",
      "GD iter. 170/499: loss=(0.03093801521202983+0j)\n",
      "GD iter. 180/499: loss=(0.030938008068529962+0j)\n",
      "GD iter. 190/499: loss=(0.030938004330064186+0j)\n",
      "GD iter. 200/499: loss=(0.030938002365689204+0j)\n",
      "GD iter. 210/499: loss=(0.030938001330002997+0j)\n",
      "GD iter. 220/499: loss=(0.030938000782371224+0j)\n",
      "GD iter. 230/499: loss=(0.030938000492078857+0j)\n",
      "GD iter. 240/499: loss=(0.030938000337861014+0j)\n",
      "GD iter. 250/499: loss=(0.030938000255773188+0j)\n",
      "GD iter. 260/499: loss=(0.03093800021200256+0j)\n",
      "GD iter. 270/499: loss=(0.03093800018862613+0j)\n",
      "GD iter. 280/499: loss=(0.030938000176123245+0j)\n",
      "GD iter. 290/499: loss=(0.030938000169426938+0j)\n",
      "GD iter. 300/499: loss=(0.030938000165835918+0j)\n",
      "GD iter. 310/499: loss=(0.030938000163907815+0j)\n",
      "GD iter. 320/499: loss=(0.030938000162871352+0j)\n",
      "GD iter. 330/499: loss=(0.03093800016231357+0j)\n",
      "GD iter. 340/499: loss=(0.03093800016201306+0j)\n",
      "GD iter. 350/499: loss=(0.03093800016185098+0j)\n",
      "GD iter. 360/499: loss=(0.030938000161763464+0j)\n",
      "GD iter. 370/499: loss=(0.03093800016171617+0j)\n",
      "GD iter. 380/499: loss=(0.030938000161690574+0j)\n",
      "GD iter. 390/499: loss=(0.030938000161676707+0j)\n",
      "GD iter. 400/499: loss=(0.030938000161669185+0j)\n",
      "GD iter. 410/499: loss=(0.030938000161665112+0j)\n",
      "GD iter. 420/499: loss=(0.030938000161662888+0j)\n",
      "GD iter. 430/499: loss=(0.03093800016166168+0j)\n",
      "GD iter. 440/499: loss=(0.03093800016166103+0j)\n",
      "GD iter. 450/499: loss=(0.030938000161660664+0j)\n",
      "GD iter. 460/499: loss=(0.030938000161660466+0j)\n",
      "GD iter. 470/499: loss=(0.030938000161660362+0j)\n",
      "GD iter. 480/499: loss=(0.0309380001616603+0j)\n",
      "GD iter. 490/499: loss=(0.03093800016166027+0j)\n",
      "The Accuracy is: 0.6672\n",
      "The F1 score is: 0.3596\n",
      "The precision is: 0.2262\n",
      "The recall is: 0.8769\n"
     ]
    }
   ],
   "source": [
    "## linear regression using PCA feature selection ##\n",
    "x_pca_t = add_bias(x_pca)\n",
    "x_t, y_t, x_v, y_v = split_data(x_pca_t, y_train_processed, 0.9)\n",
    "# x_t, y_t = data_augmentation(x_t, y_t)\n",
    "initial_w = np.random.randn(x_pca_t.shape[1]) * 0.01\n",
    "w, loss = mean_square_error_gd(y_t, x_t, initial_w, max_iters = 500, gamma=0.05)\n",
    "y_pred = x_v @ w\n",
    "y_pred_mean = np.mean(y_pred)\n",
    "y_pred = (y_pred >= y_pred_mean).astype(int)\n",
    "predict_acc_pure(y_pred, y_v)\n",
    "predict_f1_pure(y_pred, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/499: loss=(0.7234766967337769-0j)\n",
      "GD iter. 1/499: loss=(0.5451834908591477-0j)\n",
      "GD iter. 2/499: loss=(0.5331040872150704-0j)\n",
      "GD iter. 3/499: loss=(0.5245318812979132-0j)\n",
      "GD iter. 4/499: loss=(0.5178091084500906-0j)\n",
      "GD iter. 5/499: loss=(0.5122486033535671-0j)\n",
      "GD iter. 6/499: loss=(0.5074821286021316-0j)\n",
      "GD iter. 7/499: loss=(0.503287997796-0j)\n",
      "GD iter. 8/499: loss=(0.49952450604815485-0j)\n",
      "GD iter. 9/499: loss=(0.49609732064821677-0j)\n",
      "GD iter. 10/499: loss=(0.49294145895859404-0j)\n",
      "GD iter. 11/499: loss=(0.490010707989586-0j)\n",
      "GD iter. 12/499: loss=(0.4872711863187253-0j)\n",
      "GD iter. 13/499: loss=(0.48469732175691993-0j)\n",
      "GD iter. 14/499: loss=(0.4822692806145236-0j)\n",
      "GD iter. 15/499: loss=(0.4799712896441396-0j)\n",
      "GD iter. 16/499: loss=(0.47779051811692536-0j)\n",
      "GD iter. 17/499: loss=(0.4757163179741322-0j)\n",
      "GD iter. 18/499: loss=(0.47373969698073787-0j)\n",
      "GD iter. 19/499: loss=(0.4718529461275023-0j)\n",
      "GD iter. 20/499: loss=(0.47004937088923326-0j)\n",
      "GD iter. 21/499: loss=(0.4683230935948921-0j)\n",
      "GD iter. 22/499: loss=(0.46666890531300387-0j)\n",
      "GD iter. 23/499: loss=(0.46508215279855725-0j)\n",
      "GD iter. 24/499: loss=(0.46355865068670526-0j)\n",
      "GD iter. 25/499: loss=(0.4620946121714609-0j)\n",
      "GD iter. 26/499: loss=(0.4606865934425761-0j)\n",
      "GD iter. 27/499: loss=(0.45933144852763663-0j)\n",
      "GD iter. 28/499: loss=(0.458026292125721-0j)\n",
      "GD iter. 29/499: loss=(0.4567684686694739-0j)\n",
      "GD iter. 30/499: loss=(0.4555555263087357-0j)\n",
      "GD iter. 31/499: loss=(0.45438519483316697-0j)\n",
      "GD iter. 32/499: loss=(0.4532553667847975-0j)\n",
      "GD iter. 33/499: loss=(0.4521640811818034-0j)\n",
      "GD iter. 34/499: loss=(0.451109509400748-0j)\n",
      "GD iter. 35/499: loss=(0.450089942858834-0j)\n",
      "GD iter. 36/499: loss=(0.44910378220923874-0j)\n",
      "GD iter. 37/499: loss=(0.44814952781751444-0j)\n",
      "GD iter. 38/499: loss=(0.4472257713296829-0j)\n",
      "GD iter. 39/499: loss=(0.44633118817615275-0j)\n",
      "GD iter. 40/499: loss=(0.44546453088216537-0j)\n",
      "GD iter. 41/499: loss=(0.44462462307677253-0j)\n",
      "GD iter. 42/499: loss=(0.4438103541095611-0j)\n",
      "GD iter. 43/499: loss=(0.4430206741983729-0j)\n",
      "GD iter. 44/499: loss=(0.4422545900427793-0j)\n",
      "GD iter. 45/499: loss=(0.44151116084759773-0j)\n",
      "GD iter. 46/499: loss=(0.44078949470864953-0j)\n",
      "GD iter. 47/499: loss=(0.44008874531958686-0j)\n",
      "GD iter. 48/499: loss=(0.43940810896418014-0j)\n",
      "GD iter. 49/499: loss=(0.43874682176316715-0j)\n",
      "GD iter. 50/499: loss=(0.43810415714874834-0j)\n",
      "GD iter. 51/499: loss=(0.4374794235432184-0j)\n",
      "GD iter. 52/499: loss=(0.43687196222112684-0j)\n",
      "GD iter. 53/499: loss=(0.43628114533685497-0j)\n",
      "GD iter. 54/499: loss=(0.43570637410164453-0j)\n",
      "GD iter. 55/499: loss=(0.43514707709596356-0j)\n",
      "GD iter. 56/499: loss=(0.4346027087047048-0j)\n",
      "GD iter. 57/499: loss=(0.43407274766410325-0j)\n",
      "GD iter. 58/499: loss=(0.43355669571047395-0j)\n",
      "GD iter. 59/499: loss=(0.4330540763219339-0j)\n",
      "GD iter. 60/499: loss=(0.4325644335451975-0j)\n",
      "GD iter. 61/499: loss=(0.4320873309003518-0j)\n",
      "GD iter. 62/499: loss=(0.43162235035723207-0j)\n",
      "GD iter. 63/499: loss=(0.4311690913776551-0j)\n",
      "GD iter. 64/499: loss=(0.4307271700183176-0j)\n",
      "GD iter. 65/499: loss=(0.43029621808967305-0j)\n",
      "GD iter. 66/499: loss=(0.42987588236653-0j)\n",
      "GD iter. 67/499: loss=(0.4294658238465095-0j)\n",
      "GD iter. 68/499: loss=(0.42906571705285007-0j)\n",
      "GD iter. 69/499: loss=(0.42867524937835483-0j)\n",
      "GD iter. 70/499: loss=(0.4282941204675585-0j)\n",
      "GD iter. 71/499: loss=(0.42792204163443875-0j)\n",
      "GD iter. 72/499: loss=(0.42755873531322425-0j)\n",
      "GD iter. 73/499: loss=(0.42720393454005084-0j)\n",
      "GD iter. 74/499: loss=(0.42685738246340116-0j)\n",
      "GD iter. 75/499: loss=(0.42651883188142986-0j)\n",
      "GD iter. 76/499: loss=(0.426188044804422-0j)\n",
      "GD iter. 77/499: loss=(0.42586479204076993-0j)\n",
      "GD iter. 78/499: loss=(0.4255488528049791-0j)\n",
      "GD iter. 79/499: loss=(0.42524001434631903-0j)\n",
      "GD iter. 80/499: loss=(0.4249380715968459-0j)\n",
      "GD iter. 81/499: loss=(0.4246428268376075-0j)\n",
      "GD iter. 82/499: loss=(0.4243540893819355-0j)\n",
      "GD iter. 83/499: loss=(0.42407167527479867-0j)\n",
      "GD iter. 84/499: loss=(0.42379540700727225-0j)\n",
      "GD iter. 85/499: loss=(0.4235251132452329-0j)\n",
      "GD iter. 86/499: loss=(0.4232606285714597-0j)\n",
      "GD iter. 87/499: loss=(0.4230017932403704-0j)\n",
      "GD iter. 88/499: loss=(0.4227484529446755-0j)\n",
      "GD iter. 89/499: loss=(0.4225004585932787-0j)\n",
      "GD iter. 90/499: loss=(0.4222576660997993-0j)\n",
      "GD iter. 91/499: loss=(0.422019936181127-0j)\n",
      "GD iter. 92/499: loss=(0.4217871341654624-0j)\n",
      "GD iter. 93/499: loss=(0.4215591298093265-0j)\n",
      "GD iter. 94/499: loss=(0.4213357971230577-0j)\n",
      "GD iter. 95/499: loss=(0.421117014204342-0j)\n",
      "GD iter. 96/499: loss=(0.42090266307935426-0j)\n",
      "GD iter. 97/499: loss=(0.4206926295511061-0j)\n",
      "GD iter. 98/499: loss=(0.42048680305462927-0j)\n",
      "GD iter. 99/499: loss=(0.42028507651863894-0j)\n",
      "GD iter. 100/499: loss=(0.42008734623334476-0j)\n",
      "GD iter. 101/499: loss=(0.4198935117240966-0j)\n",
      "GD iter. 102/499: loss=(0.4197034756305703-0j)\n",
      "GD iter. 103/499: loss=(0.4195171435912147-0j)\n",
      "GD iter. 104/499: loss=(0.4193344241326984-0j)\n",
      "GD iter. 105/499: loss=(0.41915522856410825-0j)\n",
      "GD iter. 106/499: loss=(0.4189794708756658-0j)\n",
      "GD iter. 107/499: loss=(0.41880706764174225-0j)\n",
      "GD iter. 108/499: loss=(0.4186379379279623-0j)\n",
      "GD iter. 109/499: loss=(0.4184720032021999-0j)\n",
      "GD iter. 110/499: loss=(0.41830918724928057-0j)\n",
      "GD iter. 111/499: loss=(0.41814941608921297-0j)\n",
      "GD iter. 112/499: loss=(0.4179926178987839-0j)\n",
      "GD iter. 113/499: loss=(0.41783872293635743-0j)\n",
      "GD iter. 114/499: loss=(0.4176876634697304-0j)\n",
      "GD iter. 115/499: loss=(0.41753937370690114-0j)\n",
      "GD iter. 116/499: loss=(0.41739378972961794-0j)\n",
      "GD iter. 117/499: loss=(0.4172508494295791-0j)\n",
      "GD iter. 118/499: loss=(0.41711049244716447-0j)\n",
      "GD iter. 119/499: loss=(0.41697266011258444-0j)\n",
      "GD iter. 120/499: loss=(0.4168372953893355-0j)\n",
      "GD iter. 121/499: loss=(0.4167043428198619-0j)\n",
      "GD iter. 122/499: loss=(0.4165737484733225-0j)\n",
      "GD iter. 123/499: loss=(0.41644545989537274-0j)\n",
      "GD iter. 124/499: loss=(0.4163194260598695-0j)\n",
      "GD iter. 125/499: loss=(0.4161955973224185-0j)\n",
      "GD iter. 126/499: loss=(0.4160739253756816-0j)\n",
      "GD iter. 127/499: loss=(0.41595436320636814-0j)\n",
      "GD iter. 128/499: loss=(0.41583686505383943-0j)\n",
      "GD iter. 129/499: loss=(0.41572138637025585-0j)\n",
      "GD iter. 130/499: loss=(0.41560788378220137-0j)\n",
      "GD iter. 131/499: loss=(0.41549631505372336-0j)\n",
      "GD iter. 132/499: loss=(0.4153866390507282-0j)\n",
      "GD iter. 133/499: loss=(0.41527881570667496-0j)\n",
      "GD iter. 134/499: loss=(0.4151728059895141-0j)\n",
      "GD iter. 135/499: loss=(0.4150685718698202-0j)\n",
      "GD iter. 136/499: loss=(0.4149660762900672-0j)\n",
      "GD iter. 137/499: loss=(0.4148652831350019-0j)\n",
      "GD iter. 138/499: loss=(0.41476615720307025-0j)\n",
      "GD iter. 139/499: loss=(0.41466866417885195-0j)\n",
      "GD iter. 140/499: loss=(0.41457277060646597-0j)\n",
      "GD iter. 141/499: loss=(0.4144784438639046-0j)\n",
      "GD iter. 142/499: loss=(0.414385652138262-0j)\n",
      "GD iter. 143/499: loss=(0.41429436440181905-0j)\n",
      "GD iter. 144/499: loss=(0.4142045503889529-0j)\n",
      "GD iter. 145/499: loss=(0.4141161805738373-0j)\n",
      "GD iter. 146/499: loss=(0.4140292261489035-0j)\n",
      "GD iter. 147/499: loss=(0.41394365900403157-0j)\n",
      "GD iter. 148/499: loss=(0.4138594517064446-0j)\n",
      "GD iter. 149/499: loss=(0.41377657748127805-0j)\n",
      "GD iter. 150/499: loss=(0.41369501019279864-0j)\n",
      "GD iter. 151/499: loss=(0.4136147243262476-0j)\n",
      "GD iter. 152/499: loss=(0.4135356949702854-0j)\n",
      "GD iter. 153/499: loss=(0.41345789780001446-0j)\n",
      "GD iter. 154/499: loss=(0.41338130906055814-0j)\n",
      "GD iter. 155/499: loss=(0.4133059055511757-0j)\n",
      "GD iter. 156/499: loss=(0.4132316646098928-0j)\n",
      "GD iter. 157/499: loss=(0.41315856409862883-0j)\n",
      "GD iter. 158/499: loss=(0.41308658238880147-0j)\n",
      "GD iter. 159/499: loss=(0.41301569834739404-0j)\n",
      "GD iter. 160/499: loss=(0.41294589132346404-0j)\n",
      "GD iter. 161/499: loss=(0.41287714113508167-0j)\n",
      "GD iter. 162/499: loss=(0.41280942805667914-0j)\n",
      "GD iter. 163/499: loss=(0.4127427328067979-0j)\n",
      "GD iter. 164/499: loss=(0.4126770365362188-0j)\n",
      "GD iter. 165/499: loss=(0.41261232081646176-0j)\n",
      "GD iter. 166/499: loss=(0.41254856762864156-0j)\n",
      "GD iter. 167/499: loss=(0.4124857593526674-0j)\n",
      "GD iter. 168/499: loss=(0.412423878756774-0j)\n",
      "GD iter. 169/499: loss=(0.41236290898737227-0j)\n",
      "GD iter. 170/499: loss=(0.41230283355920994-0j)\n",
      "GD iter. 171/499: loss=(0.412243636345828-0j)\n",
      "GD iter. 172/499: loss=(0.4121853015703074-0j)\n",
      "GD iter. 173/499: loss=(0.4121278137962917-0j)\n",
      "GD iter. 174/499: loss=(0.4120711579192786-0j)\n",
      "GD iter. 175/499: loss=(0.4120153191581708-0j)\n",
      "GD iter. 176/499: loss=(0.4119602830470767-0j)\n",
      "GD iter. 177/499: loss=(0.4119060354273534-0j)\n",
      "GD iter. 178/499: loss=(0.41185256243988305-0j)\n",
      "GD iter. 179/499: loss=(0.41179985051757506-0j)\n",
      "GD iter. 180/499: loss=(0.41174788637808685-0j)\n",
      "GD iter. 181/499: loss=(0.41169665701675523-0j)\n",
      "GD iter. 182/499: loss=(0.4116461496997324-0j)\n",
      "GD iter. 183/499: loss=(0.41159635195731814-0j)\n",
      "GD iter. 184/499: loss=(0.4115472515774847-0j)\n",
      "GD iter. 185/499: loss=(0.4114988365995842-0j)\n",
      "GD iter. 186/499: loss=(0.4114510953082361-0j)\n",
      "GD iter. 187/499: loss=(0.41140401622738676-0j)\n",
      "GD iter. 188/499: loss=(0.41135758811453654-0j)\n",
      "GD iter. 189/499: loss=(0.4113117999551283-0j)\n",
      "GD iter. 190/499: loss=(0.41126664095709325-0j)\n",
      "GD iter. 191/499: loss=(0.41122210054554736-0j)\n",
      "GD iter. 192/499: loss=(0.41117816835763593-0j)\n",
      "GD iter. 193/499: loss=(0.41113483423751956-0j)\n",
      "GD iter. 194/499: loss=(0.4110920882314976-0j)\n",
      "GD iter. 195/499: loss=(0.4110499205832658-0j)\n",
      "GD iter. 196/499: loss=(0.4110083217293021-0j)\n",
      "GD iter. 197/499: loss=(0.4109672822943793-0j)\n",
      "GD iter. 198/499: loss=(0.41092679308719693-0j)\n",
      "GD iter. 199/499: loss=(0.41088684509613244-0j)\n",
      "GD iter. 200/499: loss=(0.41084742948510533-0j)\n",
      "GD iter. 201/499: loss=(0.4108085375895523-0j)\n",
      "GD iter. 202/499: loss=(0.4107701609125094-0j)\n",
      "GD iter. 203/499: loss=(0.4107322911207974-0j)\n",
      "GD iter. 204/499: loss=(0.4106949200413091-0j)\n",
      "GD iter. 205/499: loss=(0.41065803965739295-0j)\n",
      "GD iter. 206/499: loss=(0.4106216421053324-0j)\n",
      "GD iter. 207/499: loss=(0.41058571967091667-0j)\n",
      "GD iter. 208/499: loss=(0.41055026478610096-0j)\n",
      "GD iter. 209/499: loss=(0.4105152700257527-0j)\n",
      "GD iter. 210/499: loss=(0.4104807281044824-0j)\n",
      "GD iter. 211/499: loss=(0.4104466318735552-0j)\n",
      "GD iter. 212/499: loss=(0.41041297431788243-0j)\n",
      "GD iter. 213/499: loss=(0.41037974855308945-0j)\n",
      "GD iter. 214/499: loss=(0.4103469478226574-0j)\n",
      "GD iter. 215/499: loss=(0.41031456549513873-0j)\n",
      "GD iter. 216/499: loss=(0.41028259506144216-0j)\n",
      "GD iter. 217/499: loss=(0.41025103013218533-0j)\n",
      "GD iter. 218/499: loss=(0.41021986443511527-0j)\n",
      "GD iter. 219/499: loss=(0.41018909181259205-0j)\n",
      "GD iter. 220/499: loss=(0.41015870621913536-0j)\n",
      "GD iter. 221/499: loss=(0.41012870171903193-0j)\n",
      "GD iter. 222/499: loss=(0.4100990724840021-0j)\n",
      "GD iter. 223/499: loss=(0.41006981279092397-0j)\n",
      "GD iter. 224/499: loss=(0.4100409170196119-0j)\n",
      "GD iter. 225/499: loss=(0.4100123796506523-0j)\n",
      "GD iter. 226/499: loss=(0.4099841952632889-0j)\n",
      "GD iter. 227/499: loss=(0.4099563585333611-0j)\n",
      "GD iter. 228/499: loss=(0.40992886423129166-0j)\n",
      "GD iter. 229/499: loss=(0.4099017072201233-0j)\n",
      "GD iter. 230/499: loss=(0.4098748824536018-0j)\n",
      "GD iter. 231/499: loss=(0.4098483849743049-0j)\n",
      "GD iter. 232/499: loss=(0.40982220991181706-0j)\n",
      "GD iter. 233/499: loss=(0.40979635248094565-0j)\n",
      "GD iter. 234/499: loss=(0.40977080797998106-0j)\n",
      "GD iter. 235/499: loss=(0.409745571788997-0j)\n",
      "GD iter. 236/499: loss=(0.409720639368191-0j)\n",
      "GD iter. 237/499: loss=(0.4096960062562636-0j)\n",
      "GD iter. 238/499: loss=(0.4096716680688361-0j)\n",
      "GD iter. 239/499: loss=(0.40964762049690373-0j)\n",
      "GD iter. 240/499: loss=(0.40962385930532663-0j)\n",
      "GD iter. 241/499: loss=(0.4096003803313539-0j)\n",
      "GD iter. 242/499: loss=(0.4095771794831829-0j)\n",
      "GD iter. 243/499: loss=(0.409554252738551-0j)\n",
      "GD iter. 244/499: loss=(0.40953159614336004-0j)\n",
      "GD iter. 245/499: loss=(0.40950920581033173-0j)\n",
      "GD iter. 246/499: loss=(0.40948707791769384-0j)\n",
      "GD iter. 247/499: loss=(0.40946520870789643-0j)\n",
      "GD iter. 248/499: loss=(0.40944359448635653-0j)\n",
      "GD iter. 249/499: loss=(0.40942223162023167-0j)\n",
      "GD iter. 250/499: loss=(0.4094011165372207-0j)\n",
      "GD iter. 251/499: loss=(0.4093802457243912-0j)\n",
      "GD iter. 252/499: loss=(0.40935961572703394-0j)\n",
      "GD iter. 253/499: loss=(0.40933922314754123-0j)\n",
      "GD iter. 254/499: loss=(0.40931906464431206-0j)\n",
      "GD iter. 255/499: loss=(0.40929913693068004-0j)\n",
      "GD iter. 256/499: loss=(0.40927943677386547-0j)\n",
      "GD iter. 257/499: loss=(0.40925996099395034-0j)\n",
      "GD iter. 258/499: loss=(0.4092407064628759-0j)\n",
      "GD iter. 259/499: loss=(0.4092216701034621-0j)\n",
      "GD iter. 260/499: loss=(0.4092028488884479-0j)\n",
      "GD iter. 261/499: loss=(0.4091842398395534-0j)\n",
      "GD iter. 262/499: loss=(0.4091658400265611-0j)\n",
      "GD iter. 263/499: loss=(0.40914764656641783-0j)\n",
      "GD iter. 264/499: loss=(0.40912965662235556-0j)\n",
      "GD iter. 265/499: loss=(0.4091118674030313-0j)\n",
      "GD iter. 266/499: loss=(0.40909427616168503-0j)\n",
      "GD iter. 267/499: loss=(0.4090768801953159-0j)\n",
      "GD iter. 268/499: loss=(0.40905967684387606-0j)\n",
      "GD iter. 269/499: loss=(0.4090426634894809-0j)\n",
      "GD iter. 270/499: loss=(0.40902583755563643-0j)\n",
      "GD iter. 271/499: loss=(0.4090091965064834-0j)\n",
      "GD iter. 272/499: loss=(0.40899273784605605-0j)\n",
      "GD iter. 273/499: loss=(0.4089764591175576-0j)\n",
      "GD iter. 274/499: loss=(0.4089603579026501-0j)\n",
      "GD iter. 275/499: loss=(0.40894443182075946-0j)\n",
      "GD iter. 276/499: loss=(0.40892867852839443-0j)\n",
      "GD iter. 277/499: loss=(0.4089130957184805-0j)\n",
      "GD iter. 278/499: loss=(0.4088976811197065-0j)\n",
      "GD iter. 279/499: loss=(0.4088824324958852-0j)\n",
      "GD iter. 280/499: loss=(0.4088673476453275-0j)\n",
      "GD iter. 281/499: loss=(0.40885242440022834-0j)\n",
      "GD iter. 282/499: loss=(0.4088376606260659-0j)\n",
      "GD iter. 283/499: loss=(0.4088230542210126-0j)\n",
      "GD iter. 284/499: loss=(0.4088086031153586-0j)\n",
      "GD iter. 285/499: loss=(0.40879430527094635-0j)\n",
      "GD iter. 286/499: loss=(0.4087801586806169-0j)\n",
      "GD iter. 287/499: loss=(0.4087661613676669-0j)\n",
      "GD iter. 288/499: loss=(0.40875231138531753-0j)\n",
      "GD iter. 289/499: loss=(0.40873860681619245-0j)\n",
      "GD iter. 290/499: loss=(0.4087250457718078-0j)\n",
      "GD iter. 291/499: loss=(0.40871162639207126-0j)\n",
      "GD iter. 292/499: loss=(0.4086983468447913-0j)\n",
      "GD iter. 293/499: loss=(0.40868520532519625-0j)\n",
      "GD iter. 294/499: loss=(0.4086722000554629-0j)\n",
      "GD iter. 295/499: loss=(0.4086593292842545-0j)\n",
      "GD iter. 296/499: loss=(0.408646591286267-0j)\n",
      "GD iter. 297/499: loss=(0.40863398436178544-0j)\n",
      "GD iter. 298/499: loss=(0.40862150683624754-0j)\n",
      "GD iter. 299/499: loss=(0.40860915705981765-0j)\n",
      "GD iter. 300/499: loss=(0.40859693340696684-0j)\n",
      "GD iter. 301/499: loss=(0.4085848342760629-0j)\n",
      "GD iter. 302/499: loss=(0.4085728580889669-0j)\n",
      "GD iter. 303/499: loss=(0.4085610032906388-0j)\n",
      "GD iter. 304/499: loss=(0.40854926834874944-0j)\n",
      "GD iter. 305/499: loss=(0.40853765175330087-0j)\n",
      "GD iter. 306/499: loss=(0.40852615201625314-0j)\n",
      "GD iter. 307/499: loss=(0.40851476767115913-0j)\n",
      "GD iter. 308/499: loss=(0.4085034972728051-0j)\n",
      "GD iter. 309/499: loss=(0.40849233939685975-0j)\n",
      "GD iter. 310/499: loss=(0.40848129263952804-0j)\n",
      "GD iter. 311/499: loss=(0.4084703556172126-0j)\n",
      "GD iter. 312/499: loss=(0.40845952696618193-0j)\n",
      "GD iter. 313/499: loss=(0.4084488053422433-0j)\n",
      "GD iter. 314/499: loss=(0.40843818942042354-0j)\n",
      "GD iter. 315/499: loss=(0.40842767789465423-0j)\n",
      "GD iter. 316/499: loss=(0.4084172694774642-0j)\n",
      "GD iter. 317/499: loss=(0.4084069628996764-0j)\n",
      "GD iter. 318/499: loss=(0.4083967569101111-0j)\n",
      "GD iter. 319/499: loss=(0.4083866502752949-0j)\n",
      "GD iter. 320/499: loss=(0.40837664177917415-0j)\n",
      "GD iter. 321/499: loss=(0.4083667302228345-0j)\n",
      "GD iter. 322/499: loss=(0.4083569144242249-0j)\n",
      "GD iter. 323/499: loss=(0.40834719321788754-0j)\n",
      "GD iter. 324/499: loss=(0.40833756545469185-0j)\n",
      "GD iter. 325/499: loss=(0.4083280300015737-0j)\n",
      "GD iter. 326/499: loss=(0.40831858574127916-0j)\n",
      "GD iter. 327/499: loss=(0.40830923157211363-0j)\n",
      "GD iter. 328/499: loss=(0.40829996640769434-0j)\n",
      "GD iter. 329/499: loss=(0.4082907891767082-0j)\n",
      "GD iter. 330/499: loss=(0.40828169882267357-0j)\n",
      "GD iter. 331/499: loss=(0.4082726943037069-0j)\n",
      "GD iter. 332/499: loss=(0.4082637745922923-0j)\n",
      "GD iter. 333/499: loss=(0.4082549386750568-0j)\n",
      "GD iter. 334/499: loss=(0.40824618555254855-0j)\n",
      "GD iter. 335/499: loss=(0.4082375142390191-0j)\n",
      "GD iter. 336/499: loss=(0.40822892376221-0j)\n",
      "GD iter. 337/499: loss=(0.4082204131631425-0j)\n",
      "GD iter. 338/499: loss=(0.40821198149591204-0j)\n",
      "GD iter. 339/499: loss=(0.4082036278274846-0j)\n",
      "GD iter. 340/499: loss=(0.40819535123749884-0j)\n",
      "GD iter. 341/499: loss=(0.40818715081806967-0j)\n",
      "GD iter. 342/499: loss=(0.4081790256735966-0j)\n",
      "GD iter. 343/499: loss=(0.40817097492057486-0j)\n",
      "GD iter. 344/499: loss=(0.40816299768741005-0j)\n",
      "GD iter. 345/499: loss=(0.40815509311423553-0j)\n",
      "GD iter. 346/499: loss=(0.4081472603527338-0j)\n",
      "GD iter. 347/499: loss=(0.40813949856596016-0j)\n",
      "GD iter. 348/499: loss=(0.40813180692816997-0j)\n",
      "GD iter. 349/499: loss=(0.40812418462464856-0j)\n",
      "GD iter. 350/499: loss=(0.4081166308515442-0j)\n",
      "GD iter. 351/499: loss=(0.40810914481570393-0j)\n",
      "GD iter. 352/499: loss=(0.4081017257345121-0j)\n",
      "GD iter. 353/499: loss=(0.4080943728357317-0j)\n",
      "GD iter. 354/499: loss=(0.4080870853573487-0j)\n",
      "GD iter. 355/499: loss=(0.4080798625474186-0j)\n",
      "GD iter. 356/499: loss=(0.4080727036639156-0j)\n",
      "GD iter. 357/499: loss=(0.4080656079745847-0j)\n",
      "GD iter. 358/499: loss=(0.4080585747567957-0j)\n",
      "GD iter. 359/499: loss=(0.40805160329740076-0j)\n",
      "GD iter. 360/499: loss=(0.40804469289259276-0j)\n",
      "GD iter. 361/499: loss=(0.40803784284776734-0j)\n",
      "GD iter. 362/499: loss=(0.408031052477387-0j)\n",
      "GD iter. 363/499: loss=(0.40802432110484677-0j)\n",
      "GD iter. 364/499: loss=(0.40801764806234275-0j)\n",
      "GD iter. 365/499: loss=(0.40801103269074307-0j)\n",
      "GD iter. 366/499: loss=(0.4080044743394604-0j)\n",
      "GD iter. 367/499: loss=(0.40799797236632646-0j)\n",
      "GD iter. 368/499: loss=(0.40799152613746936-0j)\n",
      "GD iter. 369/499: loss=(0.40798513502719264-0j)\n",
      "GD iter. 370/499: loss=(0.40797879841785567-0j)\n",
      "GD iter. 371/499: loss=(0.40797251569975707-0j)\n",
      "GD iter. 372/499: loss=(0.4079662862710193-0j)\n",
      "GD iter. 373/499: loss=(0.4079601095374752-0j)\n",
      "GD iter. 374/499: loss=(0.40795398491255686-0j)\n",
      "GD iter. 375/499: loss=(0.4079479118171858-0j)\n",
      "GD iter. 376/499: loss=(0.407941889679665-0j)\n",
      "GD iter. 377/499: loss=(0.4079359179355729-0j)\n",
      "GD iter. 378/499: loss=(0.40792999602765917-0j)\n",
      "GD iter. 379/499: loss=(0.4079241234057416-0j)\n",
      "GD iter. 380/499: loss=(0.40791829952660547-0j)\n",
      "GD iter. 381/499: loss=(0.407912523853904-0j)\n",
      "GD iter. 382/499: loss=(0.4079067958580601-0j)\n",
      "GD iter. 383/499: loss=(0.4079011150161708-0j)\n",
      "GD iter. 384/499: loss=(0.407895480811912-0j)\n",
      "GD iter. 385/499: loss=(0.4078898927354457-0j)\n",
      "GD iter. 386/499: loss=(0.4078843502833274-0j)\n",
      "GD iter. 387/499: loss=(0.4078788529584172-0j)\n",
      "GD iter. 388/499: loss=(0.4078734002697898-0j)\n",
      "GD iter. 389/499: loss=(0.40786799173264726-0j)\n",
      "GD iter. 390/499: loss=(0.4078626268682335-0j)\n",
      "GD iter. 391/499: loss=(0.4078573052037491-0j)\n",
      "GD iter. 392/499: loss=(0.40785202627226824-0j)\n",
      "GD iter. 393/499: loss=(0.4078467896126563-0j)\n",
      "GD iter. 394/499: loss=(0.4078415947694895-0j)\n",
      "GD iter. 395/499: loss=(0.40783644129297497-0j)\n",
      "GD iter. 396/499: loss=(0.40783132873887284-0j)\n",
      "GD iter. 397/499: loss=(0.40782625666841926-0j)\n",
      "GD iter. 398/499: loss=(0.40782122464824994-0j)\n",
      "GD iter. 399/499: loss=(0.4078162322503263-0j)\n",
      "GD iter. 400/499: loss=(0.40781127905186154-0j)\n",
      "GD iter. 401/499: loss=(0.4078063646352482-0j)\n",
      "GD iter. 402/499: loss=(0.40780148858798704-0j)\n",
      "GD iter. 403/499: loss=(0.40779665050261704-0j)\n",
      "GD iter. 404/499: loss=(0.407791849976646-0j)\n",
      "GD iter. 405/499: loss=(0.40778708661248275-0j)\n",
      "GD iter. 406/499: loss=(0.4077823600173701-0j)\n",
      "GD iter. 407/499: loss=(0.407777669803319-0j)\n",
      "GD iter. 408/499: loss=(0.4077730155870434-0j)\n",
      "GD iter. 409/499: loss=(0.40776839698989653-0j)\n",
      "GD iter. 410/499: loss=(0.4077638136378077-0j)\n",
      "GD iter. 411/499: loss=(0.40775926516122063-0j)\n",
      "GD iter. 412/499: loss=(0.4077547511950319-0j)\n",
      "GD iter. 413/499: loss=(0.4077502713785311-0j)\n",
      "GD iter. 414/499: loss=(0.40774582535534165-0j)\n",
      "GD iter. 415/499: loss=(0.4077414127733621-0j)\n",
      "GD iter. 416/499: loss=(0.4077370332847091-0j)\n",
      "GD iter. 417/499: loss=(0.40773268654566036-0j)\n",
      "GD iter. 418/499: loss=(0.40772837221659936-0j)\n",
      "GD iter. 419/499: loss=(0.4077240899619598-0j)\n",
      "GD iter. 420/499: loss=(0.40771983945017215-0j)\n",
      "GD iter. 421/499: loss=(0.40771562035360986-0j)\n",
      "GD iter. 422/499: loss=(0.4077114323485373-0j)\n",
      "GD iter. 423/499: loss=(0.40770727511505755-0j)\n",
      "GD iter. 424/499: loss=(0.4077031483370617-0j)\n",
      "GD iter. 425/499: loss=(0.4076990517021788-0j)\n",
      "GD iter. 426/499: loss=(0.40769498490172595-0j)\n",
      "GD iter. 427/499: loss=(0.40769094763066016-0j)\n",
      "GD iter. 428/499: loss=(0.4076869395875298-0j)\n",
      "GD iter. 429/499: loss=(0.4076829604744276-0j)\n",
      "GD iter. 430/499: loss=(0.4076790099969439-0j)\n",
      "GD iter. 431/499: loss=(0.40767508786412093-0j)\n",
      "GD iter. 432/499: loss=(0.4076711937884073-0j)\n",
      "GD iter. 433/499: loss=(0.4076673274856136-0j)\n",
      "GD iter. 434/499: loss=(0.4076634886748683-0j)\n",
      "GD iter. 435/499: loss=(0.4076596770785744-0j)\n",
      "GD iter. 436/499: loss=(0.40765589242236727-0j)\n",
      "GD iter. 437/499: loss=(0.40765213443507176-0j)\n",
      "GD iter. 438/499: loss=(0.4076484028486614-0j)\n",
      "GD iter. 439/499: loss=(0.40764469739821757-0j)\n",
      "GD iter. 440/499: loss=(0.40764101782188855-0j)\n",
      "GD iter. 441/499: loss=(0.4076373638608508-0j)\n",
      "GD iter. 442/499: loss=(0.4076337352592691-0j)\n",
      "GD iter. 443/499: loss=(0.40763013176425833-0j)\n",
      "GD iter. 444/499: loss=(0.4076265531258455-0j)\n",
      "GD iter. 445/499: loss=(0.4076229990969322-0j)\n",
      "GD iter. 446/499: loss=(0.4076194694332579-0j)\n",
      "GD iter. 447/499: loss=(0.40761596389336313-0j)\n",
      "GD iter. 448/499: loss=(0.40761248223855395-0j)\n",
      "GD iter. 449/499: loss=(0.40760902423286677-0j)\n",
      "GD iter. 450/499: loss=(0.40760558964303306-0j)\n",
      "GD iter. 451/499: loss=(0.4076021782384453-0j)\n",
      "GD iter. 452/499: loss=(0.40759878979112285-0j)\n",
      "GD iter. 453/499: loss=(0.40759542407567895-0j)\n",
      "GD iter. 454/499: loss=(0.40759208086928717-0j)\n",
      "GD iter. 455/499: loss=(0.40758875995165-0j)\n",
      "GD iter. 456/499: loss=(0.40758546110496563-0j)\n",
      "GD iter. 457/499: loss=(0.407582184113897-0j)\n",
      "GD iter. 458/499: loss=(0.4075789287655412-0j)\n",
      "GD iter. 459/499: loss=(0.40757569484939754-0j)\n",
      "GD iter. 460/499: loss=(0.4075724821573386-0j)\n",
      "GD iter. 461/499: loss=(0.4075692904835794-0j)\n",
      "GD iter. 462/499: loss=(0.40756611962464895-0j)\n",
      "GD iter. 463/499: loss=(0.40756296937936015-0j)\n",
      "GD iter. 464/499: loss=(0.4075598395487823-0j)\n",
      "GD iter. 465/499: loss=(0.40755672993621195-0j)\n",
      "GD iter. 466/499: loss=(0.40755364034714586-0j)\n",
      "GD iter. 467/499: loss=(0.40755057058925326-0j)\n",
      "GD iter. 468/499: loss=(0.40754752047234843-0j)\n",
      "GD iter. 469/499: loss=(0.40754448980836494-0j)\n",
      "GD iter. 470/499: loss=(0.4075414784113284-0j)\n",
      "GD iter. 471/499: loss=(0.407538486097331-0j)\n",
      "GD iter. 472/499: loss=(0.40753551268450605-0j)\n",
      "GD iter. 473/499: loss=(0.4075325579930024-0j)\n",
      "GD iter. 474/499: loss=(0.40752962184495967-0j)\n",
      "GD iter. 475/499: loss=(0.407526704064484-0j)\n",
      "GD iter. 476/499: loss=(0.40752380447762326-0j)\n",
      "GD iter. 477/499: loss=(0.4075209229123437-0j)\n",
      "GD iter. 478/499: loss=(0.40751805919850603-0j)\n",
      "GD iter. 479/499: loss=(0.40751521316784245-0j)\n",
      "GD iter. 480/499: loss=(0.4075123846539335-0j)\n",
      "GD iter. 481/499: loss=(0.40750957349218575-0j)\n",
      "GD iter. 482/499: loss=(0.4075067795198091-0j)\n",
      "GD iter. 483/499: loss=(0.40750400257579505-0j)\n",
      "GD iter. 484/499: loss=(0.4075012425008951-0j)\n",
      "GD iter. 485/499: loss=(0.4074984991375987-0j)\n",
      "GD iter. 486/499: loss=(0.40749577233011314-0j)\n",
      "GD iter. 487/499: loss=(0.40749306192434176-0j)\n",
      "GD iter. 488/499: loss=(0.40749036776786374-0j)\n",
      "GD iter. 489/499: loss=(0.40748768970991434-0j)\n",
      "GD iter. 490/499: loss=(0.40748502760136374-0j)\n",
      "GD iter. 491/499: loss=(0.40748238129469827-0j)\n",
      "GD iter. 492/499: loss=(0.4074797506440007-0j)\n",
      "GD iter. 493/499: loss=(0.40747713550493064-0j)\n",
      "GD iter. 494/499: loss=(0.40747453573470604-0j)\n",
      "GD iter. 495/499: loss=(0.4074719511920841-0j)\n",
      "GD iter. 496/499: loss=(0.40746938173734304-0j)\n",
      "GD iter. 497/499: loss=(0.4074668272322639-0j)\n",
      "GD iter. 498/499: loss=(0.40746428754011227-0j)\n",
      "GD iter. 499/499: loss=(0.40746176252562083-0j)\n",
      "The Accuracy is: 0.8656\n",
      "The F1 score is: 0.4605\n",
      "The precision is: 0.3608\n",
      "The recall is: 0.6364\n"
     ]
    }
   ],
   "source": [
    "# logistic regression using pca feature selection #\n",
    "x_pca_t = add_bias(x_pca)\n",
    "x_t, y_t, x_v, y_v = split_data(x_pca_t, y_train_processed, 0.9)\n",
    "x_t, y_t = data_augmentation(x_t, y_t)\n",
    "initial_w = np.random.randn(x_pca_t.shape[1]) * 0.01\n",
    "w, loss = logistic_regression(y_t, x_t, initial_w, max_iters=500, gamma=0.15)\n",
    "y_pred = sigmoid(x_v @ w)\n",
    "y_pred = (y_pred >= 0.7).astype(int)\n",
    "predict_acc_pure(y_pred, y_v)\n",
    "predict_f1_pure(y_pred, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/99: loss=(0.6909626798061412-0j)\n",
      "GD iter. 1/99: loss=(0.6735794558601624-0j)\n",
      "GD iter. 2/99: loss=(0.6583223113486754-0j)\n",
      "GD iter. 3/99: loss=(0.6448689264505854-0j)\n",
      "GD iter. 4/99: loss=(0.6329464838761912-0j)\n",
      "GD iter. 5/99: loss=(0.6223263407459684-0j)\n",
      "GD iter. 6/99: loss=(0.6128178374165825-0j)\n",
      "GD iter. 7/99: loss=(0.6042622492063763-0j)\n",
      "GD iter. 8/99: loss=(0.5965273504120941-0j)\n",
      "GD iter. 9/99: loss=(0.5895027471942651-0j)\n",
      "GD iter. 10/99: loss=(0.5830959752063374-0j)\n",
      "GD iter. 11/99: loss=(0.5772292865389332-0j)\n",
      "GD iter. 12/99: loss=(0.5718370269939669-0j)\n",
      "GD iter. 13/99: loss=(0.566863504476215-0j)\n",
      "GD iter. 14/99: loss=(0.5622612591162924-0j)\n",
      "GD iter. 15/99: loss=(0.5579896588306951-0j)\n",
      "GD iter. 16/99: loss=(0.554013757150464-0j)\n",
      "GD iter. 17/99: loss=(0.5503033619432851-0j)\n",
      "GD iter. 18/99: loss=(0.5468322736803585-0j)\n",
      "GD iter. 19/99: loss=(0.5435776601625875-0j)\n",
      "GD iter. 20/99: loss=(0.5405195413063457-0j)\n",
      "GD iter. 21/99: loss=(0.5376403629393663-0j)\n",
      "GD iter. 22/99: loss=(0.534924642811943-0j)\n",
      "GD iter. 23/99: loss=(0.5323586754010304-0j)\n",
      "GD iter. 24/99: loss=(0.5299302847547922-0j)\n",
      "GD iter. 25/99: loss=(0.5276286167395428-0j)\n",
      "GD iter. 26/99: loss=(0.5254439637276672-0j)\n",
      "GD iter. 27/99: loss=(0.5233676160972459-0j)\n",
      "GD iter. 28/99: loss=(0.5213917359752566-0j)\n",
      "GD iter. 29/99: loss=(0.5195092495039314-0j)\n",
      "GD iter. 30/99: loss=(0.5177137545891721-0j)\n",
      "GD iter. 31/99: loss=(0.515999441636123-0j)\n",
      "GD iter. 32/99: loss=(0.5143610252176699-0j)\n",
      "GD iter. 33/99: loss=(0.5127936849783787-0j)\n",
      "GD iter. 34/99: loss=(0.5112930143662293-0j)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 35/99: loss=(0.5098549760207924-0j)\n",
      "GD iter. 36/99: loss=(0.5084758628398119-0j)\n",
      "GD iter. 37/99: loss=(0.5071522639048595-0j)\n",
      "GD iter. 38/99: loss=(0.5058810345774382-0j)\n",
      "GD iter. 39/99: loss=(0.5046592701849643-0j)\n",
      "GD iter. 40/99: loss=(0.5034842828056246-0j)\n",
      "GD iter. 41/99: loss=(0.5023535807356293-0j)\n",
      "GD iter. 42/99: loss=(0.5012648502845554-0j)\n",
      "GD iter. 43/99: loss=(0.5002159395965198-0j)\n",
      "GD iter. 44/99: loss=(0.49920484423860506-0j)\n",
      "GD iter. 45/99: loss=(0.49822969433474773-0j)\n",
      "GD iter. 46/99: loss=(0.4972887430543463-0j)\n",
      "GD iter. 47/99: loss=(0.49638035629114724-0j)\n",
      "GD iter. 48/99: loss=(0.49550300339027636-0j)\n",
      "GD iter. 49/99: loss=(0.49465524880028805-0j)\n",
      "GD iter. 50/99: loss=(0.4938357445433074-0j)\n",
      "GD iter. 51/99: loss=(0.4930432234102107-0j)\n",
      "GD iter. 52/99: loss=(0.4922764927996747-0j)\n",
      "GD iter. 53/99: loss=(0.49153442913014783-0j)\n",
      "GD iter. 54/99: loss=(0.4908159727625925-0j)\n",
      "GD iter. 55/99: loss=(0.49012012337945404-0j)\n",
      "GD iter. 56/99: loss=(0.48944593577188256-0j)\n",
      "GD iter. 57/99: loss=(0.4887925159929348-0j)\n",
      "GD iter. 58/99: loss=(0.4881590178394382-0j)\n",
      "GD iter. 59/99: loss=(0.4875446396295103-0j)\n",
      "GD iter. 60/99: loss=(0.4869486212464849-0j)\n",
      "GD iter. 61/99: loss=(0.48637024142328966-0j)\n",
      "GD iter. 62/99: loss=(0.4858088152441888-0j)\n",
      "GD iter. 63/99: loss=(0.4852636918433361-0j)\n",
      "GD iter. 64/99: loss=(0.4847342522817974-0j)\n",
      "GD iter. 65/99: loss=(0.4842199075866536-0j)\n",
      "GD iter. 66/99: loss=(0.48372009693751894-0j)\n",
      "GD iter. 67/99: loss=(0.483234285987327-0j)\n",
      "GD iter. 68/99: loss=(0.48276196530558124-0j)\n",
      "GD iter. 69/99: loss=(0.4823026489334607-0j)\n",
      "GD iter. 70/99: loss=(0.48185587304122457-0j)\n",
      "GD iter. 71/99: loss=(0.4814211946793034-0j)\n",
      "GD iter. 72/99: loss=(0.48099819061529525-0j)\n",
      "GD iter. 73/99: loss=(0.480586456249836-0j)\n",
      "GD iter. 74/99: loss=(0.48018560460497345-0j)\n",
      "GD iter. 75/99: loss=(0.47979526537927275-0j)\n",
      "GD iter. 76/99: loss=(0.47941508406440964-0j)\n",
      "GD iter. 77/99: loss=(0.4790447211184899-0j)\n",
      "GD iter. 78/99: loss=(0.4786838511917539-0j)\n",
      "GD iter. 79/99: loss=(0.4783321624007202-0j)\n",
      "GD iter. 80/99: loss=(0.4779893556471564-0j)\n",
      "GD iter. 81/99: loss=(0.4776551439785894-0j)\n",
      "GD iter. 82/99: loss=(0.47732925198733767-0j)\n",
      "GD iter. 83/99: loss=(0.47701141524531215-0j)\n",
      "GD iter. 84/99: loss=(0.47670137977205324-0j)\n",
      "GD iter. 85/99: loss=(0.4763989015336878-0j)\n",
      "GD iter. 86/99: loss=(0.4761037459706711-0j)\n",
      "GD iter. 87/99: loss=(0.47581568755235654-0j)\n",
      "GD iter. 88/99: loss=(0.4755345093565869-0j)\n",
      "GD iter. 89/99: loss=(0.4752600026726446-0j)\n",
      "GD iter. 90/99: loss=(0.4749919666260259-0j)\n",
      "GD iter. 91/99: loss=(0.474730207823623-0j)\n",
      "GD iter. 92/99: loss=(0.47447454001800576-0j)\n",
      "GD iter. 93/99: loss=(0.4742247837895879-0j)\n",
      "GD iter. 94/99: loss=(0.4739807662455588-0j)\n",
      "GD iter. 95/99: loss=(0.47374232073453953-0j)\n",
      "GD iter. 96/99: loss=(0.4735092865759984-0j)\n",
      "GD iter. 97/99: loss=(0.47328150880352926-0j)\n",
      "GD iter. 98/99: loss=(0.4730588379211607-0j)\n",
      "GD iter. 99/99: loss=(0.47284112967192193-0j)\n",
      "The Accuracy is: 0.8703\n",
      "The F1 score is: 0.4238\n",
      "The precision is: 0.3417\n",
      "The recall is: 0.5579\n"
     ]
    }
   ],
   "source": [
    "# logistic regression using pca feature selection #\n",
    "initial_w = np.random.randn(x_pca.shape[1]) * 0.01\n",
    "w, loss = reg_logistic_regression(y_train_processed, x_pca, lambda_=0.01, initial_w=initial_w, max_iters=100, gamma=0.15)\n",
    "predict_acc(x_train_processed_orig_pca, y_train_processed_orig, w, logistic=False, threshold=0.85)\n",
    "predict_f1(x_train_processed_orig_pca, y_train_processed_orig, w, logistic=False, threshold=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/499: loss=(0.9901564298975539+0j)\n",
      "GD iter. 1/499: loss=(0.9180567142604487+0j)\n",
      "GD iter. 2/499: loss=(0.8473132518989671+0j)\n",
      "GD iter. 3/499: loss=(0.7835344625511956+0j)\n",
      "GD iter. 4/499: loss=(0.7386115670863207+0j)\n",
      "GD iter. 5/499: loss=(0.7121296831005176+0j)\n",
      "GD iter. 6/499: loss=(0.6964861420187531+0j)\n",
      "GD iter. 7/499: loss=(0.6841974916539455+0j)\n",
      "GD iter. 8/499: loss=(0.6751308984598546+0j)\n",
      "GD iter. 9/499: loss=(0.668363753939572+0j)\n",
      "GD iter. 10/499: loss=(0.6630907562849307+0j)\n",
      "GD iter. 11/499: loss=(0.6585788351587056+0j)\n",
      "GD iter. 12/499: loss=(0.6548553752473383+0j)\n",
      "GD iter. 13/499: loss=(0.6516554770893607+0j)\n",
      "GD iter. 14/499: loss=(0.648719116349231+0j)\n",
      "GD iter. 15/499: loss=(0.6461075542368311+0j)\n",
      "GD iter. 16/499: loss=(0.6436694712754563+0j)\n",
      "GD iter. 17/499: loss=(0.641431752058077+0j)\n",
      "GD iter. 18/499: loss=(0.6393861069891237+0j)\n",
      "GD iter. 19/499: loss=(0.6375419503799885+0j)\n",
      "GD iter. 20/499: loss=(0.6359343364388194+0j)\n",
      "GD iter. 21/499: loss=(0.6344126993378452+0j)\n",
      "GD iter. 22/499: loss=(0.6330021094414835+0j)\n",
      "GD iter. 23/499: loss=(0.6317018052848913+0j)\n",
      "GD iter. 24/499: loss=(0.6304239024162057+0j)\n",
      "GD iter. 25/499: loss=(0.6291949190266091+0j)\n",
      "GD iter. 26/499: loss=(0.6280249961181803+0j)\n",
      "GD iter. 27/499: loss=(0.6268849486264961+0j)\n",
      "GD iter. 28/499: loss=(0.6257845023803619+0j)\n",
      "GD iter. 29/499: loss=(0.6247095678958486+0j)\n",
      "GD iter. 30/499: loss=(0.6236630336696148+0j)\n",
      "GD iter. 31/499: loss=(0.6226612275907315+0j)\n",
      "GD iter. 32/499: loss=(0.6217047008755879+0j)\n",
      "GD iter. 33/499: loss=(0.6207774140576434+0j)\n",
      "GD iter. 34/499: loss=(0.6198786284138948+0j)\n",
      "GD iter. 35/499: loss=(0.6190127346174132+0j)\n",
      "GD iter. 36/499: loss=(0.6181592533050437+0j)\n",
      "GD iter. 37/499: loss=(0.6173216717064977+0j)\n",
      "GD iter. 38/499: loss=(0.6165086215771827+0j)\n",
      "GD iter. 39/499: loss=(0.6157068604973623+0j)\n",
      "GD iter. 40/499: loss=(0.6149380627221271+0j)\n",
      "GD iter. 41/499: loss=(0.6142502660207112+0j)\n",
      "GD iter. 42/499: loss=(0.6135765044457627+0j)\n",
      "GD iter. 43/499: loss=(0.6129376440153833+0j)\n",
      "GD iter. 44/499: loss=(0.6122975207590122+0j)\n",
      "GD iter. 45/499: loss=(0.6116699828390623+0j)\n",
      "GD iter. 46/499: loss=(0.6110482205356296+0j)\n",
      "GD iter. 47/499: loss=(0.6104384478266459+0j)\n",
      "GD iter. 48/499: loss=(0.609876115292681+0j)\n",
      "GD iter. 49/499: loss=(0.6093181367198749+0j)\n",
      "GD iter. 50/499: loss=(0.6087852296277216+0j)\n",
      "GD iter. 51/499: loss=(0.608261601902633+0j)\n",
      "GD iter. 52/499: loss=(0.6077576192037427+0j)\n",
      "GD iter. 53/499: loss=(0.6072625574658693+0j)\n",
      "GD iter. 54/499: loss=(0.6068106110804581+0j)\n",
      "GD iter. 55/499: loss=(0.6063701558083663+0j)\n",
      "GD iter. 56/499: loss=(0.6059634945684661+0j)\n",
      "GD iter. 57/499: loss=(0.6055617884078047+0j)\n",
      "GD iter. 58/499: loss=(0.6051868726496129+0j)\n",
      "GD iter. 59/499: loss=(0.6048103778027367+0j)\n",
      "GD iter. 60/499: loss=(0.604476162247149+0j)\n",
      "GD iter. 61/499: loss=(0.604157455689631+0j)\n",
      "GD iter. 62/499: loss=(0.603829195747789+0j)\n",
      "GD iter. 63/499: loss=(0.6035177971000183+0j)\n",
      "GD iter. 64/499: loss=(0.6032148624443269+0j)\n",
      "GD iter. 65/499: loss=(0.602914785691019+0j)\n",
      "GD iter. 66/499: loss=(0.6026059482273161+0j)\n",
      "GD iter. 67/499: loss=(0.6023257061376526+0j)\n",
      "GD iter. 68/499: loss=(0.6020423178949944+0j)\n",
      "GD iter. 69/499: loss=(0.6017696994833625+0j)\n",
      "GD iter. 70/499: loss=(0.6015212429674286+0j)\n",
      "GD iter. 71/499: loss=(0.6012690634761585+0j)\n",
      "GD iter. 72/499: loss=(0.601028986869713+0j)\n",
      "GD iter. 73/499: loss=(0.6007888265594145+0j)\n",
      "GD iter. 74/499: loss=(0.600562718745904+0j)\n",
      "GD iter. 75/499: loss=(0.6003379152583919+0j)\n",
      "GD iter. 76/499: loss=(0.6001256017872727+0j)\n",
      "GD iter. 77/499: loss=(0.5999186853851927+0j)\n",
      "GD iter. 78/499: loss=(0.5997001981258018+0j)\n",
      "GD iter. 79/499: loss=(0.599495942606578+0j)\n",
      "GD iter. 80/499: loss=(0.5992908490718517+0j)\n",
      "GD iter. 81/499: loss=(0.5990899859473012+0j)\n",
      "GD iter. 82/499: loss=(0.5988867084051303+0j)\n",
      "GD iter. 83/499: loss=(0.59869891558258+0j)\n",
      "GD iter. 84/499: loss=(0.598503104319128+0j)\n",
      "GD iter. 85/499: loss=(0.598300320386108+0j)\n",
      "GD iter. 86/499: loss=(0.5981179040017147+0j)\n",
      "GD iter. 87/499: loss=(0.5979305918125738+0j)\n",
      "GD iter. 88/499: loss=(0.59774060220027+0j)\n",
      "GD iter. 89/499: loss=(0.5975727921713359+0j)\n",
      "GD iter. 90/499: loss=(0.5973989340552666+0j)\n",
      "GD iter. 91/499: loss=(0.5972346007242725+0j)\n",
      "GD iter. 92/499: loss=(0.5970568570144943+0j)\n",
      "GD iter. 93/499: loss=(0.5968991252649012+0j)\n",
      "GD iter. 94/499: loss=(0.5967357924449509+0j)\n",
      "GD iter. 95/499: loss=(0.5965849505776523+0j)\n",
      "GD iter. 96/499: loss=(0.596433726842304+0j)\n",
      "GD iter. 97/499: loss=(0.5962812656035963+0j)\n",
      "GD iter. 98/499: loss=(0.5961505396248549+0j)\n",
      "GD iter. 99/499: loss=(0.5959986623522012+0j)\n",
      "GD iter. 100/499: loss=(0.5958796579137531+0j)\n",
      "GD iter. 101/499: loss=(0.5957253000677641+0j)\n",
      "GD iter. 102/499: loss=(0.5955969642052671+0j)\n",
      "GD iter. 103/499: loss=(0.5954797740080046+0j)\n",
      "GD iter. 104/499: loss=(0.5953349551892204+0j)\n",
      "GD iter. 105/499: loss=(0.5952089884205997+0j)\n",
      "GD iter. 106/499: loss=(0.5950892235671036+0j)\n",
      "GD iter. 107/499: loss=(0.5949624488773391+0j)\n",
      "GD iter. 108/499: loss=(0.5948527687003856+0j)\n",
      "GD iter. 109/499: loss=(0.5947045865411592+0j)\n",
      "GD iter. 110/499: loss=(0.5945757912073213+0j)\n",
      "GD iter. 111/499: loss=(0.5944582465138539+0j)\n",
      "GD iter. 112/499: loss=(0.5943369142509742+0j)\n",
      "GD iter. 113/499: loss=(0.5942444041581+0j)\n",
      "GD iter. 114/499: loss=(0.5941004674891043+0j)\n",
      "GD iter. 115/499: loss=(0.5939817973370539+0j)\n",
      "GD iter. 116/499: loss=(0.593873509263646+0j)\n",
      "GD iter. 117/499: loss=(0.5937710546281196+0j)\n",
      "GD iter. 118/499: loss=(0.5936484352149822+0j)\n",
      "GD iter. 119/499: loss=(0.5935566567946553+0j)\n",
      "GD iter. 120/499: loss=(0.593441653483061+0j)\n",
      "GD iter. 121/499: loss=(0.5933251056949271+0j)\n",
      "GD iter. 122/499: loss=(0.5932247888495141+0j)\n",
      "GD iter. 123/499: loss=(0.5931403225889785+0j)\n",
      "GD iter. 124/499: loss=(0.5930160616767539+0j)\n",
      "GD iter. 125/499: loss=(0.5929170167329484+0j)\n",
      "GD iter. 126/499: loss=(0.5928163984857041+0j)\n",
      "GD iter. 127/499: loss=(0.5927276713094449+0j)\n",
      "GD iter. 128/499: loss=(0.5926382808413363+0j)\n",
      "GD iter. 129/499: loss=(0.5925256998479813+0j)\n",
      "GD iter. 130/499: loss=(0.5924322702668613+0j)\n",
      "GD iter. 131/499: loss=(0.5923521807559461+0j)\n",
      "GD iter. 132/499: loss=(0.5922495095011017+0j)\n",
      "GD iter. 133/499: loss=(0.5921703313255284+0j)\n",
      "GD iter. 134/499: loss=(0.5920523572158942+0j)\n",
      "GD iter. 135/499: loss=(0.591969510310706+0j)\n",
      "GD iter. 136/499: loss=(0.5918582494989941+0j)\n",
      "GD iter. 137/499: loss=(0.5917890916887175+0j)\n",
      "GD iter. 138/499: loss=(0.5916884851367048+0j)\n",
      "GD iter. 139/499: loss=(0.5916219452332037+0j)\n",
      "GD iter. 140/499: loss=(0.5915155521055703+0j)\n",
      "GD iter. 141/499: loss=(0.5914251220257172+0j)\n",
      "GD iter. 142/499: loss=(0.5913296983312588+0j)\n",
      "GD iter. 143/499: loss=(0.591278367517623+0j)\n",
      "GD iter. 144/499: loss=(0.5911869894069152+0j)\n",
      "GD iter. 145/499: loss=(0.5911077421898485+0j)\n",
      "GD iter. 146/499: loss=(0.5909934190651471+0j)\n",
      "GD iter. 147/499: loss=(0.5909157776118966+0j)\n",
      "GD iter. 148/499: loss=(0.5908290696739513+0j)\n",
      "GD iter. 149/499: loss=(0.5907476474223612+0j)\n",
      "GD iter. 150/499: loss=(0.5906743790514871+0j)\n",
      "GD iter. 151/499: loss=(0.5905912120013136+0j)\n",
      "GD iter. 152/499: loss=(0.5905128808190003+0j)\n",
      "GD iter. 153/499: loss=(0.5904173461039341+0j)\n",
      "GD iter. 154/499: loss=(0.5903623209558013+0j)\n",
      "GD iter. 155/499: loss=(0.5902787589084522+0j)\n",
      "GD iter. 156/499: loss=(0.5902083760906602+0j)\n",
      "GD iter. 157/499: loss=(0.5901226961460817+0j)\n",
      "GD iter. 158/499: loss=(0.5900602504786088+0j)\n",
      "GD iter. 159/499: loss=(0.5899777346909697+0j)\n",
      "GD iter. 160/499: loss=(0.589893626660141+0j)\n",
      "GD iter. 161/499: loss=(0.5898372250712843+0j)\n",
      "GD iter. 162/499: loss=(0.5897483441821488+0j)\n",
      "GD iter. 163/499: loss=(0.5896904116594331+0j)\n",
      "GD iter. 164/499: loss=(0.5896257302600809+0j)\n",
      "GD iter. 165/499: loss=(0.5895627944608741+0j)\n",
      "GD iter. 166/499: loss=(0.589524556575852+0j)\n",
      "GD iter. 167/499: loss=(0.5894541369612748+0j)\n",
      "GD iter. 168/499: loss=(0.5893866612362924+0j)\n",
      "GD iter. 169/499: loss=(0.5893253681405378+0j)\n",
      "GD iter. 170/499: loss=(0.5892595705008319+0j)\n",
      "GD iter. 171/499: loss=(0.5892531919811621+0j)\n",
      "GD iter. 172/499: loss=(0.5891432659822806+0j)\n",
      "GD iter. 173/499: loss=(0.5891300568621507+0j)\n",
      "GD iter. 174/499: loss=(0.5890352421276241+0j)\n",
      "GD iter. 175/499: loss=(0.5890095742267345+0j)\n",
      "GD iter. 176/499: loss=(0.5889174871565552+0j)\n",
      "GD iter. 177/499: loss=(0.5889131636651788+0j)\n",
      "GD iter. 178/499: loss=(0.5888549317905963+0j)\n",
      "GD iter. 179/499: loss=(0.5887800750515018+0j)\n",
      "GD iter. 180/499: loss=(0.5887160637653107+0j)\n",
      "GD iter. 181/499: loss=(0.588688279794038+0j)\n",
      "GD iter. 182/499: loss=(0.5886303920477808+0j)\n",
      "GD iter. 183/499: loss=(0.588602652732832+0j)\n",
      "GD iter. 184/499: loss=(0.588520954084538+0j)\n",
      "GD iter. 185/499: loss=(0.5884880924116597+0j)\n",
      "GD iter. 186/499: loss=(0.5884396683460157+0j)\n",
      "GD iter. 187/499: loss=(0.5883962181571561+0j)\n",
      "GD iter. 188/499: loss=(0.5883429639255684+0j)\n",
      "GD iter. 189/499: loss=(0.5882984086886142+0j)\n",
      "GD iter. 190/499: loss=(0.5882671191885627+0j)\n",
      "GD iter. 191/499: loss=(0.5882192534018085+0j)\n",
      "GD iter. 192/499: loss=(0.5881836312071129+0j)\n",
      "GD iter. 193/499: loss=(0.5881512817116478+0j)\n",
      "GD iter. 194/499: loss=(0.5880891841363148+0j)\n",
      "GD iter. 195/499: loss=(0.5880597124660125+0j)\n",
      "GD iter. 196/499: loss=(0.5880275517913229+0j)\n",
      "GD iter. 197/499: loss=(0.5879728663027551+0j)\n",
      "GD iter. 198/499: loss=(0.5879646497517+0j)\n",
      "GD iter. 199/499: loss=(0.5878990392734988+0j)\n",
      "GD iter. 200/499: loss=(0.5878713912744343+0j)\n",
      "GD iter. 201/499: loss=(0.5878012292961504+0j)\n",
      "GD iter. 202/499: loss=(0.587781029742108+0j)\n",
      "GD iter. 203/499: loss=(0.5877572430233563+0j)\n",
      "GD iter. 204/499: loss=(0.5876993989487599+0j)\n",
      "GD iter. 205/499: loss=(0.5876772570578178+0j)\n",
      "GD iter. 206/499: loss=(0.5876336379351914+0j)\n",
      "GD iter. 207/499: loss=(0.5875796475920189+0j)\n",
      "GD iter. 208/499: loss=(0.5875611649729989+0j)\n",
      "GD iter. 209/499: loss=(0.587524713667906+0j)\n",
      "GD iter. 210/499: loss=(0.5874781630266726+0j)\n",
      "GD iter. 211/499: loss=(0.5874381345855394+0j)\n",
      "GD iter. 212/499: loss=(0.587401635287552+0j)\n",
      "GD iter. 213/499: loss=(0.5873820476034415+0j)\n",
      "GD iter. 214/499: loss=(0.5873376814300993+0j)\n",
      "GD iter. 215/499: loss=(0.587312644109704+0j)\n",
      "GD iter. 216/499: loss=(0.5872818906156718+0j)\n",
      "GD iter. 217/499: loss=(0.5872489195676656+0j)\n",
      "GD iter. 218/499: loss=(0.5872027986013033+0j)\n",
      "GD iter. 219/499: loss=(0.5871719974212656+0j)\n",
      "GD iter. 220/499: loss=(0.5871197268466587+0j)\n",
      "GD iter. 221/499: loss=(0.5871281680947833+0j)\n",
      "GD iter. 222/499: loss=(0.5870866015896733+0j)\n",
      "GD iter. 223/499: loss=(0.5870384399895624+0j)\n",
      "GD iter. 224/499: loss=(0.587003931267293+0j)\n",
      "GD iter. 225/499: loss=(0.5869756141531218+0j)\n",
      "GD iter. 226/499: loss=(0.5869521317352625+0j)\n",
      "GD iter. 227/499: loss=(0.586920431301704+0j)\n",
      "GD iter. 228/499: loss=(0.5868831174335056+0j)\n",
      "GD iter. 229/499: loss=(0.5868339220610752+0j)\n",
      "GD iter. 230/499: loss=(0.5868102115560374+0j)\n",
      "GD iter. 231/499: loss=(0.5867758083237056+0j)\n",
      "GD iter. 232/499: loss=(0.5867600895923596+0j)\n",
      "GD iter. 233/499: loss=(0.5867257839241731+0j)\n",
      "GD iter. 234/499: loss=(0.5866872768627448+0j)\n",
      "GD iter. 235/499: loss=(0.586660799226993+0j)\n",
      "GD iter. 236/499: loss=(0.5866284155532759+0j)\n",
      "GD iter. 237/499: loss=(0.5866275012296319+0j)\n",
      "GD iter. 238/499: loss=(0.5865610288771761+0j)\n",
      "GD iter. 239/499: loss=(0.5865581145846849+0j)\n",
      "GD iter. 240/499: loss=(0.5865245746268577+0j)\n",
      "GD iter. 241/499: loss=(0.5864870313697147+0j)\n",
      "GD iter. 242/499: loss=(0.5864544147048094+0j)\n",
      "GD iter. 243/499: loss=(0.5864476608615038+0j)\n",
      "GD iter. 244/499: loss=(0.586441590635722+0j)\n",
      "GD iter. 245/499: loss=(0.5863868870183637+0j)\n",
      "GD iter. 246/499: loss=(0.586353617732425+0j)\n",
      "GD iter. 247/499: loss=(0.5863551064905287+0j)\n",
      "GD iter. 248/499: loss=(0.5863137139357079+0j)\n",
      "GD iter. 249/499: loss=(0.5862868803400755+0j)\n",
      "GD iter. 250/499: loss=(0.5862644565018637+0j)\n",
      "GD iter. 251/499: loss=(0.5862593612562006+0j)\n",
      "GD iter. 252/499: loss=(0.5862162620430637+0j)\n",
      "GD iter. 253/499: loss=(0.5861883324737723+0j)\n",
      "GD iter. 254/499: loss=(0.5861842891889891+0j)\n",
      "GD iter. 255/499: loss=(0.5861532190954952+0j)\n",
      "GD iter. 256/499: loss=(0.5861614795984527+0j)\n",
      "GD iter. 257/499: loss=(0.5861344343112713+0j)\n",
      "GD iter. 258/499: loss=(0.5860961524639806+0j)\n",
      "GD iter. 259/499: loss=(0.5860682446627342+0j)\n",
      "GD iter. 260/499: loss=(0.5860689180169241+0j)\n",
      "GD iter. 261/499: loss=(0.5860301485364001+0j)\n",
      "GD iter. 262/499: loss=(0.586018761689525+0j)\n",
      "GD iter. 263/499: loss=(0.5859896221393446+0j)\n",
      "GD iter. 264/499: loss=(0.5859744617883568+0j)\n",
      "GD iter. 265/499: loss=(0.5859503044279093+0j)\n",
      "GD iter. 266/499: loss=(0.5859274255464808+0j)\n",
      "GD iter. 267/499: loss=(0.5859232196787316+0j)\n",
      "GD iter. 268/499: loss=(0.5859109142637134+0j)\n",
      "GD iter. 269/499: loss=(0.5858731767044574+0j)\n",
      "GD iter. 270/499: loss=(0.585855555160833+0j)\n",
      "GD iter. 271/499: loss=(0.5858185626224466+0j)\n",
      "GD iter. 272/499: loss=(0.5858092384448069+0j)\n",
      "GD iter. 273/499: loss=(0.5857936410727124+0j)\n",
      "GD iter. 274/499: loss=(0.5857741610712104+0j)\n",
      "GD iter. 275/499: loss=(0.5857553951536046+0j)\n",
      "GD iter. 276/499: loss=(0.5857435064845556+0j)\n",
      "GD iter. 277/499: loss=(0.5857612495516621+0j)\n",
      "GD iter. 278/499: loss=(0.5857231634404224+0j)\n",
      "GD iter. 279/499: loss=(0.5857013864342479+0j)\n",
      "GD iter. 280/499: loss=(0.5856780484738133+0j)\n",
      "GD iter. 281/499: loss=(0.5856726475863274+0j)\n",
      "GD iter. 282/499: loss=(0.5856285218378171+0j)\n",
      "GD iter. 283/499: loss=(0.5856180944399664+0j)\n",
      "GD iter. 284/499: loss=(0.58560247529333+0j)\n",
      "GD iter. 285/499: loss=(0.5856121003173408+0j)\n",
      "GD iter. 286/499: loss=(0.585568434949963+0j)\n",
      "GD iter. 287/499: loss=(0.5855480278748512+0j)\n",
      "GD iter. 288/499: loss=(0.5855459150477832+0j)\n",
      "GD iter. 289/499: loss=(0.5855171120161222+0j)\n",
      "GD iter. 290/499: loss=(0.5854932700908657+0j)\n",
      "GD iter. 291/499: loss=(0.585489364121551+0j)\n",
      "GD iter. 292/499: loss=(0.5854605255849353+0j)\n",
      "GD iter. 293/499: loss=(0.5854624277829672+0j)\n",
      "GD iter. 294/499: loss=(0.5854367863329715+0j)\n",
      "GD iter. 295/499: loss=(0.5854202567628363+0j)\n",
      "GD iter. 296/499: loss=(0.5854136881859385+0j)\n",
      "GD iter. 297/499: loss=(0.5853961964567642+0j)\n",
      "GD iter. 298/499: loss=(0.5853969912634653+0j)\n",
      "GD iter. 299/499: loss=(0.5853544422093153+0j)\n",
      "GD iter. 300/499: loss=(0.5853496538003286+0j)\n",
      "GD iter. 301/499: loss=(0.5853561009190306+0j)\n",
      "GD iter. 302/499: loss=(0.5853372175950141+0j)\n",
      "GD iter. 303/499: loss=(0.5853118228610957+0j)\n",
      "GD iter. 304/499: loss=(0.5852925049412707+0j)\n",
      "GD iter. 305/499: loss=(0.5852685614245692+0j)\n",
      "GD iter. 306/499: loss=(0.585278449269184+0j)\n",
      "GD iter. 307/499: loss=(0.5852523120345613+0j)\n",
      "GD iter. 308/499: loss=(0.5852322424955291+0j)\n",
      "GD iter. 309/499: loss=(0.5852099260731227+0j)\n",
      "GD iter. 310/499: loss=(0.5852008374908414+0j)\n",
      "GD iter. 311/499: loss=(0.5852081210336083+0j)\n",
      "GD iter. 312/499: loss=(0.5851699117439162+0j)\n",
      "GD iter. 313/499: loss=(0.5851571333697677+0j)\n",
      "GD iter. 314/499: loss=(0.5851719424753583+0j)\n",
      "GD iter. 315/499: loss=(0.5851234055123804+0j)\n",
      "GD iter. 316/499: loss=(0.5851222290972309+0j)\n",
      "GD iter. 317/499: loss=(0.5851021079082775+0j)\n",
      "GD iter. 318/499: loss=(0.5850738027752559+0j)\n",
      "GD iter. 319/499: loss=(0.5850859735023829+0j)\n",
      "GD iter. 320/499: loss=(0.5850647045801897+0j)\n",
      "GD iter. 321/499: loss=(0.5850584701526457+0j)\n",
      "GD iter. 322/499: loss=(0.5850510199101707+0j)\n",
      "GD iter. 323/499: loss=(0.5850423884250706+0j)\n",
      "GD iter. 324/499: loss=(0.5850329557946671+0j)\n",
      "GD iter. 325/499: loss=(0.5850042520884349+0j)\n",
      "GD iter. 326/499: loss=(0.5850357046032006+0j)\n",
      "GD iter. 327/499: loss=(0.5849947372975728+0j)\n",
      "GD iter. 328/499: loss=(0.5849694194968719+0j)\n",
      "GD iter. 329/499: loss=(0.5849546334308713+0j)\n",
      "GD iter. 330/499: loss=(0.5849410561696647+0j)\n",
      "GD iter. 331/499: loss=(0.5849068261515213+0j)\n",
      "GD iter. 332/499: loss=(0.584932335618058+0j)\n",
      "GD iter. 333/499: loss=(0.5849264714935801+0j)\n",
      "GD iter. 334/499: loss=(0.5848963212431338+0j)\n",
      "GD iter. 335/499: loss=(0.5848864738687884+0j)\n",
      "GD iter. 336/499: loss=(0.5849160375724499+0j)\n",
      "GD iter. 337/499: loss=(0.5848711175810658+0j)\n",
      "GD iter. 338/499: loss=(0.5848558372684434+0j)\n",
      "GD iter. 339/499: loss=(0.584825098308633+0j)\n",
      "GD iter. 340/499: loss=(0.5848185270078328+0j)\n",
      "GD iter. 341/499: loss=(0.5847970811568864+0j)\n",
      "GD iter. 342/499: loss=(0.5848249291463399+0j)\n",
      "GD iter. 343/499: loss=(0.5848181048806876+0j)\n",
      "GD iter. 344/499: loss=(0.5847754498333821+0j)\n",
      "GD iter. 345/499: loss=(0.5847784495175495+0j)\n",
      "GD iter. 346/499: loss=(0.5847593214244846+0j)\n",
      "GD iter. 347/499: loss=(0.5847517507567994+0j)\n",
      "GD iter. 348/499: loss=(0.5847533838409805+0j)\n",
      "GD iter. 349/499: loss=(0.5847117738422734+0j)\n",
      "GD iter. 350/499: loss=(0.5847182310005126+0j)\n",
      "GD iter. 351/499: loss=(0.5847139935162471+0j)\n",
      "GD iter. 352/499: loss=(0.5846733696967982+0j)\n",
      "GD iter. 353/499: loss=(0.5847098287883015+0j)\n",
      "GD iter. 354/499: loss=(0.584664966900287+0j)\n",
      "GD iter. 355/499: loss=(0.584695687177518+0j)\n",
      "GD iter. 356/499: loss=(0.5846509820338156+0j)\n",
      "GD iter. 357/499: loss=(0.584664795837155+0j)\n",
      "GD iter. 358/499: loss=(0.584624224416437+0j)\n",
      "GD iter. 359/499: loss=(0.5846306124703327+0j)\n",
      "GD iter. 360/499: loss=(0.5846188393109518+0j)\n",
      "GD iter. 361/499: loss=(0.584596819790248+0j)\n",
      "GD iter. 362/499: loss=(0.5845857788932065+0j)\n",
      "GD iter. 363/499: loss=(0.5846065952891805+0j)\n",
      "GD iter. 364/499: loss=(0.5845682322964445+0j)\n",
      "GD iter. 365/499: loss=(0.5846050212576153+0j)\n",
      "GD iter. 366/499: loss=(0.5845496680419056+0j)\n",
      "GD iter. 367/499: loss=(0.5845634422447966+0j)\n",
      "GD iter. 368/499: loss=(0.5845341669720291+0j)\n",
      "GD iter. 369/499: loss=(0.5845373293320401+0j)\n",
      "GD iter. 370/499: loss=(0.5845238239494679+0j)\n",
      "GD iter. 371/499: loss=(0.5845156605182178+0j)\n",
      "GD iter. 372/499: loss=(0.5844998757670086+0j)\n",
      "GD iter. 373/499: loss=(0.5845169365461014+0j)\n",
      "GD iter. 374/499: loss=(0.5844868233302478+0j)\n",
      "GD iter. 375/499: loss=(0.5844609170422709+0j)\n",
      "GD iter. 376/499: loss=(0.5844779216607079+0j)\n",
      "GD iter. 377/499: loss=(0.584481921945274+0j)\n",
      "GD iter. 378/499: loss=(0.5844575720742746+0j)\n",
      "GD iter. 379/499: loss=(0.5844305533237149+0j)\n",
      "GD iter. 380/499: loss=(0.5844364944891502+0j)\n",
      "GD iter. 381/499: loss=(0.5844195525337053+0j)\n",
      "GD iter. 382/499: loss=(0.5844252425103047+0j)\n",
      "GD iter. 383/499: loss=(0.5844007965056014+0j)\n",
      "GD iter. 384/499: loss=(0.5844037071475866+0j)\n",
      "GD iter. 385/499: loss=(0.5844018291344762+0j)\n",
      "GD iter. 386/499: loss=(0.5843983491882562+0j)\n",
      "GD iter. 387/499: loss=(0.5843642605472587+0j)\n",
      "GD iter. 388/499: loss=(0.5843604536362466+0j)\n",
      "GD iter. 389/499: loss=(0.5843718065836563+0j)\n",
      "GD iter. 390/499: loss=(0.5843604383592534+0j)\n",
      "GD iter. 391/499: loss=(0.5843426189486031+0j)\n",
      "GD iter. 392/499: loss=(0.5843316784553596+0j)\n",
      "GD iter. 393/499: loss=(0.5843125070305317+0j)\n",
      "GD iter. 394/499: loss=(0.5843243222286731+0j)\n",
      "GD iter. 395/499: loss=(0.5843017434976634+0j)\n",
      "GD iter. 396/499: loss=(0.5843310783135243+0j)\n",
      "GD iter. 397/499: loss=(0.584302744381307+0j)\n",
      "GD iter. 398/499: loss=(0.5843090428659508+0j)\n",
      "GD iter. 399/499: loss=(0.5842870028084938+0j)\n",
      "GD iter. 400/499: loss=(0.5842781584487169+0j)\n",
      "GD iter. 401/499: loss=(0.5842522793426661+0j)\n",
      "GD iter. 402/499: loss=(0.5842545562294609+0j)\n",
      "GD iter. 403/499: loss=(0.5842258071916129+0j)\n",
      "GD iter. 404/499: loss=(0.5842580626551849+0j)\n",
      "GD iter. 405/499: loss=(0.5842567206932643+0j)\n",
      "GD iter. 406/499: loss=(0.5842533437924667+0j)\n",
      "GD iter. 407/499: loss=(0.5842332989300225+0j)\n",
      "GD iter. 408/499: loss=(0.5842405426697829+0j)\n",
      "GD iter. 409/499: loss=(0.5841896304717311+0j)\n",
      "GD iter. 410/499: loss=(0.5842451430947788+0j)\n",
      "GD iter. 411/499: loss=(0.5841832105688325+0j)\n",
      "GD iter. 412/499: loss=(0.5842018084140861+0j)\n",
      "GD iter. 413/499: loss=(0.5841795079534295+0j)\n",
      "GD iter. 414/499: loss=(0.5841858335459351+0j)\n",
      "GD iter. 415/499: loss=(0.5841659515615732+0j)\n",
      "GD iter. 416/499: loss=(0.5841704966459118+0j)\n",
      "GD iter. 417/499: loss=(0.5841401330144536+0j)\n",
      "GD iter. 418/499: loss=(0.584155010193361+0j)\n",
      "GD iter. 419/499: loss=(0.5841352448160009+0j)\n",
      "GD iter. 420/499: loss=(0.5841699953330047+0j)\n",
      "GD iter. 421/499: loss=(0.5841556805750303+0j)\n",
      "GD iter. 422/499: loss=(0.5841489637913847+0j)\n",
      "GD iter. 423/499: loss=(0.5841146218626505+0j)\n",
      "GD iter. 424/499: loss=(0.5841503802338134+0j)\n",
      "GD iter. 425/499: loss=(0.5841118176938436+0j)\n",
      "GD iter. 426/499: loss=(0.5841080195225418+0j)\n",
      "GD iter. 427/499: loss=(0.5840878523603875+0j)\n",
      "GD iter. 428/499: loss=(0.5841007809420966+0j)\n",
      "GD iter. 429/499: loss=(0.584111499166742+0j)\n",
      "GD iter. 430/499: loss=(0.5840738507107194+0j)\n",
      "GD iter. 431/499: loss=(0.5840666706633282+0j)\n",
      "GD iter. 432/499: loss=(0.5840838407697665+0j)\n",
      "GD iter. 433/499: loss=(0.5840787687562006+0j)\n",
      "GD iter. 434/499: loss=(0.5840675366296333+0j)\n",
      "GD iter. 435/499: loss=(0.5840585509755633+0j)\n",
      "GD iter. 436/499: loss=(0.5840439832394296+0j)\n",
      "GD iter. 437/499: loss=(0.5840444462091883+0j)\n",
      "GD iter. 438/499: loss=(0.5840544914447162+0j)\n",
      "GD iter. 439/499: loss=(0.5840276769306059+0j)\n",
      "GD iter. 440/499: loss=(0.5840215835382575+0j)\n",
      "GD iter. 441/499: loss=(0.584027233579495+0j)\n",
      "GD iter. 442/499: loss=(0.5840162505562914+0j)\n",
      "GD iter. 443/499: loss=(0.5839930076840587+0j)\n",
      "GD iter. 444/499: loss=(0.5839968850601678+0j)\n",
      "GD iter. 445/499: loss=(0.5840161495852921+0j)\n",
      "GD iter. 446/499: loss=(0.5839771553763873+0j)\n",
      "GD iter. 447/499: loss=(0.5839835688979113+0j)\n",
      "GD iter. 448/499: loss=(0.5839926851412701+0j)\n",
      "GD iter. 449/499: loss=(0.5839854901332885+0j)\n",
      "GD iter. 450/499: loss=(0.5840003750394636+0j)\n",
      "GD iter. 451/499: loss=(0.5839569380704385+0j)\n",
      "GD iter. 452/499: loss=(0.5839569848256856+0j)\n",
      "GD iter. 453/499: loss=(0.583938542082584+0j)\n",
      "GD iter. 454/499: loss=(0.5839861552504012+0j)\n",
      "GD iter. 455/499: loss=(0.5839603189873346+0j)\n",
      "GD iter. 456/499: loss=(0.5839765519549851+0j)\n",
      "GD iter. 457/499: loss=(0.5839480861883538+0j)\n",
      "GD iter. 458/499: loss=(0.5839604102887432+0j)\n",
      "GD iter. 459/499: loss=(0.5839456106242754+0j)\n",
      "GD iter. 460/499: loss=(0.583952494999425+0j)\n",
      "GD iter. 461/499: loss=(0.583924109418589+0j)\n",
      "GD iter. 462/499: loss=(0.5839565674306733+0j)\n",
      "GD iter. 463/499: loss=(0.5839190688713238+0j)\n",
      "GD iter. 464/499: loss=(0.5839307764956035+0j)\n",
      "GD iter. 465/499: loss=(0.5839060635921461+0j)\n",
      "GD iter. 466/499: loss=(0.5839011026823123+0j)\n",
      "GD iter. 467/499: loss=(0.5839107100501864+0j)\n",
      "GD iter. 468/499: loss=(0.5838823713666934+0j)\n",
      "GD iter. 469/499: loss=(0.5838875892476285+0j)\n",
      "GD iter. 470/499: loss=(0.5838869559163363+0j)\n",
      "GD iter. 471/499: loss=(0.583895208213408+0j)\n",
      "GD iter. 472/499: loss=(0.5838792027121312+0j)\n",
      "GD iter. 473/499: loss=(0.5838827797018308+0j)\n",
      "GD iter. 474/499: loss=(0.5838732136255979+0j)\n",
      "GD iter. 475/499: loss=(0.5838761142742638+0j)\n",
      "GD iter. 476/499: loss=(0.5838719998771987+0j)\n",
      "GD iter. 477/499: loss=(0.5838728271914582+0j)\n",
      "GD iter. 478/499: loss=(0.5838677166267626+0j)\n",
      "GD iter. 479/499: loss=(0.5838517800040985+0j)\n",
      "GD iter. 480/499: loss=(0.5838542799714204+0j)\n",
      "GD iter. 481/499: loss=(0.583846176137735+0j)\n",
      "GD iter. 482/499: loss=(0.5838328101320929+0j)\n",
      "GD iter. 483/499: loss=(0.5838323673846166+0j)\n",
      "GD iter. 484/499: loss=(0.5838535554211551+0j)\n",
      "GD iter. 485/499: loss=(0.5838201055023639+0j)\n",
      "GD iter. 486/499: loss=(0.5838536023463006+0j)\n",
      "GD iter. 487/499: loss=(0.5838347765114233+0j)\n",
      "GD iter. 488/499: loss=(0.5838213565539874+0j)\n",
      "GD iter. 489/499: loss=(0.5838110995122345+0j)\n",
      "GD iter. 490/499: loss=(0.5838162431668894+0j)\n",
      "GD iter. 491/499: loss=(0.583815651407464+0j)\n",
      "GD iter. 492/499: loss=(0.5837916140933944+0j)\n",
      "GD iter. 493/499: loss=(0.5838224927932267+0j)\n",
      "GD iter. 494/499: loss=(0.5837793897739909+0j)\n",
      "GD iter. 495/499: loss=(0.5837952337758974+0j)\n",
      "GD iter. 496/499: loss=(0.583780551547929+0j)\n",
      "GD iter. 497/499: loss=(0.5838028036587157+0j)\n",
      "GD iter. 498/499: loss=(0.5837929456755263+0j)\n",
      "GD iter. 499/499: loss=(0.5838305345131882+0j)\n",
      "The Accuracy is: 0.8246\n",
      "The F1 score is: 0.4153\n",
      "The precision is: 0.3016\n",
      "The recall is: 0.6667\n"
     ]
    }
   ],
   "source": [
    "x_t, y_t, x_v, y_v = split_data(x_pca, y_train_processed, 0.9)\n",
    "x_t, y_t = data_augmentation(x_t, y_t)\n",
    "initial_w = np.random.randn(x_t.shape[1]) * 0.01\n",
    "w, loss = hinge_regression(y_t, x_t, initial_w, lambda_=0.3, max_iters=500, gamma=0.01)\n",
    "y_pred = ((x_v @ w) > 1).astype(int)\n",
    "predict_acc_pure(y_pred, y_v)\n",
    "predict_f1_pure(y_pred, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SVM to classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_svm, b_svm = SVM.gradient_descent(x_train_processed_orig_pca[:, 1:], y_train_processed_orig, epochs=500, lr=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
